[{"title":"go/Go语言随记","date":"2021-07-31T14:35:21.290Z","path":"2021/07/31/go/Go语言随记/","text":"Go 语法语法基础1234567891011121314151617181920212223//文件中的所有其余代码都属于 main 包package main//引入 fmt 包import ( \"fmt\" \"math\" \"reflect\" \"strings\")//main 程序运行的入口，程序运行时首先运行//go 静态类型func main() &#123; fmt.Println(\"hello world\") fmt.Println(math.Floor(2.67)) fmt.Println(strings.Title(\"hello zcy\")) fmt.Println('a') fmt.Println(reflect.TypeOf(5.2)) fmt.Println(reflect.TypeOf(1)) var numA int = 4 //通常类型声明可以省略 fmt.Println(numA)&#125; 零值 float：0，int：0，string：空字符串，boolean：false 123var myFloat float64var myString stringfmt.Println(myFloat, myString) 短变量 短变量声明：在同一个代码域中不能进行不能对同一个变量重复声明 短变量在声明时类型也是确定了，后续不能进行跨类型赋值，可以同类型赋值 123myVar := 123myVar = 234fmt.Println(myVar) 常量 使用 const 关键字定义，不是 var 必须在声明常量时进行赋值，并且不可以改变常量的值 常量没有 := 语法 1const StudentName string = \"zhang\" 命名规则对于变量、函数、类型的命名规则 【强制】名称必须以字母开头，可以有任意数量的字母或数字 【强制】如果变量、函数、类型是以大写字母开头 ，则认为它是可以导出的（可以在 main 包或者其他包中被引用），可以在当前包之外的包中被访问；如果是小写字母开头，则认为是未导出，只能在当前包中使用 【强制】命名时避免和 Go 的保留关键字重复，会造成对 Go 本身的类型无法使用 【约定】遵守驼峰式 命名 【约定】当名称的 含义在上下文中很明显时，可以用缩写来代替，例如：用 i 代替 index 【约定】包名应该全部小写，含义相当明确时可缩写 【约定】多个单词的包名应该全部小写，不是下划线或者驼峰式 变量命名不要与包名冲突 转换 数学运算和比较运算要求包含的值具有相同的类型，类型不同需要运算或者比较时需要进行转换 1234var numInt = 3var numFloat = 4.6fmt.Println(numInt * numFloat) //Invalid operation: numInt*numFloat (mismatched types int and float64)fmt.Println(float64(numInt) * numFloat) 命令 go fmt：自动重新格式化源文件以便使用 Go 标准格式 go build：将 go 源代码编译成计算机可执行的二进制文件 go run：编译并运行一个程序，而不将可运行文件保存在当前目录 方法方法是与特定类型的值关联的函数 时间方法 123var now = time.Now()fmt.Println(now.Year())fmt.Println(now.String()) 键盘输入 1234fmt.Print(&quot;请输入内容：&quot;)reader :&#x3D; bufio.NewReader(os.Stdin) &#x2F;&#x2F;从标准输入（键盘）读取input, _ :&#x3D; reader.ReadString(&#39;\\n&#39;) &#x2F;&#x2F;以字符串形式返回用户所有输入内容；换行符前的所有内容将被读取fmt.Println(input) _：上面代码块中出现的“_”，表示空白标识符，空白标识符接收的值会被丢弃掉；Go 不允许定义变量却不使用，这种情况使用空白标识符来处理； 正常情况下要对程序的异常（错误）返回进行处理，否则可能会对后面程序的运行造成意外情况 1234567fmt.Print(\"请输入内容：\")reader := bufio.NewReader(os.Stdin)input, err := reader.ReadString('\\n')if err != nil &#123; log.Fatal(nil) //打印错误并且终止程序&#125;fmt.Println(input) 块和变量的作用域变量的作用域由其声明所在块和嵌套在该块中的其他块组成，声明的变量可以在其作用域任何地方被访问，在域外无法访问 函数函数定义和参数123456func calculateArea(width float64, height float64) (float64, error) &#123; if width &lt; 0 || height &lt; 0 &#123; return 0, fmt.Errorf(\"输入异常：width&#123;%.2f&#125;, height&#123;%.2f&#125;\", width, height) &#125; return width * height, nil&#125; Go 函数可以有多个返回值，Go 是一种值传递语言，函数的形式参数从调用中接收实参的副本 12345678910111213func main() &#123; aa := 5 paramChange(aa) fmt.Println(aa)&#125;func paramChange(num int) &#123; num = 10 fmt.Println(num)&#125;//运行后输出//10//5 即在调用的函数体中不会改变出入参数的值，这种和 java 的引用传递不同 指针可以利用 &amp; 符号获取变量的地址，即变量在内存中的地址，也称为指针 1234func paramAddress(num int) &#123; fmt.Println(&amp;num)&#125;//输出：0xc00001e098 指针类型指针类型表示为 *变量类型 ，列入指向一个 int 类型变量的指针类型是 *int，声明的指针变量也只能保存一种类型的值的指针，例如将。int 指针赋值给 float 指针会编译错误 可以利用 *指针变量 获取指针指向的值，还可以通过 * 改变指针指向的值，此处是指针（内存地址）不变，但是该内存处的值被改变，所有引用该内存地址的变量的值都会被改变。这里可以做到在上述函数参数传递中改变原参数的值 1234567891011121314func paramPoint() &#123; var myInt = 10 myIntPointer := &amp;myInt fmt.Println(myIntPointer) fmt.Println(*myIntPointer) //输出 10 *myIntPointer = 20 fmt.Println(*myIntPointer) //输出 20 fmt.Println(myInt) // 输出 20 var myFloat float64 var myFloatPointer *float64 myFloatPointer = &amp;myFloat fmt.Println(myFloatPointer) //myFloatPointer = &amp;myInt，编译异常&#125; 函数指针1234567891011func main() &#123; aa := 5 fmt.Println(*funcPoint(&amp;aa)) //输出 50 fmt.Println(aa) //输出 10&#125;func funcPoint(numPoint *int) *int &#123; var result = *numPoint * 10 *numPoint = 10 return &amp;result&#125; 数组var 变量名 [数组大小]数据类型{字面量}，与变量一样，数组在创建时会给数组中每一项初始化为对应数据类型的零值 123456789101112131415161718var ageArray [2]intageArray[1] = 15fmt.Println(ageArray[0]) //输出：0var nameArray = [2]string&#123;\"aa\", \"bb\"&#125;fmt.Println(nameArray[0]) //输出：aafmt.Printf(\"%#v\\n\", nameArray) //输出：[2]string&#123;\"aa\", \"bb\"&#125;for i := 0; i &lt; len(nameArray); i++ &#123; fmt.Print(nameArray[i], \"--\")&#125;for index, value := range nameArray &#123; fmt.Println(index, \"---\", value)&#125;for _, value := range nameArray &#123; fmt.Println(value)&#125; 使用for ... range 遍历数组，index 保存了索引，value 保存了值；这种方式不会引起无效数组的访问，当下文代码块不需要使用index 或者 value 时，可以用_空白标识符。 切片var 变量名 []数据类型{字面量}，与数组不同的是切片在声明时，不指定大小。声明切片变量不会创建初始化该切片，一般使用内建函数 make() 来创建切片。 123456789101112131415161718var mySlice = []int&#123;1, 2, 3&#125;notes := make([]string, 10, 20) //10表示切片初识大小，20表示切片的初识容量。当切片追加元素个数超过20时会进行容量扩容，扩为原来的 2 倍，即 40notes[0] = \"a\"notes[1] = \"b\"fmt.Println(mySlice) //[1 2 3]fmt.Println(notes) //[a b ]var myArray = []int&#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;sliceArray := myArray[1:5] //切片截取fmt.Println(sliceArray) //[2 3 4 5]sliceArray = append(sliceArray, 11, 12, 13)fmt.Println(sliceArray) // [2 3 4 5 11 12 13]sliceArray = append(sliceArray, 11, 12, 13)fmt.Println(sliceArray) // [2 3 4 5 11 12 13]newSlice := append(mySlice, 4, 5, 6)fmt.Println(mySlice) //[1 2 3]fmt.Println(newSlice) //[1 2 3 4 5 6] 通过数据创建的切片，切片是底层数组内容的视图，对于数组的修改会反映给所有的切片 Go 通过内建函数 append() 在一个切片尾部追加一个或者多个值，返回包含了老元素与新元素的新切片。切片的底层数组不能增长大小，如果在尾部添加元素数组空间不够时，会自动开辟新的空间将所有元素拷贝过来，返回新的切片指向地址。所以一般要用原切片变量接收 append() 函数的返回值，或者用其他变量接收。 切片变量的零值nil。 可变长函数参数123func paramFun(paramOne string, paramTwo ...string) &#123;&#125; 函数可以同时设置一个或者多个可变长参数，仅函数定义的最后一个参数可以是可变长 映射var 变量名 map[键数据类型]值数据类型{字面量}，与切片相同，声明映射变量不会初始化创建映射变量 ，需要调用 make() 函数。 123var myMap map[string]intmyMap = make(map[string]int, 10) //10：初识容量initMap := map[string]int&#123;\"a\": 1, \"b\": 2&#125; 零值映射变量的零值是 nil，初始化后的映射访问一个不存在的键时，得到零值时对应数据类型的零值。这种情况会造成无法判断该舰是已经存在于 map 中（不存在或者已经存在键值就是默认值） 12value, ok := initMap[\"a\"]delete(initMap, \"b\") 此时解决这个问题，在访问键值时返回了两个参数，第一个时该键对应的值，第二个时布尔值，键存在返回 true，不存在返回 false map 和切片在作为函数参数传递时是引用传递，不同于其他类型的值传递 struct 结构体可以定义 struct 的变量，也可以定义 struct 的类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport \"fmt\"var myParamStruct struct&#123; name string age int schoolName string grade float64 gender bool //true:男，false：女&#125;type myTypeStruct struct &#123; name string age int schoolName string grade float64 gender bool //true:男，false：女 family //内嵌 struct，此时可以直接在myTypeStruct中使用 family 中的属性，匿名字段；当然也可以定义变量名来访问&#125;type family struct &#123; father string mather string&#125;func main() &#123; myParamStruct.name = \"zcy\" myParamStruct.age = 22 myParamStruct.schoolName = \"小学\" myParamStruct.grade = 12.33 myParamStruct.gender = true fmt.Println(myParamStruct) var studentOne myTypeStruct studentOne.name = \"李四\" studentOne.age = 21 studentOne.schoolName = \"小学\" studentOne.grade = 32.33 studentOne.gender = false fmt.Println(studentOne) changeAge(studentOne) fmt.Println(studentOne) modifyStudent(&amp;studentOne) fmt.Println(studentOne) fmt.Println((*&amp;studentOne).name) studentTwo := myTypeStruct&#123; //使用短变量和字面量初始化创建struct类型变量 name: \"赵六\", age: 33, grade: 33.22, schoolName: \"aa\", gender: true, &#125; studentTwo.father = \"AA\" studentTwo.mather = \"BB\" fmt.Println(studentTwo)&#125;func changeAge(student myTypeStruct) &#123; student.age++ fmt.Println(student)&#125;func modifyStudent(student *myTypeStruct) &#123; student.name = \"李四-王五\" fmt.Println(student)&#125; 在函数的参数中使用 struct 类型，如果是指针访问其中的字段注意格式：(*指针变量).fieldName，“&amp;变量”表示指向了变量的地址即指针，“*指针变量”中 * 相当于指针运算符可以获取指针指向的值；通常可以省略 *，直接通过指针访问属性字段 如果要在其他的包中使用定义的 struct，则类型名称和对应需要导出的字段名称首字母都要大写 定义类型基础类型定义123456type MyType stringtype StrName stringvar strName StrNamestrName = StrName(\"zcc\")typeTest := MyType(\"aaa\") 可以把任何基础类型的值转换为定义的类型 定义方法12345678func (m MyType) typeMethod() &#123; fmt.Println(&quot;hello &quot;, m)&#125;value :&#x3D; MyType(&quot;zcy&quot;)value.typeMethod() &#x2F;&#x2F;输出：hello zcyvalueTwo :&#x3D; MyType(&quot;lisi&quot;)valueTwo.typeMethod() 输出：hello li si func (接收器参数名 接收器类型) typeMethod() {} 方法定义是在函数名称前增加一个接收器参数类型和接收器参数名，一个方法被定义了某个类型后，可以被这个类型创建的所有变量调用。类似于其他语言中的 this 或 self 关键字(可隐式使用)，但在 Go 中是显式声明调用。几点要求： 接收器参数名一般使用接收器类型名称的首字母小写 方法和接收器参数类型必须要定义在同一个包中，不能跨包定义。确保了不会为一些基础数据类型定义新方法 指针类型接收器参数1234567891011func (m *MyType) typeMethodPointer() &#123; fmt.Println(&quot;hello &quot;, m)&#125;value :&#x3D; MyType(&quot;zcy&quot;)value.typeMethod() &#x2F;&#x2F;输出：hello zcyvalueTwo :&#x3D; MyType(&quot;lisi&quot;)&amp;valueTwo.typeMethod() 输出：hello li sivalue.typeMethodPointer()(&amp;valueTwo).typeMethodPointer() 与函数参数传递类似，如果不使用指针接收器接收的是拷贝值不会改变原值。接收器参数定义时可以利用指针类型的接收器参数。在调用时可以省略显式声明指针变量调用，Go 会做自动转换，当然也可以定义指针变量调用，但是代码中应该保持风格统一 封装嵌入自定义类型后，内部数据并不想让包外程序直接访问到，破坏内部封闭原则。需要将部分数据封装，提供统一的对外访问方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package calendarimport ( \"errors\" \"fmt\")type Date struct &#123; year int month int day int&#125;func (d *Date) SetDate(year int, month int, day int) error &#123; err := d.SetDay(day) if err != nil &#123; return err &#125; err = d.SetMonth(month) if err != nil &#123; return err &#125; err = d.SetYear(year) if err != nil &#123; return err &#125; return nil&#125;func (d *Date) SetYear(year int) error &#123; if year &lt; 1 &#123; return errors.New(\"输入年无效\") &#125; d.year = year return nil&#125;func (d *Date) SetMonth(month int) error &#123; if month &lt; 1 || month &gt; 12 &#123; return errors.New(\"输入月份无效\") &#125; d.month = month return nil&#125;func (d *Date) SetDay(day int) error &#123; if day &lt; 1 || day &gt; 31 &#123; return errors.New(\"输入天数无效\") &#125; d.day = day return nil&#125;func (d *Date) Year() int &#123; return d.year&#125;func (d *Date) Month() int &#123; return d.month&#125;func (d *Date) Day() int &#123; return d.day&#125;func (d *Date) Display() &#123; fmt.Println(*d)&#125; 例如上述代码如果 Date 的属性是可以导出的，则会破坏数据的有效性校验。未导出的变量、struct字段、函数、方法、等仍然能够被相同包的导出的函数或方法访问。Go 的未导出数据是包内可见，所以要做到包内数据安全。 1234567891011121314151617181920212223242526package mainimport ( \"HeadFirstGo/src/chapterEight/calendar\" \"fmt\" \"log\")func main() &#123; date := calendar.Date&#123;&#125; err := date.SetDate(2021, 8, 10) if err != nil &#123; log.Fatal(err) &#125; date.Display() event := calendar.Event&#123;&#125; event.Title = \"测试标题\" err = event.SetDate(2, 3, 5) if err != nil &#123; log.Fatal(err) &#125; fmt.Println(event.Year(), event.Month(), event.Day()) event.DisplayEvent()&#125; 这里也可以定义 get 方法输出封装的属性值，一般情况下使用属性字段名首字母大写来定义 get 方法名，不是 Get 开头。 123456789101112131415package calendarimport \"fmt\"type Event struct &#123; Title string Date //嵌入匿名Date类型，Event可以拥有 Date 属性字段&#125;//这里体现了包内非导出数据的可见性var eventTest = Event&#123;\"aa\", Date&#123;1, 2, 4&#125;&#125;func (e Event) DisplayEvent() &#123; fmt.Println(eventTest)&#125; 接口类型123type 类型名称 interface &#123; 接口名称(传递参数) 返参&#125; 接口是特定类型具有的一组方法，一个类型完全拥有了接口定义的所有方法称为满足接口，然后可以通过该类型使用该类型满足的所有接口。这里比较拗口，相当于这个类型要完全实现这个接口。 类型中的方法名、参数类型、返回值必须都和接口定义一样，类型可以有其他的方法，但是不能比接口定义中的少，否则就不满足那个接口。当类型的方法比接口定义多时，在调用时，如果类型参数被声明为接口类型，则不能调用。 1234567891011121314151617181920212223242526272829303132type MyInterface interface &#123; PlayMusic() MusicName()&#125;type Piano struct &#123; Name string&#125;func (p Piano) PlayMusic() &#123; fmt.Println(p.Name, \"演奏钢琴曲\")&#125;func (p Piano) MusicName() &#123; fmt.Println(\"我是钢琴\")&#125;func (p Piano) Other() &#123; fmt.Println(\"钢琴可以演奏其他的吗？\")&#125;func main() &#123; var piano music.MyInterface = music.Piano&#123;Name: \"钢琴\"&#125; piano.MusicName() piano.PlayMusic() //piano.Other() 编译错误 //使用类型断言获取类型具体的值，ok 表示类型断言是否成功 pianoType, ok := piano.(music.Piano) if ok &#123; pianoType.Other() //这样可以调用类型自己的方法 &#125;&#125; 如果定义了一个不需要任何方法的接口，type AnyThing interface{} 它会被任何类型满足。 goroutine 和 channelgoroutine 实现 Go 程序的并发执行，main 函数的执行也是启动一个 goroutine 123456789101112131415161718func main() &#123; go playA() go playB() time.Sleep(1 * time.Second) fmt.Println(\"执行完毕\")&#125;func playA() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(\"A\", i) &#125;&#125;func playB() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(\"B\", i) &#125;&#125; channelgoroutine 之间的通信通道，使用内建 make() 函数来创建 channel 变量：myChannel := make(chan float64, 3)，3 表示创建缓冲区的大小，此时只有缓冲区被填满时继续发送会产生阻塞。 当前有 goroutine A 通过channel C 向 goroutine B发送数据：当 A 开始发送数据到 C 后，A 的执行就会被阻塞，B 开始接收数据时，B的执行也会被阻塞，当 B 处理完成后通过 C 发送数据，A 完成接收，A 和 B 继续执行后面的程序。 123456789101112131415161718192021222324func abcPlay(channel chan string) &#123; channel &lt;- \"a\" channel &lt;- \"b\" channel &lt;- \"c\"&#125;func defPlay(channel chan string) &#123; channel &lt;- \"d\" channel &lt;- \"e\" channel &lt;- \"f\"&#125;func channelPlay() &#123; c1 := make(chan string) //创建两个channel使得交替打印 adbecf c2 := make(chan string) go abcPlay(c1) //分别启动两个 goroutine go defPlay(c2) fmt.Println(&lt;-c1) //阻塞，等到abcPlay处理完成输出c1发送回来的值 fmt.Println(&lt;-c2) //这里可以看出来c1和c2在交替阻塞主 goroutine 的执行，否则 fmt.Println(&lt;-c1) //程序就不会始终按照 adbecf 的顺序来打印了 fmt.Println(&lt;-c2) fmt.Println(&lt;-c1) fmt.Println(&lt;-c2)&#125; 特性 Tipsdeferdefer 代码 defer 关键字确保函数调用发生，即使函数因为异常提前退出。延迟函数或者方法的调用，当程序出现 panic 异常奔溃时，延迟的函数仍然会被调用，多个延迟调用函数时，延迟函数执行的顺序与被延迟的顺序(代码顺序)相反(入栈出栈)。defer 是在当前函数生命周期结束后调用。如果函数正常执行结束，也是先执行 return 语句，在执行 defer 语句。 recover()内置的 recover() 函数阻止程序奔溃，只返回 nil。可以在可能引发函数奔溃的代码之前延迟调用。但是一般不直接 defer recover() 声明调用，可以包装为其他函数。这样可以保证程序能正常执行完。 12345678func freakOut() &#123; defer calmDown() panic(\"程序奔溃\")&#125;func calmDown() &#123; recover()&#125; 函数作为类型1234567891011121314151617func viewHandler(writer http.ResponseWriter, request *http.Request) &#123; message := []byte(\"hello web!\") _, err := writer.Write(message) if err != nil &#123; log.Fatal(err) &#125;&#125;func main() &#123; http.HandleFunc(\"/hello\", viewHandler) err := http.ListenAndServe(\"localhost:8080\", nil) log.Fatal(err)&#125;var myFunc func(http.ResponseWriter, *http.Request) //定义函数类型，如果函数有返参，这里也需要声明myFunc = viewHandler //将函数赋值给函数变量，注意这里不能带有 () 括号myFunc(nil, nil) //函数类型变量后面带上 () 表示执行函数调用 函数类型变量也可以作为函数或者方法的参数传递，但是这里要注意参数声明必须要和传递函数的参数数量、类型、返参数量、返参类型相同。","tags":[{"name":"Go","slug":"Go","permalink":"https://zcy-fover.github.io/tags/Go/"}]},{"title":"数据结构和算法/数据结构与算法之美/12.二叉树-下","date":"2020-07-20T13:59:58.860Z","path":"2020/07/20/数据结构和算法/数据结构与算法之美/12.二叉树-下/","text":"二叉树二叉查找树支持数据的快速查找、插入、删除，二叉查找树要求树中的每一个节点的值都比左子节点大，比右子节点小。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"二叉树","slug":"二叉树","permalink":"https://zcy-fover.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"java/Thread/thread","date":"2020-06-27T08:06:19.339Z","path":"2020/06/27/java/Thread/thread/","text":"线程线程的状态new 就绪 阻塞 运行 结束 start 和 run 的区别 Thread.start() 启动新的线程，线程处于就绪（可运行）状态，线程获取到 CPU 资源之后，就执行该线程相应的 run 方法。同一个线程的 start 方法不能被重复调用。 Thread.run() 方法内容是线程体，线程具体的执行步骤。run 只是一个方法调用，可以被重复多次调用，不会开辟新的线程。 创建线程的三种方式12345678910111213141516171819202122232425262728293031323334353637public class HowToCreateThread &#123; static class MyThread extends Thread &#123; @Override public void run() &#123; System.out.println(\"extend Thread class to create thread\"); &#125; &#125; static class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(\"implement Runnable interface to create thread\"); &#125; &#125; static class MyCall implements Callable&lt;String&gt; &#123; @Override public String call() &#123; System.out.println(\"implement Callable interface to create thread\"); return \"success\"; &#125; &#125; public static void main(String[] args) &#123; new MyThread().start(); new Thread(new MyRunnable()).start(); new Thread(() -&gt; System.out.println(\"implement Runnable interface to create thread\")).start(); new Thread(new FutureTask&lt;&gt;(new MyCall())).start(); ExecutorService service = new ThreadPoolExecutor(10, 10, 1000, TimeUnit.MILLISECONDS, new SynchronousQueue&lt;&gt;()); service.execute(() -&gt; System.out.println(\"implement Runnable interface to create thread\")); service.shutdown(); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://zcy-fover.github.io/tags/Thread/"}]},{"title":"设计/分布式/01.分布式系统-概念","date":"2020-06-22T13:56:09.341Z","path":"2020/06/22/设计/分布式/01.分布式系统-概念/","text":"分布式分布式应用到很多领域中，例如存储、缓存、文件系统、锁、事务、调度任务、调度计算、中间件消息、数据采集等等。本篇主要学习分布式的概念和理论基础。 术语概念进程与线程进程是系统进行资源分配和调度的一个独立单位，是具有一定独立功能的程序关于某个数据集上的一次运行活动； 线程是进程的一个实体，能独立运行的基本单位，是 CPU 调度和分配的基本单位，线程基本拥有很少系统资源（程序计数器、寄存器和栈），可以与其他线程共享进程所拥有的资源。 并行和并发系统拥有多 CPU，当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程可以同时执行互不影响，叫做并行。 运行时间或者系统资源有限，CPU 将其划分为若干个时间段去执行，当一个线程正在执行时，其他线程处于挂起状态，当再次获取资源时继续执行，这种方式称为并发。 锁保护临界区的一种机制，再多线程场景中应用比较广泛。减少或者规避锁争用的集中策略：分拆锁、分离锁、避免共享变量缓存、使用并发容器（Amino）、使用 Immutable 数据和 ThreadLocal 中的数据。如果一个锁守护多个相互独立的状态量，通过分拆锁是每一个锁守护不同的状态量，改进可伸缩性降低每个锁被访问的频率。分拆锁对于中等竞争强度的锁能够有效的将其转换为非竞争锁，提高性能和扩展性。分拆锁被扩展为若干加锁快的集合归属于相互独立的对象，这种叫做分离锁。JDK 8 中的 ConcurrentHashMap 的实现就是使用多个锁的数组，每个锁守护自己的一部分数据，将原锁的请求分摊，以支持更好的并发性。 集群一组相互独立、通过高速网络互连的计算机，构成一个组以单一系统的模式加以管理。集群对外的表现应当和独立的服务器相同。集群的搭建也是为了提供系统的可用性和扩展性。根据担任的角色不同，集群有几种类型： 节点：系统中按照协议完成工作的一个逻辑实体，可以是执行某些工作的进程或者机器 网络：系统的数据传输通道，用来彼此通信，通信具有方向性 存储：系统中持久化数据的数据库或者文件存储服务器 搭建集群涉及到的技术： 网络层，网络互联结构、通信协议和信号技术 节点机及操作系统层高性能客户机、分层或基于微内核的操作系统 集群系统管理层：资源管理、资源调度、负载均衡、并行 IPO、安全等 应用层：并行程序开发环境、串行应用、并行应用等 无状态服务无状态，不保存存储状态，可以随意重启和替代便于做扩展。 系统重发与幂等性在做微服务设计或者 httpClient 的设计中，当一次请求出现网络或者其他失败时，有时会涉及自动重发（重试）机制。由于第一次的请求服务提供者没有明确返回业务成功与否的结果，所以当调用者有重试机制的时候，服务方应该支持幂等性设计。客户端配置重试机制时也应当充分了解服务提供者是否支持幂等性。 硬件异常服务器宕机：服务器停电、内存异常错误等，宕机时不能提供服务的节点称为不可用，服务器宕机时将丢失内部信息，所以要考虑存储系统的持久化，以便系统重启时恢复数据。 网络异常：消息丢失、网络数据包错误等 磁盘故障：区分为软件故障和硬件故障。硬件故障例如：主板 IDE 接口松动、硬件设备不兼容、电源不稳；坏道、分区表损坏病毒等。 机房级异常：当一个机房整体断点，此时对于业务可能就是毁灭性的。需要做到同城或者异地机房的灾备。 分布式理论CAP 理论提出了一致性、可用性、分区容错性的取舍问题；Paxos、Raft、2PC、3PC 给出了一致性的解决方案；Lease 主要针对网络拥堵或者瞬断情况给出双主的解决方案；Quorum NWR 和 MVCC 主要解决分布式存储领域的一致性问题；Gossip 是一种去中心化、容错而又最终一致性的算法。 CAP 理论一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否有同样的值，所有数据节点都是同一份最新的数据副本。一致性被称为原子对象，任何读写都应该看起来是原子操作或串行，后面的读一定能读到前面写的内容，所有的读写请求看起来像全局有序。 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求，对数据更新具备高可用性。对任何非失败的节点都应该在有限的时间内给出请求的响应，请求可终止性。 分区容忍性（P）：分区相当于对于通信时限的要求，在一定时间内系统不能达到数据一致性，就意味着发生了分区，此时需要在 C 和 A 之间做出选择。允许节点之间丢失任意多的消息，当发生网络分区时有可能完全丢失消息。 CA without P如果不允许 P 的情况出现，则 C 和 A 是可以保证的，但是分区情况的出现是不可控的，始终会存在。分布式系统强调的是分区出现后各子系统依然可以保持 CA。关系数据库、LDAP就是放弃了分区容忍性 CP without A不要求可用性，各个节点之间强一致，但是分区可能导致节点之间的同步时间无限延长，如此来保证 CP，传统的数据库分布式事务、分布式锁属于这种情况。 AP without C分区发生时保证高可用就需要放弃一致性，分区发生时，一些节点可能失去联系，为了高可用每个节点使用本地数据提供服务这样可能导致全局的数据不一致。或者某些节点的数据延迟或者损失，造成对外服务的数据不一致。有些微服务的注册中心就采用这种方式实现。 Paxos 协议基于消息传递一致性算法，主要解决分布式系统中在多个节点之间就某个值（提案）达成一致（决议）的通信协议。能够处理在少数节点离线的情况下剩余的多数节点仍然能够达成一致。对于协议的学习可以参考：Paxos 算法详解 或者《从Paxos到zookeeper分布式一致性原理与实践》- 倪超 一书。 2 PC 协议2 阶段提交协议， 是一种原子提交协议。有第三者协调器来处理分布式原子服务参与者是提交或者回滚事务的分布式算法。该协议的两个阶段：提交请求阶段（投票阶段）和提交阶段。 投票阶段确定各个参与者对于各自事务处理是否准备就绪，参与者发送 YES 表示可以提交，NO 表示失败。如果所有参与者都返回 YES，则进入提交阶段；如果有参与者发送 No，则协调器通知所有参与者事务中断。 提交阶段如果参与者都表示 YES 已经准备可以提交事务，此时协调者给所有参与者发送提交事务的消息，参与者接收提交事务后并发送反馈信息（ACK）；如果有参与者事务提交失败或者超时，则协调者通知所有参与者回滚，参与者完整回滚并发送确认消息（ACK）。 缺点 同步阻塞性协议，所有参与者（节点）事务阻塞，当参与者占有共有资源时，其他事务也将处于阻塞 由于协调者的重要性，当协调者故障时会导致参与者的事务处于悬挂状态 3 PC 协议由于 2 PC 协议中，当协调者故障后整个分布式事务可能就会瘫痪阻塞掉，所以在 3 PC 协议中增加了一个预提交的过程。 第一阶段，协调器询问确认参与者是否都可以提交事务，全部 YES 之后进入到预提交阶段；如果有 NO 则事务中断，协调者向参与者发消息事务中断 第二阶段，协调者向参与者发送预提交请求，各个参与者执行预提交请求并返回 ACK 响应，都成功后进入第三阶段；如果有参与者发送了 NO 或者超时，协调者向所有参与者发送 abort 中断请求，参与者执行事务中断 第三阶段，参与者在预提交全部 YES 之后，协调者通知参与者真正提交事务，参与者提交成功之后想协调者发送 ACK 响应；如果协调者没有收到参与者发送的 ACK 消息或者超时，则协调者发送 abort 请求中断事务； 如果协调者故障导致参与者等待超时或者网络原因部分参与者没有收到 doCommit 请求，由于之前已经全部执行过 preCommit 所以参与者会倾向于自己提交事务，但这也有可能造成数据不一致。 3 PC 协议在协调者和参与者都增加了超时机制，不会让事务一直处于阻塞状态，解决了单点故障导致的阻塞问题，但是也有可能造成数据不一致。 Raft 算法Raft 和 Paxos 算法都是一致性算法，在实现上稍微不同，Raft 分解为几个关键模块：领导人选举、日志复制、安全性。在 Raft 算法中任何一个服务器可以扮演三种角色之一： 领导者（Leader）：处理所有客户端交互、日志复制等动作，一般只有一个领导者 选民（Follower）：负责响应来自 Leader 或者 Candidate 的数据，被动参与选举的投票 候选人（Candidate）：Leader 的候选者，选举成功后成为 Leader 选举过程： 任何一个服务器都可以成为候选者，向其他服务器发出要求选取自己的请求，其他服务器都同意回复 OK，则该服务器成为 Leader；成为 Leader 后可以做日志复制等操作，并在每一段时间内向所有 Follower 发送 Hearbeat 保持所有节点的状态，Follower 收到 Hearbeat 后重设自己的 Timeout 时间 如果有一个选民 Follower 宕机或者失联，则只要超过半数选民同意回复 OK 即可 如果 Leader 故障，其他选民正常进行选举；如果故障 Leader 恢复，由于选举是有届数记录，旧的 Leader 自动降级为 Follower 假如出现一种竞争状态，总共四个服务器，有两个 Follower 同时发出选举请求，各获得两票支持（分别有一台回复 OK和自己的一票），要超过半数才能成为 Leader，此时共有两个 Candidate 和两个 Follower，两类节点的倒计时器还在运行，达到 Timeout 的节点重新发起选举 参考：Raft 算法 Lease 机制维护分布式系统的数据一致性，由授权者授予分布式环境一段时间内数据一致性的承诺。颁发者发出 Lease 后，不管是否被接收，只要Lease不过期，颁发者都会按照协议遵守承诺，在过期时间内不修改数据。Lease 的持有者只能在有效期内使用，一旦 Lease 过期持有者需要放弃执行重新申请 Lease。主要解决缓存和服务器之间的数据一致性问题。 已经过期的 Lease 导致读不到的问题，节点数据已经过期，但是服务器还未发布新的 Lease，此时读不到数据影响业务；解决方案：此时有服务器直接返回数据，下次再读时可能已经发布 Lease 服务器通过其他方式修改了数据要发布新的 Lease，但是各节点的 Lease 还没有到过期时间；解决方法：服务器主动通知所有节点放弃当前 Lease，接收新的 Lease 如果一次更新操作的数据对象分布在不同的节点上，对于数据 A，只要对应的节点 Lease 过期即可，对于数据 B 不影响。 脑裂问题主备模式是实现高可用（HA）系统的一种方式，但是两个节点断开联系时，一个整体分裂为两个独立节点，节点之间争抢共享资源，导致系统紊乱数据错误等。 心跳检测是判断主备服务器是否还建立链接的一个重要方式，但是心跳检测的不确定性也是导致脑裂的一个重要原因。例如：master 服务器暂时失联，slave 服务器上位开始接手工作，但是此时 master 又活过来了还在继续工作，这个就会导致两个服务器发生分裂对主备判断逻辑带来不确定因素。 此时需要引入第三方检测服务器（Monitor），当 salve 要接管 master 时，由 Monitor 再 ping 一下 master，如果确实失联在切换。此时就需要 Monitor 的高可用保障。 Quorum NWR分布式存储系统中控制一致性级别的策略。 N：同一份数据的拷贝份数 W：更新一个数据对象时确保成功更新的份数 R：读取一个对象时需要读取的拷贝份数 具体的策略是：$$W &gt; N / 2\\W + R &gt; N$$写操作要确保成功的份数应高于同一份数据拷贝总份数的一半； 写操作加上读操作的总份数也要高于同一份数据拷贝总份数 N W R 说明 1 单点问题，无法满足高可用 2 在一个节点故障后，退化为单点 3 2，3 1，2，3 读越大，写性能越差；写越大，读性能越差 4 或者更多 服务器节点成本高 MVCC多版本并发控制，一般把基于锁（行级锁）的并发控制称为悲观锁机制，MVCC 机制称为乐观锁机制。MVCC 是一种宽松的机制，读写互不阻塞。 Gossip分布式系统状态分布在集群中的各个节点上，集群的状态同步存在两个问题： 每一个节点如何较快的得知集群状态全集的某些特征 如何避免多个节点就某个状态发生分歧，是的集群的状态实时或者最终一致 Gossip 是一个去中心化思路的分布式协议，通过信息的部分传递，达到全集群的状态信息传播，传播时间收敛在 $O(log(N))$ N 是节点数量。解决状态在集群中的传播和状态一致性的保证两个问题。 状态的传播这种状态消息的传播类似于留言的传播，节点接收到消息后在传播给其他节点。每个节点起初可能只掌握整个集群的部分状态信息，通过传播达到全集状态的获取。 状态一致性同一状态信息，不同的节点掌握的值可能不同，通过基于 Gossip 构建的协议包版本进行解决。","tags":[{"name":"分布式","slug":"分布式","permalink":"https://zcy-fover.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"数据存储/缓存/Redis/Redis学习","date":"2020-06-18T13:01:38.790Z","path":"2020/06/18/数据存储/缓存/Redis/Redis学习/","text":"RedisRedis 之持久化持久化的意义在于缓存中的数据对于业务是否必要，如果数据损失是否可以通过其他数据存储方式恢复。如果需要通过 Redis 自己来恢复，这就是 Redis 持久化的意义。持久化的两种方式：快照和日志。 快照（RDB）将缓存数据序列化成二进制放到磁盘中，开机时或者恢复时从磁盘中读取二进制数据反序列化即可。利用快照数据恢复时间快，但是快照的生成间隔较大时，可能丢失很多数据。 日志（AOF）将 Redis 操作指令追加到日志文件中，数据恢复时要重新执行命令，恢复时间长。日志的级别： 每操作：没操作一次 Redis，就将操作日志刷新到日志文件中，这样做就可以报最高程度的保证操作日志的完整性，最多是写当前日志时故障，最多丢失一条操作日志。 每秒钟：将操作日志先写到系统缓冲池中，每秒钟在写到磁盘上。这种情况下最多损失一秒内一个缓冲池的日志数据。（当缓冲池满了之后系统也会自己写到磁盘上）。默认级别。 缓冲池大小：当日志缓冲池满了之后操作系统将数据写到磁盘中，这种情况下也是最多损失一个缓冲池大小数据，但是由于少了每秒钟限制，将损失扩大了。 使用早期 Redis 版本中，默认使用 RDB 做持久化，可以自己开启 AOF，但是开启 AOF 后，RDB 就失效了。优化后将两种方式混合使用，在 AOF 文件当中包含历史的 RDB，然后从当前时间再开始追加日志。这样在恢复时就是 RDB 加少量操作日志，可以快速恢复又最大保证了数据的完整性。这些配置可以在 Redis 启动的配置文件中开启。还可以在客户端使用 BGREWRITEAOF 指令重写日志文件，将日志文件压缩，消除重复的无用指令只保留最后的有效指令，例如：对同一个 key 的重复写或者读操作，只保留最后一条日志即可。如果使用了混合方式，使用该指令时就会在日志文件中生成快照，记录当前缓存的二进制数据。 Redis 的可用性单点故障如果是单机器，机器故障后业务就要瘫痪，利用主从或者主备模式来解决。主从复制两种模式比较： 强一致性主机接收到指令后先执行操作然后通知从机执行，从机执行成功后会送主机，主机通知客户端成功。这种情况下如果主从之间的通信错误导致执行失败。对于客户端导致服务不可用，这种情况下主机是可用的只是从机的同步出现错误。这种强一致性会破坏可用性。 弱一致性主机操作指令成功后返回给客户端同时异步通知从机。这种情况下就有可能会导致从机指令丢失，丢失数据。Redis 的主从复制默认运行在这种模式下。 压力、扩展性单实例机器无法达到业务性能需求，需要扩展，利用分片集群模式来扩展服务能力。进行业务拆分，利用 AKF 划分原则，通过主备保证数据恢复，将数据按照业务分开降低数据在机器上的耦合（业务上对于热点数据和冷数据的处理和性能要求可能也是不同的），同类数据分片存储提高热点数据访问对于服务器的性能要求。 分片一般情况下为了避免这两种情况，首先会搭建一个 Redis 的分片集群，然后集群中的 Redis 实例以主从形式搭建。如果是分片集群，客户端在命令发送时就需要有一个算法来讲不同的命令分配到不同的分片上。分片算法的三种实现： 客户端实现客户端维护分片集群的实例，通过自定义算法（取模等）将指令分配到不同的分片上。这种方式耦合度太高，如果集群分片增加，算法也需要修改。 代理客户端链接代理，将数据发送到代理，代理将数据发送到分片集群，分配算法由代理层实现，实现了解藕。但是分片集群更新时，代理层还是需要优化。 一致性哈希抽象出一个 m 区间的哈希环，然后利用已有的机器节点将这个环分割，机器负载落在某个分割环的一个区间，不再是直接对应到机器上。这样当某个机器故障后，只需要将这一部分数据迁移到他的临近机器上，不需要全部数据迁移。参考文章：一致性哈希 Redis 锁","tags":[{"name":"Redis","slug":"Redis","permalink":"https://zcy-fover.github.io/tags/Redis/"}]},{"title":"数据存储/MySQL/08.MySQL高可用-复制","date":"2020-06-15T13:13:09.035Z","path":"2020/06/15/数据存储/MySQL/08.MySQL高可用-复制/","text":"MySQL 高可用 - 复制“可用”就是指系统是否可用；“高”往往是一个百分比，指系统可用占比。毕竟有可能出现故障或者宕机。高可用分为计算和存储高可用。计算高可用有（主备、主从、对称集群、非对称集群）几种模式，存储高可用有（主备、主从、主备/主从切换、主主、集群、分区）几种模式。MySQL的复制功能是构建高可用应用的基础，复制也是可扩展性、灾难恢复、备份、数据仓库等工作的基础。 复制的应用数据分布：通过复制将数据分布到不同的地理位置做备份负载均衡：通过复制将读操作分布备机或者其他服务器上，实现对读密集应用的优化备份：复制也是备份的技术实现之一高可用和故障切换：复制为高可用实现技术支持，在出现故障时可以切换到备机上MySQL 升级测试：使用高版本作为备库时，保证在升级实例前查询能够在备库上按照预期执行 复制的原理 MySQL复制 在主库上把数据更改记录到二进制日志（Binary Log）中：在提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中，MySQL会按照事务提交的顺序而不是每条语句执行的顺序来记录二进制日志，在记录日志后主库通知存储引擎提交事务 备库将主库上的日志复制到自己的中继日志（relay Log）：备库上启动工作线程（I/O线程），与主库建立客户端连接。然后在主库上启动一个二进制转储线程（该线程没有对应的 SQL 命令），二进制转储线程会读取主库上的二进制日志中的事件，不对事件进行轮询处理。如果转储线程进度追赶上主库的更新速度，他将进入睡眠状态，直到主库发送信号量通知转储线程有新的二进制日志产生，转储线程会继续工作。I/O 线程将接收到的二进制日志写入到备库的中继日志中 备库读取中继日志中的事件，将其重放到备库数据库上：备库 SQL 线程读取中继日志中的事件并在备库上执行，实现备库的数据更新。当 SQL 线程追赶上 I/O 线程，中继日志已经在系统缓存中，此时开销就比较低。SQL 线程也可以通过配置决定是否将操作日志写到自己的二进制日志中 复制实现方式基于语句的复制基于语句复制也称为逻辑复制，在这种模式下主库会记录造成数据更改的 SQL，备库会读取并重放这些事件（重新执行主主库记录的 SQL）。 优点 记录和执行都比较简单 二进制事件更加紧凑 基于语句的模式占用带宽较小 缺点 主库数据的更新，除了 SQL 语句，可能还有其他因素。例如：使用了时间戳函数可能导致主备库插入的时间不一样；使用了 CURRENT_USER() 函数等 更新必须是串行的，需要加锁来处理 基于行的复制将实际数据记录在二进制日志中 优点 记录实际数据可以保证主备的数据是一致的 备库无需重放主库的查询语句，例如下面语句，如果使用基于语句复制则会导致备库也有很大开销 1INSERT INTO TEST_TABLE(col1, col2, col3) SELECT col1, col2, sum(col3) FROM table2 GROUP BY col1, col2; 缺点 有导致全表记录修改的 SQL，此时主库的日志记录和备库的数据复制开销都很大 基于行复制时，如果需要进行时间点恢复比较困难 这两种模式都不是完美的，MySQL 可以在两种模式下切换，默认是基于语句的复制，当发现语句不能被正确复制时使用基于行的复制。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"高可用","slug":"高可用","permalink":"https://zcy-fover.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"}]},{"title":"数据存储/缓存/Redis/Linux编译安装Redis","date":"2020-06-07T13:28:50.858Z","path":"2020/06/07/数据存储/缓存/Redis/Linux编译安装Redis/","text":"Redis 编译安装下载解压在要安装的目录下下载后解压缩 12wget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-6.0.4.tar.gztar xzf redis-6.0.4.tar.gz make 编译进入解压后的目录 redis-6.0.4，输入 make 回车，出现：cc: Command not fund ，是因为系统中没有安装 GCC 编译器。 GCC版本低 安装 GCC输入命令安装 GCC 编译器 1yum install gcc 再次 make 时，出现 In file included from adlist.c:34:0:、zmalloc.h:50:31: fatal error: jemalloc/jemalloc.h: No such file or directory、compilation termianted 错误 错误文件 是因为之前的编译的缓存文件存在，执行 1make distclean 升级 GCC再次 make，由于 GCC 版本过低可能会出现 server.c:5166...、[server.o] Error 1、Leaving directory &#39;/root/redis/redis-6.0.4/src&#39; 错误 GCC版本过低错误 升级 GCC 的版本 12345yum -y install centos-release-sclyum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils# 设置改版本为默认echo &quot;source &#x2F;opt&#x2F;rh&#x2F;devtoolset-9&#x2F;enable&quot; &gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 升级好之后执行 make distclean 和 make 命令，编译成功。此时编译好之后在 src 目录下已经生成了可执行的 redis-server 和 redis-cli 服务，但是我们把它安装在特定的文件夹中和源码区分开。 安装1make PREFIX&#x3D;&#x2F;root&#x2F;tools&#x2F;redis install PREFIX 是将 Redis 服务安装在这个文件夹下面。就是将生成的服务拷贝到这个文件夹下面。 配置Redis 服务快捷访问vi /etc/profile 增加 12export REDIS_HOME&#x3D;&#x2F;root&#x2F;tools&#x2F;redisexport PATH&#x3D;$PATH:$REDIS_HOME&#x2F;bin 退出保存后，利用 source /etc/profile 重新在当前 bash 加载文件中的命令。使得可以在任意路径执行 Redis 的服务。 配置 Redis 服务进入到源码文件夹中的 utils 文件夹。执行 ./install_server.sh 服务配置错误","tags":[{"name":"Redis","slug":"Redis","permalink":"https://zcy-fover.github.io/tags/Redis/"},{"name":"Redis编译","slug":"Redis编译","permalink":"https://zcy-fover.github.io/tags/Redis%E7%BC%96%E8%AF%91/"}]},{"title":"java/jvm/5.GC 垃圾收集","date":"2020-06-07T02:52:23.875Z","path":"2020/06/07/java/jvm/5.GC 垃圾收集/","text":"GC 垃圾收集主要介绍垃圾收集的方法论以及虚拟机根据方法论具体是实现的垃圾收集器。 垃圾收集算法判断对象已死之后如何把这些对象收集起来并且回收掉，主要的算法有标记-清除、复制、标记-整理、分代收集。 标记-清除算法标记出所有需要回收的对象，标记完成后统一回收。如何标记在可达性分析中有讲。 缺点 效率问题，标记和清除的过程效率都不高 空间问题，清除之后会产生大量的空间碎片，空间碎片过多导致以后在运行过程中如果要给大对象分配内存空间还是空间不足，可能会再次触发 GC。 复制算法将内存分为两块，其中一块内存用完之后，将还存活的对象复制到另一块，然后将当前内存一次清理掉。这样每次都是半块内存一起回收，不需要考虑内存碎片等。 缺点 只有一半内存在使用，降低了内存的使用率 改进版本是将内存分为 Eden 空间和两块较小的 Survivor 空间，配置比例 $8:1:1$，每次使用 Eden 和一块 Survivor 空间，当需要内存回收时，将还存活对象一次性复制到另一块 Survivor 空间，但是另一块 Survivor 空间不足时需要其他的内存控件来做担保，保证全部存活对象得以复制。 标记-整理算法复制算法对于存活对象较少的新生代效果较好，如果是老年代内存回收需要转移复制的对象过多可能会降低效率。标记-整理算法是将所有存活的对象向一端移动，然后清理掉边界以外的内存。 分代收集算法一般对象存活周期将内存分为新生代和老年代，新生代每次垃圾收集时都有大量对象失效，可以选用复制算法；老年代没有其他内存空间作担保、对象存活率也高适用标记-整理算法来回收。 垃圾收集器垃圾收集算法是垃圾收集的方法论，垃圾收集器是内存回收的具体实现。 Serial 收集器Serial 收集器是最基本、发展历史最悠久的收集器。 特点 主要针对新生代内存，采用复制算法 单线程收集，必须暂停其他的工作线程 没有线程间的切换开销，获得单线程的最高收集效率，简单而高效 应用 虚拟机在 Client 模式下的默认新生代收集器 配置参数-XX:+UseSerialGC 是一个“单线程”的收集器，这个“单线程”的意义是当收集器工作时必须暂停其他的工作线程，直到收集结束。这样的优点就是收集器没有线程交互的开销，只做垃圾收集简单而高效。 Serial Old 收集器Serial 收集器的老年底版本，也是单线程收集，采用标记-整理算法。 应用 在 JDK 1.5 之前版本中与 PS MarkSweep 收集器（类似 SerialOld收集器）搭配使用 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用 ParNew 收集器Serial 收集器的多线程版本，会有多个收集线程一起工作。如果是在单 CPU 的环境中， ParNew 的效率是不如 Serial 收集器，因为存在线程交互的开销。但如果增加了 CPU 数量 ParNew 的效果会更好。 特点 新生代收集器，采用复制算法 多收集线程并行工作，需要暂停其他用户工作线程 应用 当老年代选择 CMS 收集器后，新生代只能选用 ParNew 收集器或者 Serial 收集器，即老年代配置了 -XX:+UseConcMarkSweepGC 后，ParNew 是默认的新生代收集器。 运行在 Server 模式下的虚拟机的中首选的新生代收集器 配置参数 -XX:+UseParNewGC -XX:ParallelGCThreads：限制垃圾收集的线程数 Parallel Scavenge 收集器特点 新生代收集器，采用复制算法 多线程并行收集 达到可控制的吞吐量（吞吐量=用户运行代码时间 / (用户运行代码时间 + 垃圾收集时间)） 应用高吞吐量可以高效的利用 CPU 时间，尽快完成运算任务，适合在后台运算不需要太多交互的任务 配置参数 -XX:+UseParallelGC -XX:MaxGCPauseMillis：最大垃圾收集停顿时间，大于 0 的毫秒数，收集器尽可能的保证收集时间不超过该值 -XX:GCTimeRatio：可直接设置吞吐量大小，大于 0 小于 100 的整数，垃圾收集时间占总时间的比率，默认值是 99，即最大允许 1%（1 / (1 + 99)）的垃圾回收时间 -XX:UseAdaptiveSizePolicy：开关参数，打开后就不需要手动指定新生代（-Xmn）、Eden、Survivor（-XX:SurvivorRatio） 、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大吞吐量，称为 GC 自适应调节策略。 Parallel Old 收集器Parallel Scavenge 收集器的老年代版本 特点 使用标记-整理算法，适用于老年代 多线程并行收集 应用在注重吞吐量以及 CPU 资源敏感的场合，可以选用 Parallel Scavenge + Parallel Old 收集器的组合。 配置参数-XX:+UseParallelOldGC CMS 收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。适用于老年代。 步骤 初始标记（CMS initial mark）：需要暂停用户线程，标记 GC Roots 能直接关联到的对象，速度很快 并发标记（CMS concurrent mark）：GC Roots Tracing 的过程，与用户线程一起工作 重新标记（CMS remark）：需要暂停用户线程，修正并发标记期间因为用户线程继续运行导致标记产生变动的那一部分记录，停顿时间比初始标记时间稍长，但是比并发标记时间短 并发清除（CMS concurrent sweep）：与用户线程一起工作 特点 并发收集、用户线程停顿时间短 使用标记-清除算法 缺点 由于并发收集，用户线程也可以并发执行，所以对 CPU 资源敏感。如果 CPU 资源较少，那收集线程对于用户线程的资源影响就会比较大 无法处理浮动垃圾，在并发清理阶段，用户线程还是继续运行这个阶段产生的垃圾只能等待下一次垃圾回收来处理。因为清理阶段用户线程还在运行，所以 CMS 收集器不是等待老年代快被填满之后再收集，需要留一部分在并发收集时给用户线程使用，可以调节参数 -XX:CMSInitiatingOccupancyFraction 来配置触发百分比，JDK 1.5 默认是 68% 触发收集，JDK 1.6 阈值提升到 92%。如果在 CMS 运行期间，如果预留的内存不满足程序运行需要，会出现 Concurrent Mode Failure 错误，虚拟机会临时启用 Serial Old 收集器来进行老年代回收，这样停顿时间会更长。 由于使用标记-清除算法，会产生大量内存碎片。CMS 提供 -XX:UseCMSCompactAtFullCollection 开关参数（默认开启）在 CMS 收集器要进行 Full GC 时开启内存碎片合并整理过程。内存整理无法并发进行，所以会导致停顿时间变长。可以利用 -XX:CMSFullGCsBeforeCompaction 参数配置在进行过几次无内存整理的 Full GC 后进行一次有压缩整理的 Full GC。 应用 CMS 收集器作为老年代收集器时，ParNew 收集器是默认的新生代收集器 CMS 的停顿时间短，适合于重视响应速度的互联网或者 B/S 系统的服务端 配置参数-XX:+UseConcMarkSweepGC G1 收集器G1（Garbage First）收集器，注重低延迟，面向服务端应用的垃圾收集器。 特点 并行与并发：利用多 CPU 来缩短停顿时间，通过并发让其他 Java 程序继续执行 分代收集：不需要其他收集器配合可以独立管理内存，采用不同的方式处理新创建对象、存活一段时间对象、经过几次 GC 后依然存活的对象 空间整合：G1 整体上看是采用标记-整理算法实现，从局部（Region之间）是采用复制算法来处理，这样保证 G1 运行期间不会产生内存碎片 可预测的停顿：建立可预测的停顿时间模型，让使用者明确指定一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间的不得超过 N 毫秒 内存分区：G1 采用内存分区的思路将内存划分为大小相等的分区，以区为单位进行回收，将存活的对象复制到另一个空闲分区，可以通过 -XX:G1HeapRegionSize 配置分区的大小（1~32M） 混合收集：G1 的收集也是 Stop-The-World 的，但是年轻代和老年代的界限比较模糊，采用了混合收集的模式，收集时根据分区，不针对是否是老年代或者新生代，可以混合收集 步骤 初始标记（Initial Mark）：标记 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top At Mark Start）的值，让下一阶段用户程序并发运行时能从正确可用 Region 去创建新对象。这个阶段需要暂停用户线程，时间较短 并发标记（Concurrent Mark）：从 GC Roots 开始对堆中的对象进行可达性分析，找出存活的对象，耗时较长。可与用户程序并发执行。 最终标记（Final Mark）：修正在并发标记期间用户线程继续运行导致标记产生变动的一部分标记记录，需要暂停用户线程但是可以并行执行。 筛选回收（Live Data Counting and Evacuation）：首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间定制回收计划。用户线程也可并发执行，但是只回收一部分 Region，时间是用户可控，暂停用户线程可以提高收集效率 GC 日志[Full GC (System.gc()) [Tenured: 71680K-&gt;72762K(172032K), 0.0326327 secs] 86171K-&gt;72762K(201536K), [Metaspace: 3515K-&gt;3515K(1056768K)], 0.0527461 secs] [Times: user=0.02 sys=0.00, real=0.05 secs] [GC (Allocation Failure) [DefNew: 0K-&gt;0K(29504K), 0.0013389 secs][Tenured: 72762K-&gt;72762K(172032K), 0.0051454 secs] 72762K-&gt;72762K(201536K), [Metaspace: 3515K-&gt;3515K(1056768K)], 0.0065562 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (Allocation Failure) [TenuredException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.zcyfover.util.gc.GcMainTest.main(GcMainTest.java:30) : 72762K-&gt;72742K(172032K), 0.0053641 secs] 72762K-&gt;72742K(201536K), [Metaspace: 3515K-&gt;3515K(1056768K)], 0.0054030 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] GC、Full GC：表示垃圾收集的停顿类型，有 “Full” 表示发生了 Stop-The-World (System.gc())：表示通过 “System.gc()” 来触发的 GC Tenured、DefNew、Metaspace：表示 GC 发生的内存区域，这个名字由收集器决定，例如还有 PSYoungGen等 71680K-&gt;72762K(172032K)：回收前该区域已使用容量，回收后该区域已使用容量，该内存区域总容量 86171K-&gt;72762K(201536K)：在方括号之外的表示堆，GC 前堆已使用容量，GC 后堆已使用容量，堆总容量 0.0326327 secs：该内存区域 GC 所占用的时间，单位是秒 Times: user=0.02 sys=0.00, real=0.05 secs：分别表示 用户态消耗的 CPU 时间，内核态消耗的 CPU 时间，操作从开始到结束所经过的墙钟时间（Wall Clock Time） 墙钟时间：非运算的等待耗时，例如磁盘等待 I/O、等待线程阻塞时间等 垃圾回收常用参数 参数 描述 UseSerialGC 虚拟机运行在 Client 模式下的默认值，打开此开关后，使用 Serial + SerialOld 收集器组合进行回收 UseParNewGC 打开此开关后使用 ParNew + SerialOld 收集器组合进行回收 UseConcMarkSweepGC 使用 ParNew + CMS + SerialOld 收集器组合进行回收，SerialOld 收集器是当 CMS 出现 Concurrent Mode Failure 失败后的后备收集器 UseParallelGC 虚拟机在 server 模式下的默认值，使用 ParallelScavenge + SerialOld（PS Mark Sweep） 收集器组合进行回收 UseParallelOldGC 使用 ParallelScavenge + ParallelOld 收集器组合收集 UseG1GC 打开开关后，可以独立进行 GC，不需要其他收集器配合 SurvivorRatio 新生代中 Eden 和 Survivor 区域的内存分配比例，默认为 8，Eden : Survivor = 8 : 1 PretenureSizeThreshold 直接晋升到老年代的对象大小，设置这个参数后，需要占用内存大于这个参数的对象直接在老年代中分配内存 MaxTenuringThreshold 晋升到老年代的对象年龄，每个对象在经过一次 Minor GC 后年龄就增加 1，达到这个年龄后就会进入老年代 UseAdaptiveSizePolicy 动态调整 java 堆中各个区域的大小以及进入老年代的年龄 HandlePromotionFailure 是否允许分配担保失败，及老年代的剩余空间不足以应付 Eden 和 Survivor 区域所有存活对象 ParallelGCThreads 设置并行 GC 时进行内存回收的线程数 GCTimeRatio GC 时间占总时间的比率，默认值 99，即允许 1%的 GC 时间，仅在使用 ParallelScavenge 收集器时生效 MaxGCPauseMillis 设置 GC 的最大停顿时间，仅在使用 ParallelScavenge 收集器时生效 CMSInitiatingOccupancyFraction 设置 CMS 收集器在老年代空间被使用多少后触发垃圾收集，默认值为 68%，仅在使用 CMS 收集器时生效 UseCMSCompactAtFullCollection 设置 CMS 收集器在完成垃圾收集后是否要进行一次内存碎片整理，仅在使用 CMS 收集器时生效 CMSFullGCsBeforeCompaction 设置 CMS 收集器在完成若干次垃圾收集器后在启动一次内存碎片整理，，仅在使用 CMS 收集器时生效","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://zcy-fover.github.io/tags/GC/"}]},{"title":"java/jvm/3.JVM-类加载过程","date":"2020-05-26T14:45:37.622Z","path":"2020/05/26/java/jvm/3.JVM-类加载过程/","text":"类加载过程java 文件经过编译后生成了 class 文件，类加载器的工作对象就是 class 文件，将 class 文件从其他位置加载到 JVM 内存中。类从加载到虚拟机到卸载出内存整个生命周期包括：加载、验证、准备、解析、初始化、使用、卸载七个过程。其中验证、准备、解析三个步骤统称为链接。 类加载过程 加载、验证、准备、初始化、卸载这 5 个过程是按顺序开始即可(不一定等上一步骤结束)。解析阶段有可能在初始化之后，这是为了支持 Java 语言的运行时绑定特性。 加载加载时虚拟机的工作： 通过一个类的全限定名来获取定义此类的二进制字节流 将字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 虚拟机获取字节流的方式： 本地磁盘中的 class 文件中获取 从 ZIP 包中获取，例如JAR、WAR、EAR等 从网络中读取 运行时计算生成，例如动态代理技术，利用 sun.misc.ProxyGenerator#generateProxyClass 为特定接口生成代理类的二进制字节流 由其他文件生成，例如 JSP 应用 从数据库中读取 对于数组类的加载，由虚拟机直接创建，但是数组的元素类型最终还是靠类加载器来加载。数组创建遵循的原则： 如果数组的组件类型（去掉一个维度的类型）是引用类型，则递归加载过程来创建，数组也在加载该组件类型的类加载器的类名称空间上被标识。 数组的组件类型不是引用类型（基本数据类型，例如 int[]），虚拟机会将数组标记为与引导类加载关联。 数组类的可见性与引用类型的可见性一致，如果组件类型不是引用类型，那数组类的可见性将默认为 public。 验证class 文件可以有多种生成方式，生成的文件是否完全符合 class 文件规范。验证是为了尽量保证虚拟机的安全，避免错误的字节流导致虚拟机奔溃。如果验证到字节流不符合规范虚拟机会抛出 java.lang.VerifyError 异常。验证大致会完成四个阶段的校验： 文件格式校验验证字节流是否符合 class 文件规范，保证输入的字节流能正确解析并且存储在方法区。 元数据验证对字节码描述的信息进行语义分析，保证描述信息符合 Java 语言规范。包括：该类是否有父类、父类是否继承了被 final 修饰的类、该类不是抽象类是否实现了其父类或者接口中的所有方法、类中的方法和字段是否与父类冲突等。 字节码验证通过数据流和控制流分析确保程序语义合法、符合逻辑。保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，例如： 保证任意时刻操作数栈数据类型与指令序列能够匹配工作，避免出现操作数栈的 int 数据类型被按照 long 类型指令加载入本地变量表 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的 符号引用验证这个验证是在加载过程的解析阶段将符号引用转化为直接引用时发生。符号引用校验是对类自身外（常量池的符号引用）的信息进行匹配性校验： 符号引用通过字符串描述的全限定名是否可以找到对应的类 指定类中是否存在符合方法的字段描述符和简单名称所描述的方法、字段 符号引用中的类、字段、方法的访问性是否可以被当前类访问 符号引用验证确保解析动作能正常执行，如果符号引用验证失败将会抛出 java.lang.IncompatibleClassChangeError 异常的子类，如：java.lang.IllegalAccessError、java.lang.NoSuchFieldError、java.langNoSuchMethodError等。 验证对于虚拟机是重要但是不必要的阶段，如果对于运行的 class 文件都反复使用和验证过，可以使用 -Xverify:none 来关闭验证。 准备在方法区中为类变量分配内存并且设置初始值，仅类变量不包括实例变量，实例变量随着对象实例化时一起在堆中分配内存。这里的初始值是数据类型的零值。例如： 1public static int value = 2; 在准备阶段只会把 value 置为 0，赋值是在编译阶段会把 putstatic 指令放到类构造器的 clinit() 方法中，在初始化阶段在执行赋值。数据零值： 数据类型 零值 数据类型 零值 int 0 boolean false short (short) 0 float 0.0f long 0L double 0.0d char ‘\\u0000’ reference null byte (byte) 0 但是如果字段属性存在 ConstantValue 属性，则编译器会给 value 生成 ConstantValue 属性，然后在准备阶段就会置为指定值，例如： 1public static final int value = 2; 解析解析是虚拟机将常量池内的符号引用转化为直接引用的过程。解析动作主要针对 7 类符号引用： 类型 名称 CONSTANT_Class_info 类或接口 CONSTANT_Fieldref_info 字段 CONSTANT_Methodref_info 类方法 CONSTANT_InterfaceMethodref_info 接口方法 CONSTANT_MethodType_info 方法类型 CONSTANT_MethodHandle_info 方法句柄 CONSTANT_InvokeDynamic_info 调用点限定符 符号引用以一组符号来描述引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义的定位到目标即可。符号引用的字面量形式定义在 Java 虚拟机规范 Class 文件中，与虚拟机的内存布局无关。 直接引用指向目标的指针、相对偏移量或者一个能间接定位到目标的句柄。与虚拟机实现的内存布局相关，同一个符号引用在不同的虚拟机上翻译出来的直接引用一般不相同，如果有了直接引用那目标一定被加载到了内存中。 初始化初始化阶段虚拟机开始执行前期编译好的字节码，初始化类变量和其他资源，就是执行类构造器 &lt;clinit&gt;() 方法。 &lt;clinit&gt;() 方法是由编译器自动收集所有类变量赋值语句和静态语句块组合，顺序是由源文件中出现的顺序决定。静态语句块只能访问到定义在静态语句块之前的变量，之后的变量在前面的静态语句块可以赋值，但是不能访问。 12345678910public class StaticTest &#123; static &#123; i = 0; System.out.println(i); // 编译器会提示：Illegal forward reference；无效的向前引用 &#125; public static int i = 1; public static void main(String[] args) &#123; System.out.println(i); &#125;&#125; &lt;clinit&gt;() 方法与类的构造函数（实例构造器()方法）不同，不需要显示调用父类的&lt;clinit&gt;() 方法，虚拟机会保证在执行子类的&lt;clinit&gt;() 之前执行完父类的&lt;clinit&gt;() 方法。即 java.lang.Object 的&lt;clinit&gt;() 方法是第一个被执行的。 由于父类的 &lt;clinit&gt;() 先执行，则父类的静态语句块先于子类的变量赋值操作。 &lt;clinit&gt;() 不是必须的，如果类或者接口没有静态语句块或者变量赋值操作，编译器也可以不生成该方法。 接口中不能使用静态语句块，但可以有变量赋值操作，都会生成 &lt;clinit&gt;() 方法。不同点是，执行接口的 &lt;clinit&gt;() 方法不需要先执行父类的，只有使用到父类接口中定义的变量时在初始化。同样接口的实现类在初始化时也不会执行接口的 &lt;clinit&gt;() 方法。 虚拟机保证一个类 &lt;clinit&gt;() 方法的执行是线程安全的。其他线程会被阻塞，等当前初始化线程执行完后其他线程也不会再进入 &lt;clinit&gt;() 方法，同一个类加载器一个类只会被初始化一次。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"java/jvm/1.JVM-内存模型","date":"2020-05-08T14:36:33.605Z","path":"2020/05/08/java/jvm/1.JVM-内存模型/","text":"JVM 内存模型Java 语言在虚拟机 JVM 的帮助下，不需要用户手动释放内存，减少了很多工作，也不容易出现内存泄漏和内存溢出问题。不过正是因为把内存的控制权交给了 JVM，这使得在出现问题后定位问题的难度也增加了。JVM 在运行的时候会把内存分为： JVM内存模型 直接内存：该部分内存不是虚拟机规范和运行时数据区的内存，但是在一些 NIO 操作中会用到。NIO 是基于 Channel 和缓冲区的 IO 方式，可以使用 native 库函数直接分配堆外内存，然后通过存储在堆内的 DirectByteBuffer 对象作为这块内存的引用来进行操作，这样避免了在 Java 堆和 native 堆复制数据，提高了性能。直接内存的分配不受 JVM 限制，但是受本机物理总内存限制，所以如果有使用到这部分内存，在分配 JVM 内存时不能全部占用物理内存。 程序寄存器JVM 可以允许多个线程同时执行，每个 JVM 线程都有自己的程序寄存器，线程正在执行的当前方法不是 native 方法则程序寄存器保存 JVM 正在执行的字节码指令的地址；如果是 native 方法则程序寄存器的值是 undefined。字节码解释器工作时通过改变程序寄存器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复都需要寄存器来完成。 JVM 多线程是通过轮流切换 CPU 来获取程序执行资源，在任何时刻一个内核只会执行一个线程中的指令，程序寄存器就保证了线程重新获取 CPU 后能让程序恢复到正确的执行位置，所以各个线程之间不能互相影响，程序寄存器也是线程私有内存空间。 程序寄存器的容量至少能保存一个 returnAddress 类型的数据或者与一个平台相关的的本地指针的值。此内存区域是唯一一个 JVM 中没有规定任何 OutOfMemoryError 的区域。 returnAddress：指向某个操作码的指针，与 Java 虚拟机指令相对应。没有直接与 Java 中的数据类型相对应，程序运行期间也无法更改。 Java 虚拟机栈方法在执行的时候都会创建一个栈帧，用于储存局部变量表、操作数栈、动态链接、方法出口等信息。方法的执行过程对应了栈帧在虚拟机中出栈入栈的过程。Java虚拟机栈也是线程私有的空间。 局部变量表存放了编译器可知的基本数据类型(byte、short、int、long、char、float、double、boolean)、对象引用(reference 类型，对象起始地址的引用指针、代表对象的句柄或者对象的相关地址)、returnAddress类型。64 位的 long 和 double 类型会占用 2 个局部变量表空间，其他数据类型只占用一个。局部变量表空间是在编译时期完成分配，当执行方法时这部分空间是完全确定的，运行期间也不会改变。 操作数栈栈帧里面包含一个先进后出的操作数栈，栈帧中的操作数栈的最大深度在编译器决定。 栈帧刚创建时，操作数栈是空的， JVM 通过字节码指令从局部变量表或者对象实例字段中复制常量或者变量值到操作数栈中，从操作数栈中取走数据、操作数据、操作结果入栈等；调用方法时也可将方法参数或者方法返回结果入栈。 操作数栈的位置可以保存任意的数据类型的值，long 和 double 占用两个单位的栈深度，其他类型则占用一个单位栈深度。 动态链接动态链接指向当前方法所在类型的运行时常量池的引用。 class 文件中，一个方法需要通过符号引用调用其他方法或者访问成员变量。动态链接是在运行时将部分符号引用转化为直接引用。部分符号引用在类加载阶段(解析)时就转化为直接引用这种转化成为静态链接。 符号引用：用一组符号描述所引用的目标，可以使任何形式的字面量，在转化时可以无歧义的定位到目标，符号引用和虚拟机的布局无关。 直接引用：与虚拟机布局相关，已经转化为直接引用，那么引用目标也一定被加载到虚拟机内存里了。直接引用可以是：直接指向目标的指针、相对偏移量、可以间接定位到目标的句柄 方法出口方法调用正常结束方法执行过程中没有抛出任何异常。方法正常完成时会返回一个字节码标识给他的调用方法，返回指令类型由返回的数据类型决定(如果方法有返回值)。 方法正常结束时，当前栈帧需要恢复调用者的状态，包括局部变量表、操作数栈并且正确递增程序计数器，以跳过刚才执行的方法调用指令。调用者将被调方法的返回值压入操作数栈后继续正常执行。 方法调用异常结束方法执行过程中某些指令导致虚拟机抛出异常或者遇到了 athrow 指令，代码无法处理或者没有捕获异常导致方法结束。异常结束时不会有返回值给调用方。 Java 虚拟机栈会产生两个异常：StackOverflowError 当线程请求的栈深度大于虚拟机栈所允许的栈深度；OutOfMemoryError 虚拟机栈可以动态扩展，如果无法申请到足够的内存则会抛出异常。 本地方法栈Java 虚拟机栈为执行 Java 方法(字节码) 服务，本地方法栈(C stack)是为虚拟机使用到的 native 方法服务。本地方法栈的支持也需要看具体的 Java 虚拟机，如果虚拟机不支持本地方法栈，则不需要开辟这一块儿内存；如果支持则在线程创建的时候会按照线程来分配内存，所以本地方法栈也是线程私有内存。该部分内存也存在 StackOverflowError 和 OutOfMemoryError异常。 方法区方法区是线程共享的内存区域，存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区在虚拟机启动的时候创建。方法区是堆的逻辑组成部分，但是虚拟机的实现可以不考虑该部分内存的垃圾收集与压缩，方法区的容量可以固定也可以动态调整，这个可以由虚拟机来具体实现。方法区内存不能满足内存分配请求虚拟机会抛出 OutOfMemoryError 异常。 运行时常量池运行时常量池都在 Java 虚拟机的方法区中分配，在加载类和接口到虚拟机后就创建对应的运行时常量池。是 class 文件中每一个类或者接口的常量池表的运行时表现形式，主要用于存放编译期生成的各种字面量或者运行期解析后才能获得的方法和字段引用。运行时常量池是方法区的一部分，所以受到方法区的内存限制。 运行时常量池比 class 文件常量池具备动态性，运行时产生的常量也可以放入到运行时常量池，例如：String.intern() 方法。 堆线程共享的内存区域，几乎所有对象实例在堆上分配内存，是虚拟机所管理的最大的一块内存空间，在虚拟机启动时创建。是垃圾收集器的主要工作区域。Java 堆可以处于物理上不连续的内存空间，逻辑上连续即可。实现时可以按照固定大小来分配空间也可以动态扩展，通过(-Xmx 和 -Xms)来控制，不需要过多空间时也可以自己收缩。如果堆中没有内存支持实例分配空间，虚拟机会抛出 OutOfMemoryError 异常。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"java/jvm/4.JVM-对象引用与回收","date":"2020-05-04T09:41:26.048Z","path":"2020/05/04/java/jvm/4.JVM-对象引用与回收/","text":"对象引用与回收在之前的文章中学习了 JVM 内存模型，程序寄存器、虚拟机栈、本地方法栈都是线程私有的，在内存管理上当线程结束时资源就会释放掉。这几个区域内存的分配和类结构相关，大概在编译器就可以决定，所以他们的内存分配和回收都具备确定性。但是堆和方法区是线程共享内存区域，线程结束内存不一定被回收，每个接口的实现类需要的内存不一样、方法运行期间才知道需要创建那些对象，这部分内存的分配和回收都是动态的，这也是垃圾收集(GC)器工作的主要对象。 那些对象需要被回收Java 中的对象都是在堆上分配内存空间的，然后通过引用指向对象地址。是否被引用是判断对象是否还存活的重要根据。 对象引用JDK 1.2之前，reference 数据类型存储的数值代表一个内存地址表示着一个引用。随着硬件的发展内存空间虽然很珍贵但是还可满足，所以在内存空间充足的情况下，有些对象则尽可能的保留在内存中当内存不足时再回收。如何区分这些对象呢，就是通过引用的强弱关系来区分，主要有四种： 强引用（Strong Reference）：这是在代码中普遍存在的一种引用，类似：Object obj = new Object()，如果强引用还存在则一定不会被回收。 软引用（Soft Reference）：通过 SoftReference 类来实现，表示有用但是非必需的对象。系统发生内存溢出之前（已经 GC 一次）会把软引用关联的对象列进回收范围进行第二次回收，如果回收后还是内存不足则会抛出内存溢出异常。 弱引用（Weak Reference）：有用非必需对象，通过 WeakReference 类来实现，弱引用对象只能生存到下一次垃圾收集之前，当垃圾收集器工作时都会回收掉弱引用关联的对象。 虚引用（Phantom Reference）：最弱的引用关系，虚引用不会对对象的存活造成影响，无法通过虚引用在获取一个对象实例。为一个对象设置虚引用是在对象被垃圾回收时可以收到一个系统的通知。可以通过 PhantomReference 类来实现。 对象是否还被引用，主要通过下面两种算法来判断： 引用计数法给对象添加一个引用计数器，当对象被引用的时候计数器就增加 1，引用失效时计数器减 1，任何时刻计数器为 0 的对象就是不再被使用的。但是当对象存在循环引用时，其实环上的对象都已经不在被使用，但是计数器不为 0，这样会造成对象无法被回收。 可达性分析算法通过 GC Roots 的对象作为起点，对引用到的对象构造一条引用链，当某个对象没有到达 GC Roots 的路径，称为不可达。这部分对象被判定为可回收的。Java 虚拟机中可以作为 GC Roots 对象的有： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的属性 方法区中常量引用的对象 本地方法栈中 JNI（Native 方法）引用的对象 对象的真正死亡也至少要经过两个标记过程： 第一次标记可达性分析后对象没有与 GC Roots 相连的引用链，此时进行第一次标记并且进行一次筛选。筛选条件是次对象是否需要执行 finalize() 方法。如果对象没有覆盖 finalize 方法、或者finalize 方法已经被虚拟机调用过，这两种情况视为不需要执行。 如果对象需要执行 finalize 方法，对象会被放在 F-Queue 队列中，稍后由虚拟机自动建立的、低优先级的 Finalizer 线程去执行。这个执行仅是触发，不会等到方法执行完，避免出现 finalize 方法执行慢、死循环等情况使 F-Queue 对垒处于等待最终导致回收系统奔溃。第一次标记后的 finalize 方法是对象逃脱死亡的最后机会。 第二次标记第二次标记是针对在 F-Queue 队列中的对象，此时如果对象确实没有引用了就会被回收。所以在第一次的标记后的 finalize 方法执行时讲对象重新与引用链上对象建立引用关系即可被移出即将回收的集合。这种自救的方法只有一次，因为对象的 finalize 方法只会被虚拟机执行一次。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class FinalizeEscapeGc &#123; public static FinalizeEscapeGc SAVE_HOOK = null; public void isAlive() &#123; System.out.println(\"对象还存活\"); &#125; @Override protected void finalize() throws Throwable &#123; System.out.println(\"finalize 方法开始执行\"); super.finalize(); FinalizeEscapeGc.SAVE_HOOK = this; &#125; public static void main(String[] args) throws InterruptedException &#123; SAVE_HOOK = new FinalizeEscapeGc(); //第一次的回收时，通过指向this，拯救自己 SAVE_HOOK = null; System.gc(); //finalize 方法的优先级较低，线程停500ms等待 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"对象已死\"); &#125; //第二次的回收时，回收成功；因为finalize方法只能被虚拟机执行一次，所以这次会被回收掉 SAVE_HOOK = null; System.gc(); //finalize 方法的优先级较低，线程停500ms等待 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"对象已死\"); &#125; &#125;&#125;//finalize 方法开始执行//对象还存活//对象已死//输出结果可看到，finalize只被执行了一次，对象第一次还存活第二次被回收了。 常量、类回收上面主要说的是堆上对象的回收，对于方法区或者永久代虽然回收的效率比较低但是也存在垃圾回收。永久代主要回收两部分：废弃的常量和无用的类。 废弃常量如果常量池中的常量没有其他对象引用了。如果此时发生内存回收并且内存可能已经不足这个常量就会被清除。常量池中的其他类（接口）、方法、字段等符号引用也类似。 无用的类一个类是否无用的判断则比较苛刻： 该类的所有实例都被回收，即堆上不存在该类的实例 加载该类的 ClassLoader 已经被回收 该类对象的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 满足这些条件时才有可能被回收，是否回收虚拟机提供了 -Xnoclassgc 参数来控制。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"java/jvm/2.JVM-类加载器","date":"2020-05-04T09:41:26.048Z","path":"2020/05/04/java/jvm/2.JVM-类加载器/","text":"类加载器Java 虚拟机执行某个类，首先需要把类文件加载到虚拟机内存中，这个动作是通过类加载器来完成的。class 文件被类加载器加载到虚拟机内存中到卸载出内存经过了加载-验证-准备-解析-初始化-使用-卸载七个阶段。 从 JVM 角度来看有两种类加载器：启动类加载器和用户自定义类加载器。从开发人员角度来讲的话可分为四种：启动类加载器、扩展类加载器、应用程序类加载器、用户自定义类加载器。 启动类加载(Bootstrap ClassLoader)使用 C 语言实现，是虚拟机的一部分，主要负责将存放在 ${JAVA_HOME}\\lib 目录中的或者通过 -Xbootclasspath 参数指定路径中的并且可以被虚拟机识别(按照文件名识别) 的类库加载到虚拟机内存中。Java 程序不可以直接引用启动类加载器，开发者在自定义了自己的类加载器后，也要把类加载的请求委派给启动类加载器(双亲委派模型)。 扩展类加载器(Extension ClassLoader)由 sun.misc.Launcher.ExtClassLoader 实现，主要负责加载${JAVA_HOME}\\lib\\ext 目录中或者被 java.ext.dir 系统变量指定路径的类库，开发人员可以直接使用扩展类加载器。 应用程序类加载器(Application ClassLoader)由 sun.misc.Launcher.AppClassLoader 实现，负责加载用户类路径(Class Path)上指定的类库，开发者可以直接使用该加载器，一般情况下用户没有指定自己的类加载器，该加载器是程序的默认加载器。java.lang.ClassLoader#getSystemClassLoader 方法的返回值就是该类加载器，所以也叫做系统类加载器。 用户自定义类加载器开发人员可以通过继承 ClassLoader 来实现自己的加载器。 类加载模型-双亲委派模型双亲委派模型是类加载器之间的一种层次关系，双亲委派模型要求除了启动类加载器外，其他的类加载器都需要有自己的父类加载器。这种父子关系不是通过继承来实现，而是通过组合模式来复用父类加载器的代码。 类加载器模型 当前类加载器收到了加载类的请求，先判断是否有父类加载器可以加载这个类，将加载请求委派给父类加载器（直到启动类加载），当父类无法加载时，子类加载器再尝试自己去加载，子类加载器无法加载时则抛出ClassNotFoundException 异常。双亲委派模型的优点： 防止一个类被重复加载（同一个 class 文件被不同的类加载器加载后是不同的类） 保护 Java 的核心类库，避免用户自定义类似于java.lang.Object、java.lang.Integer类，对应用程序有一定安全保证 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/* * @param name 类全路径名：例如：java.lang.Integer * @param resolve * @return The resulting Class object * @throws ClassNotFoundException If the class could not be found */protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; //返回一个对象用于加锁，从线程安全上保证一个类被一个加载器加载 synchronized (getClassLoadingLock(name)) &#123; // 检查这个类是否已经被加载过了 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; //判断该类加载是否存在父类加载器，如果存在则使用父类加载器 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; //没有父类加载器，则直接尝试使用启动类加载器加载（也是为了保证核心类库的安全） c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); //调用当前类加载器自己的加载方法 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; //使用该方法链接类 c，装入引用类（超类、接口、字段、方法中使用的本地变量等）。 resolveClass(c); &#125; return c; &#125;&#125;protected Object getClassLoadingLock(String className) &#123; Object lock = this; //用 ConcurrentHashMap 实现，当前类加载器是否注册实现了 ParallelLoaders 并行加载能力 if (parallelLockMap != null) &#123; //parallerLockMap 由内部类 ParallelLoaders 来初始化 //实现了并行加载，则把当前需要加载的类全名做key，new一个对象做value放入parallelLockMap，表示这个类在被加载 Object newLock = new Object(); lock = parallelLockMap.putIfAbsent(className, newLock); if (lock == null) &#123; lock = newLock; &#125; &#125; //直接讲当前类加载器对象返回，表示当前类加载器正在加载 className 这个类 return lock;&#125; 破坏双亲委派模型双亲委派模型是一种推荐的类加载器实现方式，从上面的代码中可以看到，自定义类加载器的实现的加载方法主要是在 findClass() 方法中实现的，在 loadClass 方法中如果父类加载器加载失败，就可以调用 findClass() 来加载，这样就可以保证实现双亲委派模型。 双亲委派模型是为了解决各个类加载器对于核心类统一加载的问题，如果基础类库中部分类需要调用用户代码，则双亲模型就要被破坏了，例如JNDI、JDBC、JCE、JAXB、JBI等。利用线程上下文类加载器（Thead Context ClassLoader）实现。 代码热替换、模块热部署等技术。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"数据存储/MySQL/MySQL 学习总结","date":"2020-04-28T15:01:23.967Z","path":"2020/04/28/数据存储/MySQL/MySQL 学习总结/","text":"MySQL 学习总结MysQL 架构 MySQL架构图 InnoDB 不是 MySQL 自带的存储引擎，是一种可插拔的插件。InnoDB、MyISAM、MEMORY存储引擎是根据表来设置的，同一个库不同的表可以使用不同的存储引擎。 不同的存储引擎在索引、事务、锁的支持上是有区别的 存储引擎 事务 锁 分布式事务 InnoDB 支持 表锁、行锁 支持 MyISAM 不支持 表锁 不支持 MySQL 的锁排他锁、共享锁、独占锁(MyISAM)、自增锁、间隙锁、意向锁 共享锁：将数据对象变为只读形式，不能进行更新，也称为读取锁定；lock in share mode 拍他锁：当执行 INSERT\\UPDATE\\DELETE 的时候，其他事务不能读取该数据；for update 间隙锁：对某个范围加锁，这样可以用来解决范围内插入造成幻读的问题 InnoDB 默认情况下是行锁，但是如果表没有索引的时候加的是表锁。 死锁：互相占用需要的资源，MySQL 解决死锁的方式：超时检测；wait for graphy 深度优先遍历检测有没有环 MySQL 日志 binlog：归属于 server 层，stat、row、mixed三种格式 慢查询日志： redo日志：物理日志，保证所有数据的完整性，针对数据页操作记录 undo日志：逻辑日志，保证单行数据实现原子性，还可以用来实现 mvcc(多版本并发控制)；针对数据行操作 事务数据库事务是构成单一逻辑工作单元的操作集合 数据库事务可以包含一个或者多个数据库操作，这些操作构成一个逻辑上的整体 构成逻辑整体的这些数据库操作，要么全部执行成功，要么全部不执行 构成事务的所有操作，要么全部都对数据库产生影响，要么全部不影响，即数据库总能保持一致性状态 并发操作下，事务的控制尤其重要 原子性 A所有操作作为一个原子，要么全部成功，要么全部不成功。通过 undo 日志来实现，数据库在执行操作时首先将操作之前的数据备份到 undo log 中，然后在事务执行失败后用户执行了 rollback 操作，利用 undo log 将数据恢复到事务执行之前。undo log 是逻辑日志，undo 日志针对的行数据操作进行记录 一致性事务的执行结果使数据库从一个一致性状态到另一个一致性状态；一致性状态是指：1、系统的状态满足数据的完整性约束，2、系统的状态反应数据库本应描述的现实世界的状态。 事务的四个特性中，一致性是事务的根本追求。但是事务的并发执行、事务故障和系统故障会对一致性造成破坏。并发控制技术保证了事务的隔离性，使得事务在并发情况下不会破坏一致性；undo 日志恢复技术保证了事务的原子性，使一致性状态不会因为事务或系统故障破坏；redo 日志保证提交的修改不会因为系统奔溃而丢失，保证了事务的持久性。 隔离性并发自行的事务不会互相影响，和串行化执行时一样。完全的隔离性会导致系统性能降低，降低对资源的利用率，但是降低隔离性后也会导致一致性标准降低，所以根据不同的业务需要也会有不同的隔离级别。 读未提交(READ UNCOMMITED)：存在脏读、不可重复度、幻读问题 读已提交(READ COMMITED)：存在不可重复度、幻读问题 可重复度(REPEATABLE READ)：默认，存在幻读问题；在同一个事务中重复读取数据，读取到的是一致的 串行化(SERIALIZABLE)： 几种问题： 脏读： A 客户端可以读取到 B 客户端事务还没有提交的更改 不可重复读：A 客户端正在修改数据，B 客户端在整个事务过程中读取到的数据不一致(A 事务提交之前和提交之后) 幻读：在 A 客户端中插入数据，在 B 客户端中范围读取数据，当 A 插入的数据在这个范围中时，此时 B 是读取不到的，但是当 B 也插入该数据时有可能会成功有可能会失败(具体看表设计)。 实现原理-基于锁的并发控制流程： 事务根据自己对数据项的操作类型申请相应的锁（读申请共享锁，写申请拍他锁） 申请锁的请求发给锁管理器，锁管理器根据当前数据项是否已经有锁以及申请的和持有的锁是否冲突决定是否为该请求授予锁 若锁被授予，则申请事务的锁可以继续执行；若被拒绝，则申请锁的事务继续等待直到其他事务放弃锁 也可以通过时间戳、有效性检查和快照隔离实现并发性控制 持久性事务一旦提交，其对数据库的更新就是持久的，任何事务或者系统故障都不会导致数据丢失。利用 redo log 来实现，事务提交前，先将 redo log 持久化，再持久化数据。当系统奔溃时，系统可以根据 redo log 将数据恢复。InnoDB 根据 innodb_flush_log_at_trx_commit 参数来设置： 事务提交，每秒写入 OS Buffer，并调用 fsync() 写入磁盘 事务提交，每次提交时写入 OS Buffer，并调用 fsync() 写入磁盘 事务提交，每次提交时写入 OS Buffer，并调用 fsync() 写入磁盘 分类 扁平事务：例如 commit rollback 链式事务 嵌套事务 索引索引帮助高效获取数据的数据结构，存储在文件系统中，文件的存储形式与存储引擎有关(InnoDB-.idb；MyISAM-.myd,*.myi)。主要有 hash 索引、二叉树、B-Tree、B+Tree。InnoDB 索引主要使用B+Tree，但是在 InnodB 内部，当某索引访问次数过多时会将其转化为自适应的哈希索引。 索引的结构哈希索引数组+链表来实现，查询的时候需要先计算查询条件的哈希值，然后找到数组对应位置，然后链表比对查找。 缺点 哈希算法需要尽可能避免哈希碰撞，哈希碰撞会导致哈希索引性能退化； 等值查询的时候哈希索引才能生效，范围查找哈希索引无效； 哈希索引需要将数据文件存储在内存中，比较耗费空间； 二叉树、红黑树索引当树的深度过深而造成 IO 次数变多影响效率。 B 树索引 所有键值分布在整个树中，找到节点就找到了数据，不用再去映射；key 存储节点地址信息，value 存储对应的行数据 搜索可能在非叶子节点就找到，性能较高 每个节点最多 m 个子树，根节点至少 2 个子树 分支节点拥有 m/2 棵子树， 所有叶子节点都在同一层，每个叶子节点最多可以有 m-1 个 key，并且以升序排列。 缺点 每个节点既要存储地址信息还有 data 数据，如果 data 数据过大会导致 IO 的压力过大，增加 IO 次数也会导致性能下降。 B+ 树 在 B 树的基础上，所有的非叶子节点不再存储 data 数据，叶子节点存储 key 和 data 数据。 B+ 树有两个头指针，一个指向根节点，一个指向关键字最小的叶子节点 叶子结点是一种链式环结构因此可以对 B+ 树进行两种查找：一种是对于主键的范围查找和分页查找；一种是从根节点开始的随机查找 这里的 key 是在建表的时候，如果有主键则用主键，否则用唯一键，如果还没有则会生成一个 6 字节的 rowId 来用。 B+ 每个叶子结点块节点个数是有限的，所以如果要插入数据则有可能引起叶子节点块儿分裂，分裂后还要调整上层的非叶子节点，所以在设置主键的尽量可以设置成自增的；当删除的时候又可能需要进行合并。 MyISAM 和 InnoDB 都使用了 B+ 树，但是在叶子节点上，InnoDB 存储了实际的行数据，MyISAM 存储的是数据地址 索引的分类主键索引可以通过主键在索引中直接查找，找到后即可拿到数据 辅助索引给非主键列添加索引，索引的实现结构还是 B+ 树，但是叶子节点存储的不是实际数据了而是对应的主键值；查找的时候先根据普通索引查找到对应的主键，然后在逐渐索引中查找对应的数据 唯一索引主键：唯一且非空，唯一键可以空 全文索引全文索引更适合做搜索相关 组合索引组合索引在存储的时候先判断第一列然后判断第二列。。。将其构建为 B+ 树 索引技术名词回表普通索引查询后需要根据主键索引去查找对应的数据叫做回表 最左匹配组合索引中先从组合索引左列开始匹配，如果没有使用最左列的条件，则组合索引失效；如果查询条件都使用了组合索引的列但是顺序不是组合索引的顺序，MySQL 的优化器会将其进行优化。 索引覆盖在查询的辅助索引的时候，如果叶子节点保存的刚好是要查找的字段数据叫做索引覆盖 索引下推现通过索引讲符合记录筛选出来然后在回表查询对应数据，减少回表查询的数据行","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"MySQL事务","slug":"MySQL事务","permalink":"https://zcy-fover.github.io/tags/MySQL%E4%BA%8B%E5%8A%A1/"}]},{"title":"数据结构和算法/数据结构与算法之美/12.二叉树-上","date":"2020-04-19T06:34:53.926Z","path":"2020/04/19/数据结构和算法/数据结构与算法之美/12.二叉树-上/","text":"二叉树概念 父节点、子节点 兄弟节点：具有相同父节点的子节点 根节点：没有父节点的节点 叶子节点（叶节点）：没有子节点的节点 节点的高度（Height）：节点到叶子节点的最长路径（边数） 节点的深度（Depth）：根节点到这个节点经过的边数 节点的层数（Level）：节点的深度 + 1 树的高度：根节点的高度 二叉树：每个节点最多有两个子节点，左子节点和右子节点 满二叉树：除叶子节点外，其他节点都有左、右两个叶子节点，深度为 k，节点数为 $2^k-1$ 完全二叉树 所有叶子节点出现在 k 层和 k-1 层，1～(k-1) 层，必须是最大节点数（根节点都有左右子节点） 第 k 层可以不满，但是子节点都必须出现在树的左侧，例如下图中如果 E 节点有一个右子节点，就不是一个完全二叉树了 将树中的节点从上到下、从左到右编号为 i，构造一个满二叉树同样编号，如果节点的编号都一样则是一个完全二叉树。例如：E 节点如果有一个右子节点，直接编号的话顺序为 10，按照满二叉树编号为 11，编号不同了则不是完全二叉树。 堆也是一种利用了完全二叉树的结构。 完全二叉树 二叉树存储链式存储通过数据、左右指针来存储，然后通过根节点将整个树串起来 12345class BinaryNode&lt;T&gt; &#123; private T element; private BinaryNode&lt;T&gt; left; private BinaryNode&lt;T&gt; right;&#125; 顺序存储（数组）通过数组下标定位节点，节点 X 的下标为 i，则他的左子节点下标为 2*i，右子节点下标为 2*i + 1，可以发现如果是非完全二叉树就会存在浪费存储空间的情况了。例如：E 右子节点下标为 11，数组下标为 10 的位置就浪费了。 二叉树的遍历 前序遍历：先访问该节点，再访问该节点的左子树，最后访问该节点的右子树 中序遍历：先访问该节点的左子树，再访问该节点，最后访问该节点的右子树 后序遍历：先访问该节点的左子树，再访问该节点的右子树，最后访问该节点 前中后是相对于当前节点被访问的书序来说的。遍历的时间复杂度是 $O(n)$。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/************************** 二叉树的遍历，递归实现 ***************************///先序遍历public void preOrderTraversalRec(BinaryNode root) &#123; if (root != null) &#123; System.out.print(root.getElement() + \"-\"); preOrderTraversalRec(root.getLeft()); preOrderTraversalRec(root.getRight()); &#125;&#125;//中序遍历public void inOrderTraversalRec(BinaryNode root) &#123; if (root != null) &#123; inOrderTraversalRec(root.getLeft()); System.out.print(root.getElement() + \"-\"); inOrderTraversalRec(root.getRight()); &#125;&#125;//后序遍历public void postOrderTraversalRec(BinaryNode root) &#123; if (root != null) &#123; postOrderTraversalRec(root.getLeft()); postOrderTraversalRec(root.getRight()); System.out.print(root.getElement() + \"-\"); &#125;&#125;/************************** 二叉树的遍历，非递归实现 ***************************///先序遍历public void preOrderTraversal(BinaryNode root) &#123; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); BinaryNode current = root; while (current != null || !stack.empty())&#123; if (current != null)&#123; System.out.print(current.getElement() + \"-\"); stack.push(current); current = current.getLeft(); &#125; else &#123; //当访问到最左边的孩子后开始访问右孩子 current = stack.pop(); current = current.getRight(); &#125; &#125;&#125;//中序遍历public void inOrderTraversal(BinaryNode root) &#123; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); BinaryNode current = root; while (current != null || !stack.empty()) &#123; if (current != null) &#123; //从根节点开始，如果当前节点有左孩子，则入栈。包括最左孩子节点 stack.push(current); current = current.getLeft(); &#125; else &#123; current = stack.pop(); System.out.print(current.getElement() + \"-\"); current = current.getRight(); &#125; &#125;&#125;//后序遍历public void postOrderTraversal(BinaryNode root) &#123; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); Stack&lt;BinaryNode&gt; outStack = new Stack&lt;&gt;(); BinaryNode current = root; while (current != null || !stack.empty())&#123; if (current != null)&#123; outStack.push(current); stack.push(current); current = current.getRight(); &#125; else &#123; current = stack.pop(); current = current.getLeft(); &#125; &#125; while (!outStack.empty())&#123; System.out.print(outStack.pop().getElement() + \"-\"); &#125;&#125;","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"二叉树","slug":"二叉树","permalink":"https://zcy-fover.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"数据存储/MySQL/06.查询及优化-下","date":"2020-04-18T03:29:39.402Z","path":"2020/04/18/数据存储/MySQL/06.查询及优化-下/","text":"查询及优化查询优化器的局限性关联子查询在 where 条件中包含 IN() 的子查询语句，MySQL 执行时并不是先执行子查询然后执行外层查询。考虑使用 EXISTS() 来代替 UNION 的限制无法将限制条件下推到内层。如果利用 union 合并结果集，希望各个子句根据 limit 只取部分结果或者对结果集先排序在合并，那么需要在各个子句中分别使用 limit 或者排序。 索引合并优化where 条件中包含多个复杂条件的时候，MySQL 可以访问单个表的多个索引以合并和交叉过滤的方式来定位需要查找的行 等值传递等值传递有可能造成额外的消耗。例如过大的 IN() 列表，而优化器发现存在 where、in 或者 using 子句，会将列表和另一个表的某列关联，这又可能导致优化和执行变慢。 并行执行MySQL 无法利用多核来执行查询 哈希关联MySQL 的关联都是循环嵌套关联，不支持哈希关联。如果使用的是 Memory 存储引擎，使用的是哈希索引，关联也类似于哈希关联。 松散索引扫描不支持松散索引扫描，无法按照不连续的方式扫描一个索引。MySQL 索引的扫描需要有一个起点和终点。 最大值和最小值优化当 where 条件中的字段列没有索引时，此时不管求那个列的最值，都会进行全表扫描 同表查询和更新MySQL 不允许在一个 SQL 中对同一张表同时进行查询和更新 查询优化器的提示 HIGH_PRIORITY、LOW_PRIORITY：标示语句的优先级，例如 HIGH_PRIORITY 用于 select 语句时，MySQL 会将该语句调度到所有正在等代表锁修改数据的语句之前。 DELAYED：对 insert 和 replace 有效，立即返回客户端然后将插入的行数据放到缓冲区在表空闲时将数据批量插入。适合于日志系统或者客户端大量写入并不需要等待插入结果的业务应用。这样会导致 LAST_INSERT_ID() 函数无法工作。 STRAIGHT_JOIN：放置在 select 关键字后让查询中所有的表按照在语句中出现的顺序进行关联；放在两个关联表的名字中间时固定其前后两个表的关联顺序。 SQL_SMALL_RESULT、SQL_BIG_RESULT：这两个提示只对 select 有效，告诉优化器对 group by 和 distinct 查询如何使用临时表及排序，结果集小放在内存临时表；结果集大建议放在磁盘临时表做排序。 SQL_BUFFER_RESULT：让查询优化器将查询结果放到临时表，然后尽可能快的释放表锁 SQL_CACHE、SQL_NO_CACHE：查询结果是否应该放在查询缓存中 SQL_CALC_FOUND_ROWS：会计算除去 limit 子句后这个查询需要返回的所有结果集总数，对实际查询结果不影响。 FOR UPDATE、LOCK IN SHARE MODE：控制了 select 语句的锁机制，只对实现了行锁存储引擎有效。 USING INDE、IGNORE INDEX、FORCE INDEX：使用或者不使用哪些索引来查询 优化特定类型的查询优化 count() 查询count() 聚合函数可以统计某个列值的数量，在统计列值要求非空(不统计NULL)；也可以统计行数，count() 统计结果集的行数，\\ 并不会扩展成所有列，而是忽略所有列直接统计行数 优化关联查询 确保 on 或者 using 子句的列上有索引 确保任何的 group by 和 order by 表达式只涉及到一个表，这样 MySQL 才有可能利用索引来优化 优化子查询优化 group by 和 distinct都可以使用索引来优化，当无法使用索引时 group by 使用临时表或者文件排序来做分组 优化 limit 分页当 offset 偏移量较大时，MySQL 需要扫描多条记录才能到达目标位置。考虑使用索引覆盖扫描，做一次关联操作再返回所需的列。 优化 SQL_CALC_FOUND_ROWS在 limit 语句上加上这个提示，MySQL 就会不管结果是否实际需要都会扫描所有满足条件的行返回总数，而不是达到 limit 限制就停止。 优化 union 查询MySQL 通过创建填充临时表的方式来执行 union 查询，但是需要手工将 where、limit、order by 等子句下推到各个子查询中，以便优化器利用这些条件进行优化。如果不是要消除重复的行，则推荐使用 union all，如果没有没有 all，MySQL 会给临时表加上 DISTINCT 对临时表做唯一性检查，这样的代价是比较高的。 静态查询分析解析查询日志、分析查询模式 使用用户自定义变量","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://zcy-fover.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"查询","slug":"查询","permalink":"https://zcy-fover.github.io/tags/%E6%9F%A5%E8%AF%A2/"},{"name":"查询优化","slug":"查询优化","permalink":"https://zcy-fover.github.io/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"}]},{"title":"数据存储/MySQL/06.查询及优化-上","date":"2020-04-18T03:29:37.484Z","path":"2020/04/18/数据存储/MySQL/06.查询及优化-上/","text":"慢查询及优化查询的执行过程：客户端，到服务端后：会话连接、SQL分析、SQL 优化、生成执行计划、执行后返回结果。执行是整个生命周期最重要的阶段。 查询分析 EXPLAIN 属性 含义 id 查询中执行 select 子句或操作表的顺序，Id 相同执行顺序由上向下；id 越大优先级越高越先执行 select_type select 子句查询类型，主要区别普通查询、联合查询、子查询等复杂查询 table 数据库中表名称，行数据是关于哪张表，可能不一定是真实的表名称 partitions 分区表命中的分区情况，非分区表该字段为空 type 访问类型，对表的访问方式 possible_keys 使用哪个索引能找到记录即该查询可以利用的索引。查询的列上若存在索引会被列出。如果没有则显示 NULL key 实际查询过程中用到的索引，一定包含在 possible_keys 中，如果没有则显示 NULL key_len 索引使用的字节数，如果是单列索引则是整个索引长度；如果是多列索引，则具体用到多少列索引就算多少 ref 列与索引的比较，表的连接匹配条件，哪些列或常量被用于查找索引列上的值 rows 估算结果集行数 filtered 返回的结果行和需要扫描读到的行数的比值 Extra 解决查询的详细信息 select_type simple：简单的 select 查询，查询中不包含子查询或者 union primary：子查询中最外层查询，查询中包含任何复杂的子部分，最外层被标记 subquery：在 select 或 where 列表中包含子查询，结果不依赖外部查询 dependent subquery：子查询中第一个 select，依赖外部查询 uncacheable subquery：一个子查询的结果不能被缓存，必须重新评估外链接第一行 derived：在 from 列表中的子查询，MySQL 会递归执行这些子查询，然后把结果集放在临时表中 union：如果第二个 select 出现在 union 之后，则被标记为 union；如果 union 包含在 from 子句的子查询中，外层 select 被标记为 derived union result：union 的结果，union 语句中第二个 select 后面的所有的 select dependent union：union 中第二个或后面的 select 语句 type system：表中仅有一行，const 连接类型的特殊情况 const：通过索引一次就找到，const 用于比较主键索引和唯一索引，如果将主键放在了 where 条件中，MySQL 可以将其转换为常量 eq_ref：唯一性索引扫描，对于每个索引键表中只会有一行记录与之匹配 ref：非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，可能会找多个符合条件的行，属于查找和扫描的混合体 ref_or_null：与 ref 类似，增加了 null 值比较 range：使用索引的范围扫描，见于使用 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN()或者like等运算符的查询中 index：遍历索引树，不需要读取数据行，例如只通过覆盖索引就查找到目标数据 all：全表扫描，然后在服务层根据条件过滤返回需要的记录 fulltext：全文索引，优先级较高，如果全文索引和普通索引同时存在，MySQL 会优先使用全文索引 index_merge：查询使用了两个以上的索引，最后取交集或者并集 unique_subquery：用于 where 中的 in 形式子查询，子查询返回不重复唯一值 index_subquery：用于 in 形式的子查询使用到了辅助索引或常数列表，子查询可能返回重复值，可以使用索引将子查询去重 ref常数等值查询显示 const，连接表查询显示驱动表的关联字段，使用了表达式、函数、条件列发生内部隐式转换显示 func Extra distinct：在 select 使用了 distinct 关键字 no table used：不带 from 子句的查询或者 from dual 使用 not in() 形式子查询或者 not exist 连接查询，这种叫做反连接。一般连接查询是先查内表再查外表，这种是先查外表再查内表 using filesort：排序时无法使用到索引，常见于 ORDER BY 和 GROUP BY 语句中 using index：查询时不需要回表，直接通过索引就可以查询 using where：存储引擎返回的记录不满足查询条件，需要在服务层通过条件过滤 using join buffer：使用了连接缓存，减少内表的循环数量以及顺序的扫描查询 using sort_union：表示使用 and 的各个索引的条件时，该信息表示是从处理结果获取交集 using_union：表示使用 or 连接各个使用索引的条件时，该信息表示从处理结果获取并集 using sort_union：表示使用 and 连接查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回。 using sort_intersection：表示使用 or 连接查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回。 firstmatch(td_name)：常见于 where 子句还有 in() 类查询，内表数据量大可能出现 loosescan(m…n)：在 in() 类型的子查询中，子查询返回的可能有重复记录 慢查询查询性能最基本的原因是访问不必要或者太多的数据。主要通过两个步骤来分析：应用是否检索了大量超过实际需要的数据，包括太多的行数据或者列数据；服务层是否在分析大量超过实际需要的行。 不需要的数据 查询不需要的记录：利用 limit 优化自己需要的记录行 多表关联时返回全部列：注意多表关联的情况，一般可能只需要关联表的某个字段而不是全部字段 取出全部列：使用了 SELECT *，可能情况比较少。使用 * 会让优化器无法利用覆盖索引完成优化，取出实际需要的列即可 重复查询相同的数据：执行相同的查询、返回相同的数据。考虑合理利用缓存 扫描额外的记录主要是在查询执行过程中是否扫描了过多的行数据，考虑是否可以优化 响应时间：响应时间主要包括两部分：服务时间和排队时间，服务时间是指数据库处理这个查询花费的具体时间，排队时间是服务器要等待某些资源没有没有执行查询的时间 扫描的行数和返回的行数：最好的情况就是扫描的行就是需要的返回的行，避免无用的行扫描 扫描的行数和访问类型：EXPLAIN 的 type 列反映了访问类型(全表扫描、索引扫描、范围扫描、唯一索引扫描、常数引用)。所以可以让 MySQL 以高效、扫描行数少的方式找到需要的记录 MySQL 应用 WHERE 条件的场景： 在索引中使用 WHERE 条件在存储引擎层过滤不匹配的记录 使用索引覆盖扫描来返回记录，在 EXTRA (using index) 。直接从索引中返回结果这是在服务器层完成不需要回表查询 从数据表中返回结果，过滤不满足条件的记录，在 EXTRA (using where) 。在服务层完成，先从数据表读出记录然后过滤 如果发现需要扫描大量的行但是只返回少量的数据，可以从下面几个方面考虑优化： 是否可以优化为从覆盖索引扫描，把需要的列放在覆盖索引中，查询索引时直接返回 优化数据库、表结构 优化查询 SQL 查询的执行过程 MySQL查询执行过程 通信协议半双工通信协议。在同一时刻客户端和服务器只能有一方发送消息。这种通信简单快速，但是同一时刻只能是发送消息或者等待响应。双方传递数据包消息时服务器会通过 max_allowed_packet 控制客户端发送数据包的大小，如果查询太大服务器会拒绝或者抛出错误。但是如果服务器响应给客户端的数据如果太大，会分开为几个数据包发送，但是客户端不能拒收，如果太大导致客户端奔溃，此时客户端应该考虑加上 limit 限制。 查询状态整个连接，或者一个查询线程在某一个时刻都有一个状态，表示 MySQL 当前正在做什么。可以使用 SHOW FULL PROCESSLIST 查看。 Sleep：服务器线程正在等待客户端发送请求 Query：服务器线程正在执行查询或者将查询结果发送给客户端 Locked：在服务器层，正在等待表锁。在存储引擎级别实现的锁，例如 InnoDB 的行锁不会体现在线程状态中；但是 MyISAM 是会出现的状态 Analyzing and statistics：线程正在收集存储引擎的统计信息，生成查询的执行计划 Copy to tmp table [on disk]：线程正在执行查询，并将结果放到临时表中，此状态一般是正在执行 GROUP BY、文件排序或者 UNION 操作。如果后面有 on disk 标记，说明 MySQL 正在将临时表放到磁盘上 Sorting result：线程正在对结果集进行排序 Sending data：线程可能在多个状态间传递数据、生成结果集或者向客户端发送数据 查询缓存查询缓存的配置开启，当一个查询请求到来时，会检查这个查询是否可以命中缓存中的数据。这个检查是通过大小写敏感的哈希查找实现。如果命中了缓存返回结果时 MySQL 会再检查用户是否有权限。如果从缓存中查询到结果则不会解析 SQL 语句生成执行计划等。 查询优化处理将 SQL 转换成一个执行计划，包括：解析 SQL、预处理、优化 SQL 执行计划 语法解析器和预处理使用语法规则验证和解析查询，将 SQL 语句生成一颗对应的“解析树”。主要验证关键字是否合法，关键字顺序是否正确，符号是否匹配(引号、括号等)。预处理器根据检查解析树是否合法，检查数据表和数据列是否存在，解析名字和别名是否有歧义。 查询优化器将合法的语法树转化为执行计划。优化器就是找出其中最优的执行计划。MySQL 的优化器是基于成本选择最优的。最初是根据读取一个 4K 数据页的成本来计算，后来变成公式主要有：每个表或者索引的页面个数、索引的基数即索引的不同值、索引和数据行的长度、索引的分布情况几个维度的统计信息来计算。 有很多原因会导致选择错误的执行计划： 统计信息不准确 执行计划的估算成本不能等同于实际执行的成本 MySQL 选择的最优也只是基于成本模型最优，并不一定是最快的执行计划 并没有考虑其他并发执行的查询，并发查询可能会影响当前的查询执行计划 并不是所有都基于成本优化，也可能基于固定规则，例如存在全文索引的 MATCH() 子句，存在全文索引的时候就是用全文索引，不考虑其他索引是否更快 不考虑不受其控制的成本，例如用户是否使用了自定义函数 MySQL 有两个优化策略：静态优化、动态优化。静态优化相当于“编译时”优化，静态优化只执行一次；动态优化相当于“执行时”优化，在查询的每次执行时都会优化。MySQL 能够处理的优化： 重新定义关联表的顺序 将外连接转换为内连接，并不是所有的外连接都是以外连接的方式执行。根据 where 条件等有的可以转换为内连接 使用等价变换规则 优化 COUNT()、MIN()、MAX()，可以利用索引的性质来很快查询到对应数据：B-Tree索引的最左记录就是最小值，最右记录是最大值，如果是没有 where 条件的 COUNT(*) 在 MyISAM 引擎中专门有一个变量来存储行记录数 预估并转化为常数，将可以转化为常数的表达式进行优化处理 覆盖索引扫描 子查询优化，避免多个查询对数据进行多次访问 提前终止查询，例如使用了 limit，或者遇到不满足的条件立即终止 等值传播 列表 IN() 的比较，对 IN 列表中的数据先进行排序，然后二分查找来确定列表中的值是否满足条件 数据和索引的统计信息统计信息由存储引擎实现，不同的存储引擎存储不同的统计信息 执行关联查询MySQL 对任何关联查询都执行循环嵌套关联操作，先在一个表中循环取出单条数据，然后嵌套循环下一个表中寻找匹配的数据，直到找到所有匹配的行，然后根据匹配的所有行返回所需要的列。如果最后一个关联表无法找到更多的数据，则会返回上一层关联表继续寻找是否有匹配的记录，以此迭代执行。 执行计划MySQL 会生成一颗查询的指令树，然后通过存储引擎执行这颗指令树然后返回查询结果 关联查询优化器优化多表关联查询的顺序，优化器通过评估不同顺序时的成本选择最优的顺序来执行。 排序优化当不能使用索引进行排序时，MySQL 需要利用内存或者磁盘进行排序，这个过程叫做文件排序。如果排序的数据量小于“排序缓冲区”直接利用内存进行快速排序，如果超过了排序缓冲区，则将将数据分块，每个数据块独立使用快速排序，然后将排序结果放在磁盘上最后将结果合并。 两次传输排序(就版本使用)：读取行指针和需要排序的字段，进行排序然后读取对应的行数据。优点是排序缓冲区存储的数据较少，可以容纳更多的行进行排序；缺点要两次数据传输，第一次是读取行指针和排序字段，第二次是根据排序结果读取行数据，而且第二次排序后读取数据时不再是数据存储的顺序，产生大量的随机 I/O，导致数据传输的成本变高。 单次传输数据：先查询读取所有需要的列，然后进行排序，最后返回结果。这样做的优缺点就和上面相反。优点减少数据读取次数，对于 I/O 密集的应用可以提高效率；缺点行数据返回很多排序无关字段占用空间，如果数据量过大可能导致需要分块排序。 在关联查询中，排序时如果排序字段都在自第一张表则在处理第一张表时就进行文件排序，其他情况都是先将关联查询结果放到临时表中然后然后再进行文件排序。如果有 limit 子句，也是先排序后使用 limit，MySQL 5.6 之后不再对所有结果排序，先丢掉不满足结果的数据然后再排序。 查询执行引擎查询执行引擎根据生成的执行计划按步骤执行，通过调用存储引擎的接口来完成。 返回结果给客户端最后将查询结果返回给客户端，如果查询不需要返回结果给客户端，MySQL 也会返回查询的基本信息，影响的行数等。如果开启了查询缓存，也会将查询结果放到缓存中。 服务端返回结果是增量、逐步返回的。这样处理服务端不需要存储太多结果，也避免一次性返回太多结果而消耗太多内存。 结果集中的每一行会以一个满足 MySQL 服务端/客户端 通信协议的封包发送，然后通过 TCP 协议传输，TCP 协议传输时可能对封包缓存然后批量传输。 重构查询方式一个复杂查询还是多个简单查询多个简单查询考虑更多的是客户端/服务端连接、网络交互的影响，MySQL 对于连接-断开已经实现的很轻量级，现代网络速度也很快，所以多个简单查询不一定比复杂查询慢。 切分查询将大的查询切分为多个小查询(例如分页) 分解关联查询分解关联查询可以： 利用缓存，缓存的效率更高 查询分解后，单个查询可以减少锁的竞争 在应用层做关联，可以更容易对数据库进行查分，做到高性能和可扩展 拆分后可能会使得效率更高 减少冗余记录的查询，在应用层做关联可以减少数据的重复查询，数据库层的关联查询很多情况下存在数据的重复访问。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://zcy-fover.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"查询","slug":"查询","permalink":"https://zcy-fover.github.io/tags/%E6%9F%A5%E8%AF%A2/"},{"name":"查询优化","slug":"查询优化","permalink":"https://zcy-fover.github.io/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"}]},{"title":"数据结构和算法/数据结构与算法之美/11.哈希算法","date":"2020-04-18T03:24:41.896Z","path":"2020/04/18/数据结构和算法/数据结构与算法之美/11.哈希算法/","text":"哈希算法将任意长度的二进制值串映射为固定长度的二进制值串，这个映射规则就是哈希算法，映射后的值叫做哈希值。 哈希算法的要求 从哈希值不能反向推导出原数据 对输入数据敏感，原始数据有一位不一样得到的哈希值也大不相同 散列冲突的概率要小 执行效率要高，执行效率应该与原值长度无关 哈希算法的应用 安全加密 MD5：消息摘要算法 SHA：安全散列算法 DES：数据加密标准 AES：高级加密标准 哈希算法是基于一个数学理论鸽巢原理。如果 MD5 哈希值是固定的 128 位，则总共可以产生 2^128 个哈希值，如果要对 2^128 + 1 个数据求哈希值，则必然会存在冲突。 鸽巢原理（也叫抽屉原理）。如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，即肯定有 2 只鸽子在 1 个鸽巢内。 唯一标识图片存储比对可以利用图片信息生成哈希值来比对，减少比对难度。 数据校验常见的有应用程序安装包校验；BT文件块的下载校验 散列函数负载均衡利用哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。 数据分片利用哈希算法将数据分片存储到不同的机器上，减少单机压力。 分布式存储利用数据分片将不同的数据存储在不同的机器上，但是如果数据量过大需要扩容 N 个机器，此时原来的数据取模的基数变了，需要迁移数据。例如使用 Redis 缓存时，这种情况可能就会直接发生雪崩效应，Redis 暂时无法提供服务，请求全部压在数据库上。 可以利用一致性哈希算法来解决这个问题，抽象出一个 m 区间的哈希环，然后利用已有的机器节点将这个环分割，机器负载落在某个分割环的一个区间，不再是直接对应到机器上。这样当某个机器故障后，只需要将这一部分数据迁移到他的临近机器上，不需要全部数据迁移。参见：一致性哈希","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"哈希算法","slug":"哈希算法","permalink":"https://zcy-fover.github.io/tags/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"}]},{"title":"数据结构和算法/数据结构与算法之美/10.散列表","date":"2020-04-18T03:24:40.275Z","path":"2020/04/18/数据结构和算法/数据结构与算法之美/10.散列表/","text":"散列表利用数据支持随机访问的特性为基础，是对数组的一种扩展。是一种key-value型数据结构，但是在存储的时候需要通过散列函数将key转换为对应的数组下标，结算后得到的值叫做散列值或者哈希值。 散列函数通过散列表的概念可以知道散列函数是非常重要的，决定了数据存储的位置。散列函数设计的基本要求： 计算得到的散列值是非负整数 如果 key1=key2，则 hash(key1) = hash(key2) 理想情况下，key1 != key2，则 hash(key1) != hash(key2) 现在已有的MD5、SHA、CRC等哈希算法，也无法避免散列冲突。 散列冲突上述第三点，如果不同的 key，计算后的哈希值一样，则存在散列冲突，需要用一些其他方法来处理散列冲突。 开放寻址法当产生哈希冲突后，继续寻找出一个可以存放数据的空闲地址，主要有以下几种方式。 线性探测当产生冲突后，继续向后查找是否有空闲位置，直到查完全表。这种方式会造成原本计算出是该位置的数据结果被其他冲突的元素占用，所以该元素只能继续向后查找。如果冲突元素删除时也会对查找造成影响，例如：A 元素产生了哈希冲突存储在 X 位置，B 元素通过哈希计算位置是 X，但是因为 X 位置已经有了 A，所以需要继续向后寻址存储在 Y 位置，当 A 元素被删除后，此时来查找 B 元素，通过哈希计算 B 元素的位置是 X，此时 X 位置是空的所以就查找不到了。 这种方式虽然解决了一部分冲突元素的存储，但是带来了很多其他需要解决的问题。 二次探测再散列类似于线性探测，线性探测的步长是 1，二次探测则是跳跃性探测 双重散列当一个哈希函数计算后产生了冲突，采用另一个哈希函数计算，直到计算出空闲位置。这样会导致计算时间变长。 链表法散列表的每个位置指向一个链表，当产生冲突后继续向链表后添加元素。 装载因子1散列表的装载因子&#x3D;填入表中的元素个数&#x2F;散列表的长度 装载因子越大,说明空闲位置越少，冲突越多，散列表的性能就降低了。 工业级散列表设计特性 具备快速的查询、插入、删除操作 内存占用合理，不浪费过的内存空间 性能稳定，极端情况下不会退化到最坏情况 设计思路 均匀的散列函数 装载因子阈值，设计动态扩容，动态扩容时降低性能影响（将动态扩容任务分摊，在插入过程中扩容） 合适的散列冲突解决方案 散列表使用举例LRU 缓存淘汰算法LRU(Least Recently Used) 最近最少使用算法。LRU 算法需要维护一个按照访问时间从大到小的排列的链表，涉及到的操作： 新增一个节点 查询一个节点 删除一个节点 如果采用双向链表则新增和删除的复杂度都是 $O(1)$，但是查找性能是$O(n)$。为了降低查找时间复杂度，引入散列表，将所有节点维护在散列表中。通过散列表快速定位节点位置，通过双向链表快速插入或者更新节点位置。 如果有新的节点过来，先插入散列表然后将其插入到双向链表的尾部；如果已有节点被访问，则通过散列表定位然后改变该节点的前继和后继指针指向，可以直接将其移到尾节点。删除时在散列表中删除节点然后通过头指针在链表中删除节点。这样插入、删除、查询都实现了$O(1)$的复杂度。 Redis 有序集合(sorted set)Redis 的有序集合是利用散列表+跳表来实现的。sorted set有两个属性：key 和 score，具有的操作： 添加元素 根据 key 查找、删除元素 根据 score 范围查找数据 根据 score 对元素排序 可以看到如果仅仅利用跳表或者散列表一种来实现，是无法达到上面的功能操作的。 Java LinkedHashMapJava 中的 LinkedHashMap 是利用双向链表和哈希表来实现的。会根据元素的插入顺序和访问顺序来排序，LinkedHashMap 的原理就是 LRU 缓存算法的实现。两者是一样的。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"散列表","slug":"散列表","permalink":"https://zcy-fover.github.io/tags/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"哈希函数","slug":"哈希函数","permalink":"https://zcy-fover.github.io/tags/%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0/"}]},{"title":"数据结构和算法/数据结构与算法之美/9.跳表","date":"2020-04-18T03:24:38.832Z","path":"2020/04/18/数据结构和算法/数据结构与算法之美/9.跳表/","text":"跳表用链表实现的类似于二分查找的数据结构，可以支持快速的插入、查找、删除操作 跳表初始化跳表类似于二分查找，但是因为是链表，不能随机访问。可以对原始链表跳跃性建立一级、二级索引…可以发现建立了索引之后，需要遍历的元素个数变少了。 跳表初始化 跳表性能分析时间复杂度链表如果有 n 个节点，第一级索引有 n/2 个节点，二级索引有 n/4 个节点，第 k 级索引的节点个数是 $n/2^k$ 个； 假设最高一级索引有两个节点 $n/2^k = 2$，$k = log_2n - 1$，整个跳表的高度是 $log_2n$，如果每一层要遍历 m 个节点，则时间复杂度是 $O(mlog_2n)$。每一层遍历的节点个数是常量级的，所以跳表的查询时间复杂度是 $O(log_2n)$。 空间复杂度如果步长为 2，需要的额外空间每一层是 n/2、n/4、n/8…4、2，求和 $S_n = (a_1-a_n*q)/(1-q)$ 共有 n-2 个节点。则空间复杂度为 $O(n)$。 跳表插入和删除跳表利用查询的性能可以很方便的找到插入位置，寻找插入位置的时间复杂度是 $O(logn)$，链表的插入时间复杂度是 $O(1)$，总体时间复杂度是 $O(logn)$。跳表如果在一个索引区间插入元素过多时可能会造成跳表的性能退化，极端情况下退化到单向链表，所以跳表的索引要能动态更新。 跳表的删除，也是需要查询到删除的位置，但是如果是单项跳表，需要记录删除位置的前一个元素，如果是双向列表则不需要。 Redis的有序集合实现Redis的有序集合 zset 使用了 ziplist(压缩链表)和 skiplist(跳表)两种实现方式。当有序结合的元素少于 128 个，所有元素大小小于 64 字节使用 ziplist，不满足这两个条件时使用 skiplist。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"跳表","slug":"跳表","permalink":"https://zcy-fover.github.io/tags/%E8%B7%B3%E8%A1%A8/"}]},{"title":"数据结构和算法/数据结构与算法之美/8.二分查找","date":"2020-04-18T03:24:36.899Z","path":"2020/04/18/数据结构和算法/数据结构与算法之美/8.二分查找/","text":"二分查找二分查找是针对有序结合，将区间分为两个，每次和区间的中位元素比较，以此循环直到找到元素或者区间的大小为 0。 实现 循环退出条件：low &lt;= high mid 取值：mid = low + (high - low) &gt;&gt; 1 low 和 high 的更新：low = mid + 1; high = mid - 1 二分查找局限性 依赖顺序表结构，即数组。需要元素的随机访问 二分查找针对有序数组，原序列无序时需要先排序 数据量太大不适合二分查找，二分查找需要顺序表结构，需要连续的地址空间，对内存要求较高。 二分查找是和静态的数据序列，不适合动态变化的。 时间复杂度二分查找采用不断的二分区间的做法，数据量为 n，经过 k 次二分查找有 $2^k = n$，则$k = log_2n$，时间复杂度是$O(logn)$","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"java/源码学习/AQS框架","date":"2020-04-18T03:22:36.174Z","path":"2020/04/18/java/源码学习/AQS框架/","text":"开发中。。。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"java/源码学习/Java8 HashMap","date":"2020-04-18T03:22:30.335Z","path":"2020/04/18/java/源码学习/Java8 HashMap/","text":"Java8 的 HashMap数据结构在 Java7 中 HashMap 底层主要利用数组、链表结构来实现，但是根据 HashMap 的存储结构，当某个 hash 位上的链表过长，查询性能就会退化，所以在 Java8 中，当链表的节点数达到 8 时会转化为红黑树，查询的时间复杂度为 $O(logn)$。 相关数据结构：数组、链表、红黑树 源码解析在看 Java8 的源码之前，需要了解位运算： &lt;&lt;：左移，低位补 0 &gt;&gt;： 带符号右移，原数是整数高位补 0，原数是负数高位补 1 &gt;&gt;&gt;：无符号右移，无论原数是正数还是负数都在高位补 0 ^：异或，相同为 0，相异为 1 &amp;：与，都为 1 结果为1，其他为 0 put 函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;/** * @param hash 插入 key 的 hash 值 * @param key 插入 key * @param value 插入的值 * @param onlyIfAbsent 如果为 true，当 key 对应的 value 不存在时才插入 * @param evict 用于linkedHashMap的尾部操作 * @return 如果 key 对应的 value 存在，并且替换过则返回旧值 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) //如果数组为空，则进行数组初始化；初始化时没有指定大小则默认为 16 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) //计算插入位置((n - 1) &amp; hash)，如果数组该位置还没有插入，则构建节点直接插入 tab[i] = newNode(hash, key, value, null); else &#123; //数组该位置已经有节点插入，则需要该数组位置是以链表实现还是红黑树，选择不同的插入方法 Node&lt;K,V&gt; e; K k; //判断数组该位置当前节点是否和要插入的节点 key 相等，如果相等取出当前节点，e 指向旧节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) //判断数组该位置节点数据结构是是否是红黑树，如果是则调用红黑树的插值方法 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //数组该位置节点是由链表实现，直接向后遍历该链表，找到插入的位置 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //遍历到达链表尾部 p.next = newNode(hash, key, value, null); //插入后如果该链表上的节点个数达到了 8 个，则把该链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //在链表遍历过程中，存在与待插入的节点相等的 key，结束循环，e 指向的就是旧节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果不为空，e 节点指向的是存在相等 key 的节点 if (e != null) &#123; // existing mapping for key V oldValue = e.value; //如果 onlyIfAbsent 为 true，当该节点对应的 value 不存在时才替换 //如果 onlyIfAbsent 为 false，直接用新节点 value 覆盖旧节点 value if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //如果该 hashMap 中的所有节点个数超过阈值，则需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize 数组扩容分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091final Node&lt;K,V&gt;[] resize() &#123; //对 hash 数组扩容或者初始化 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //数组容量已经大于 0，判断是否超过最大容量 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //没有超过最大容量，直接扩大 2 倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //判断是否超过最大容量并且大于默认容量，则阈值扩大一倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold //使用 HashMap(int initialCapacity) 初始化数组容量大小 //第一次执行 put 操作时，将数组容量初始化为计算的阈值 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults //使用 new HashMap() 初始化后，将数组容量初始化为默认值 16 newCap = DEFAULT_INITIAL_CAPACITY; //阈值也是默认值 12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //在 if (oldThr &gt; 0) 这个条件中，第一次 put 时，newThr 值为 0 if (newThr == 0) &#123; //利用初始化的数组容量计算新的阈值 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) //用新的容量初始化新的 hash 数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果是第一次初始化，则可以直接返回；否则需要将旧数组的数组，重新迁移到新的数组中 if (oldTab != null) &#123; //遍历旧数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //旧数组当前位置节点不为空 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) //旧数组该位置只有一个节点，计算该节点在新数组的索引值，插入节点 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //如果该节点是红黑树结构 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order //每次扩容时，容量都是原来的 2倍，这种情况下每个元素在新数组中的索引位置：要么是不变，还有一种是原位置+扩容长度。 //当然也可以利用 e.hash &amp; (newCap - 1)来计算，这两个是等价的。但是 java8 的这个处理性能好 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //根据上述的两种方式，可以将旧数组该位置量表分为两个链表，然后分别插入到新数组的对应位置 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 索引位置结算hash &amp; (cap - 1)：利用模运算也可以计算索引，但是模运算的性能不如与运算。 例如： cap 为 16 时，hash 值为 30：0001 1110 &amp; 0000 1111 = 0000 1110，索引值为 14 cap 为 16 时，hash 值为 5：0001 1110 &amp; 0000 0101 = 0000 0100，索引值为 4 在扩容时，链表复制的情况： newCap 为 32，hash 值为 30 时：0001 1110 &amp; 0001 1111 = 0001 1110 新的索引值是：30，符合旧的索引值 + 旧的数组大小 newCap 为 32，hash 值为 5 时：0001 1110 &amp; 0000 0101= 0000 0100 新的索引值是：4，位置不变 get 函数分析12345678910111213141516171819202122232425public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 如果数组不为空，对应数组索引位置节点不为空时进行查找 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //判断该位置首节点是不是要查找的节点 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果该位置上的节点是红黑树结构，执行红黑树的查找方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //遍历查找链表寻找目标节点是否存在 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://zcy-fover.github.io/tags/HashMap/"}]},{"title":"java/源码学习/Java8 ConcurrentHashMap","date":"2020-04-18T03:22:27.940Z","path":"2020/04/18/java/源码学习/Java8 ConcurrentHashMap/","text":"Java8 ConcurrentHashMapConcurrentHashMap 和 HashMap 是相同的，但是在并发环境下 ConcurrentHashMap 可以保证线程安全。Java7 中 ConcurrentHashMap 是一个 Segment 对象数组，Segment 继承了 ReentrantLock 来加锁，所以每次加锁操作的都是一个 Segment，这样只要保证每个 Segment 线程安全继而实现全局线程安全。在扩容时只是对 Segment 数组某个位置的 HashEntry[] 扩为原来两倍。 Java8 中通过 CAS 和 synchronized 实现并行访问。 实现 CAS 主要通过三个步骤： 读取元素 element 的值，赋值为 temp； 对 temp 进行操作 读取 element 的值，比较 temp 和 element 是否相等，如果想等则写入，不想等则循环步骤 1在第三步的比较写入操作，操作系统是可以保证原子性的。 init 对象初始化1234567891011121314151617//例如这个构造函数，主要是计算 sizeCtl 的值，对初始化容量 initialCapacity * 1.5 + 1，然后向上取最近的 2 的 n 次方幂public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125;private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; sizeCtl 的值 -1：表示正在初始化 -N：表示有 N-1 个线程正在执行扩容操作 0：表示还未执行初始化 N：表示初始化或下次扩容的大小 工具方法tabAt1234567/** * 利用 Volatile 的可见性和有序性获取 tab 中下标为 i 的节点 */@SuppressWarnings(\"unchecked\")static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; casTabAt123456789/** * 基于 CAS 操作将 tab 中下标为 i 的节点更新为 v */static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; //((long)i &lt;&lt; ASHIFT) + ABASE：计算 i 在数组 tab 中的偏移量； //c：原对象 //v：新节点 return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; setTabAt123456/** * 保证有序性和可见性在 tab 中下标为 i 的位置插入节点 v */static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; put 函数分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //在 ConcurrentHashMap 中，节点的 key 和 value 都不能为空，这与 HashMap 中不同 if (key == null || value == null) throw new NullPointerException(); //计算 hash 值 int hash = spread(key.hashCode()); //记录对应数组位置上的链表长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) //如果数组为空则进行初始化 tab = initTable(); //计算节点 key 的索引位置，用 f 指向该位置第一个节点 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果数组该位置为空，利用 CAS 操作将节点插入到当前位置 //插入成功则结束循环 //插入失败，则结束本次循环，进行下一次循环，看是否可以插入 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //fh 如果是 -1 时，表示需要进行扩容和数据迁移 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; //该位置头节点 f 不为空 V oldVal = null; //对该位置头节点 f 加锁 synchronized (f) &#123; //确保节点没有被改变 if (tabAt(tab, i) == f) &#123; //如果数组没有在进行扩容，首节点 hash 值大于 0，则是链表？？？ if (fh &gt;= 0) &#123; //记录链表的长度 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //判断是否存在重复的 key，并且判断是否要进行替换 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; //如果数组首位置节点是红黑树类型，插入新节点 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果是链表，计算当前节点个数是否需要转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; addCount 元素计数在并发情况下，对元素个数计数的方法也不是那么简单了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @param x 增加的节点个数 * @param check if &lt;0, don't check resize, if &lt;= 1 only check if uncontended */private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //counterCells 并发情况下辅助计数的数组 //尝试将 baseCount 加 1 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; //如果 as 为空，尚未出现并发 //ThreadLocalRandom 在当前线程中获取随机数；随机获取数组某个位置为空 //CAS 修改上面位置的值失败，则出现了并发 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; //将 baseCount 与计数盒子所有数求和 s = sumCount(); &#125; //检查是否需要扩容 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //当数组大小已经超过阈值 //数组不为空 数组的长度没有超过最大容量 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; //根据数组容量计算得到一个标识；测试：n=16 =&gt; rs=32795; n=0 =&gt; rs=32800; n=1&lt;&lt;30 =&gt; rs=32769 int rs = resizeStamp(n); //sc &lt; 0，说明正在扩容了 if (sc &lt; 0) &#123; //这里没有看明白，sc 是一个负数，rs 是一个正数，为什么 rs + 1 会存在等于 sc //后面扩容过程中会对 sizeCtl 的值进行调整，但是这里的条件判断没有完全明白 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //迁移数据前将 sc 的值设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)，迁移过程中会更改 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; 初始化数组 initTable123456789101112131415161718192021222324252627282930private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; &#x2F;&#x2F;初始化时有可能没有获取到锁，所以循环初始化过程直到当前线程初始化完成或者别的线程初始化完成 while ((tab &#x3D; table) &#x3D;&#x3D; null || tab.length &#x3D;&#x3D; 0) &#123; if ((sc &#x3D; sizeCtl) &lt; 0) &#x2F;&#x2F;sc &lt; 0，则当前线程没有获取到锁 &#x2F;&#x2F;yield 函数通知线程调度器放弃对处理器占用，但是调度器可以忽略该通知 &#x2F;&#x2F;yield 让当前线程从“运行状态”进入“就绪状态”，将当前线程放入同优先级等待队列，把 CPU 时间让给其他线程执行，再次等待获取 CPU 时间片。 Thread.yield(); &#x2F;&#x2F; lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; &#x2F;&#x2F;SIZECTL 表示的是 sizeCtl 在 this 中的偏移量，在写入时需要使用 &#x2F;&#x2F;通过CAS操作将 sc 赋值为 -1，表示获取到了锁 try &#123; if ((tab &#x3D; table) &#x3D;&#x3D; null || tab.length &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;构造函数没有设置初始化容量使用默认：16 int n &#x3D; (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt &#x3D; (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table &#x3D; tab &#x3D; nt; &#x2F;&#x2F;计算阈值，相当于 n * 3&#x2F;4 sc &#x3D; n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl &#x3D; sc; &#125; break; &#125; &#125; return tab;&#125; helpTransfer 协助扩容1234567891011121314151617181920212223242526272829/** * 当头节点的 hash 值为 -1，说明 table 正在对节点进行扩容操作， * 当前节点协助扩容 */final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; //ForwardingNode 扩容节点，在扩容过程中使用，不存储数据 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; //根据 length 计算标示符 int rs = resizeStamp(tab.length); //如果 nextTab、table 指向没有被其他线程修改并且 sc 小于 0，说明还在扩容 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; //sc 无符号右移 16 位，不等于 rs；说明 sc 的高 16 位保存的就是标示位，但是怎么保存的没懂？？？ //sizeCtl == rs + 1 //sizeCtl == rs + 65535，达到最大辅助线程数 //transferIndex &lt;= 0 转移下标正在调整 //扩容结束 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; //sizeCtl 加 1，增加一个线程辅助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; transfer 数据迁移数据迁移的时候，也是多线程迁移，每个线程负责一个范围 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n &#x3D; tab.length, stride; &#x2F;&#x2F;cpu 如果是多核，length &#x2F;8 ，然后将桶平均划分到每个 CPU 上，如果划分后小于16，stride 就等于 16 &#x2F;&#x2F;这么做的原因是，如果数据迁移任务较多，就放到多个 CPU，处理，如果较少就一个 CPU 处理 &#x2F;&#x2F;假设有 512 个数组要迁移，CPU 为双核：则把任务分为了 16 份，每份负责 32 个数组元素，把 32 个元素看作一个桶 if ((stride &#x3D; (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) &#x2F; NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride &#x3D; MIN_TRANSFER_STRIDE; &#x2F;&#x2F; subdivide range &#x2F;&#x2F;新的 table 没有初始化 if (nextTab &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) &#x2F;&#x2F;将新的数组扩容为原来的两倍 Node&lt;K,V&gt;[] nt &#x3D; (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab &#x3D; nt; &#125; catch (Throwable ex) &#123; &#x2F;&#x2F; try to cope with OOME sizeCtl &#x3D; Integer.MAX_VALUE; return; &#125; nextTable &#x3D; nextTab; transferIndex &#x3D; n; &#125; int nextn &#x3D; nextTab.length; &#x2F;&#x2F;迁移节点，表示当前节点已经在迁移数据了，别的线程遇到后则跳过 ForwardingNode&lt;K,V&gt; fwd &#x3D; new ForwardingNode&lt;K,V&gt;(nextTab); &#x2F;&#x2F;表示当前位置是否处理完成，是否需要继续向前推进 boolean advance &#x3D; true; &#x2F;&#x2F;为 true，表示完成了迁移 boolean finishing &#x3D; false; &#x2F;&#x2F; to ensure sweep before committing nextTab &#x2F;&#x2F;无限循环，bound 表示当前线程可以处理的桶区间的最小下标 for (int i &#x3D; 0, bound &#x3D; 0;;) &#123; Node&lt;K,V&gt; f; int fh; &#x2F;&#x2F;当前线程领取任务的标记，如果领取了一个任务，则进行后面的处理，处理完了之后在桶里领取下一个 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;&#x3D; bound || finishing) &#x2F;&#x2F;i - 1 后大于bound，说明任务还未处理完，可能还需要领取任务 &#x2F;&#x2F;如果是第一次进入，需要走后面的 nextIndex 赋值 advance &#x3D; false; else if ((nextIndex &#x3D; transferIndex) &lt;&#x3D; 0) &#123; &#x2F;&#x2F;transferIndex &lt;&#x3D; 0，表示所有区间都有线程在处理了，当前线程完成任务 i &#x3D; -1; advance &#x3D; false; &#125; &#x2F;&#x2F;这里就是当前线程在领取任务了，划分好自己需要处理的任务区间 else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex, nextBound &#x3D; (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; &#x2F;&#x2F;当前线程可以处理的区间的最小下标 bound &#x3D; nextBound; &#x2F;&#x2F;当前线程可以处理的区间的最大下标 i &#x3D; nextIndex - 1; &#x2F;&#x2F;当一个桶的任务处理完了之后在领取下一个桶 advance &#x3D; false; &#125; &#125; &#x2F;&#x2F;i &lt; 0，说明该区间已经处理完成 if (i &lt; 0 || i &gt;&#x3D; n || i + n &gt;&#x3D; nextn) &#123; int sc; &#x2F;&#x2F;已经全部完成了扩容，则结束 if (finishing) &#123; nextTable &#x3D; null; table &#x3D; nextTab; sizeCtl &#x3D; (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; &#x2F;&#x2F;表示当前线程完成了扩容，尝试将 sizeCtl - 1 if (U.compareAndSwapInt(this, SIZECTL, sc &#x3D; sizeCtl, sc - 1)) &#123; &#x2F;&#x2F;如果相等了说明全部扩容已经完成了，在扩容之前的时候是把 sc 做了(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)处理 if ((sc - 2) !&#x3D; resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing &#x3D; advance &#x3D; true; i &#x3D; n; &#x2F;&#x2F; recheck before commit &#125; &#125; &#x2F;&#x2F;获取 tab[i] 节点，如果为空 else if ((f &#x3D; tabAt(tab, i)) &#x3D;&#x3D; null) &#x2F;&#x2F;放入 fwd 节点表示当前节点已经在处理了 advance &#x3D; casTabAt(tab, i, null, fwd); else if ((fh &#x3D; f.hash) &#x3D;&#x3D; MOVED) &#x2F;&#x2F;当前节点已经处理过了 advance &#x3D; true; &#x2F;&#x2F; already processed else &#123; &#x2F;&#x2F;还没有还是处理，对当前节点加锁 synchronized (f) &#123; &#x2F;&#x2F;再次判断还是否是 f 节点 if (tabAt(tab, i) &#x3D;&#x3D; f) &#123; Node&lt;K,V&gt; ln, hn; &#x2F;&#x2F; f 节点的 hash 值大于 0，treeBin 的 hash 值是 -2 if (fh &gt;&#x3D; 0) &#123; &#x2F;&#x2F;这里的处理也与 HashMap 类似，将原来的链表分为两部分： &#x2F;&#x2F;第一部分 hash &amp; n &#x3D; 0 &#x2F;&#x2F;第二部分 hash &amp; n !&#x3D; 0 int runBit &#x3D; fh &amp; n; Node&lt;K,V&gt; lastRun &#x3D; f; &#x2F;&#x2F;循环找到 lastRun 节点 for (Node&lt;K,V&gt; p &#x3D; f.next; p !&#x3D; null; p &#x3D; p.next) &#123; int b &#x3D; p.hash &amp; n; if (b !&#x3D; runBit) &#123; runBit &#x3D; b; lastRun &#x3D; p; &#125; &#125; &#x2F;&#x2F;判断 lastRun 往后的节点是放在新数组 nextTab[i] 位置还是 nextTab[i + n] 位置 if (runBit &#x3D;&#x3D; 0) &#123; ln &#x3D; lastRun; hn &#x3D; null; &#125; else &#123; hn &#x3D; lastRun; ln &#x3D; null; &#125; for (Node&lt;K,V&gt; p &#x3D; f; p !&#x3D; lastRun; p &#x3D; p.next) &#123; int ph &#x3D; p.hash; K pk &#x3D; p.key; V pv &#x3D; p.val; if ((ph &amp; n) &#x3D;&#x3D; 0) ln &#x3D; new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn &#x3D; new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; &#x2F;&#x2F;迁移到新的数组中，将旧的数组的 i 位置设置为正在迁移节点 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); &#x2F;&#x2F;当前数组位置处理完毕，for 循环，i 往前推进，判断当前桶里还有没有数组需要处理 advance &#x3D; true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t &#x3D; (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo &#x3D; null, loTail &#x3D; null; TreeNode&lt;K,V&gt; hi &#x3D; null, hiTail &#x3D; null; int lc &#x3D; 0, hc &#x3D; 0; &#x2F;&#x2F;头节点是红黑树，也是将原来的树分为两部分 for (Node&lt;K,V&gt; e &#x3D; t.first; e !&#x3D; null; e &#x3D; e.next) &#123; int h &#x3D; e.hash; TreeNode&lt;K,V&gt; p &#x3D; new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) &#x3D;&#x3D; 0) &#123; if ((p.prev &#x3D; loTail) &#x3D;&#x3D; null) lo &#x3D; p; else loTail.next &#x3D; p; loTail &#x3D; p; ++lc; &#125; else &#123; if ((p.prev &#x3D; hiTail) &#x3D;&#x3D; null) hi &#x3D; p; else hiTail.next &#x3D; p; hiTail &#x3D; p; ++hc; &#125; &#125; &#x2F;&#x2F;如果将原来的树分为两部分后，节点个数小于 6，则把树转换为链表然后放到新数组的对应位置 ln &#x3D; (lc &lt;&#x3D; UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc !&#x3D; 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn &#x3D; (hc &lt;&#x3D; UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc !&#x3D; 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance &#x3D; true; &#125; &#125; &#125; &#125; &#125;&#125; get 函数分析1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; &#x2F;&#x2F;计算 key 的 hash 值 int h &#x3D; spread(key.hashCode()); &#x2F;&#x2F;tab 不为空，并且 tab[(n - 1) &amp; h)] 位置不为空；tabAt 这里用了 volatile 属性来读取 if ((tab &#x3D; table) !&#x3D; null &amp;&amp; (n &#x3D; tab.length) &gt; 0 &amp;&amp; (e &#x3D; tabAt(tab, (n - 1) &amp; h)) !&#x3D; null) &#123; if ((eh &#x3D; e.hash) &#x3D;&#x3D; h) &#123; &#x2F;&#x2F; 判断头节点是否就是目标节点 if ((ek &#x3D; e.key) &#x3D;&#x3D; key || (ek !&#x3D; null &amp;&amp; key.equals(ek))) return e.val; &#125; &#x2F;&#x2F;如果 eh &lt; 0。可能正在扩容或者当前节点是红黑树 else if (eh &lt; 0) &#x2F;&#x2F;这里会在运行时根据 e 的实例类型是 TreeNode 还是 FowardingNode 调用对应的 find 方法 return (p &#x3D; e.find(h, key)) !&#x3D; null ? p.val : null; &#x2F;&#x2F;循环遍历链表查找目标节点 while ((e &#x3D; e.next) !&#x3D; null) &#123; if (e.hash &#x3D;&#x3D; h &amp;&amp; ((ek &#x3D; e.key) &#x3D;&#x3D; key || (ek !&#x3D; null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 总结在 ConcurrentHashMap 中要进行一些数据操作时，大体上三个判断： 数组是否存在 数组是不是正在进行扩容 对目标数组位置加锁进行后续处理 对于红黑树，由于需要知道红黑树数据结构的操作，等学习了红黑树后在看。如果了解红黑树，也就是在前面的框架下进行链表与树的转换，以及节点的增、删、查。 在 ConcurrentHashMap 学习过程中还有很多地方没有看懂： 当有新的线程协助扩容时，判断扩容是否已经结束的几个条件 红黑树相关需要继续学习 多核多线程进行数据迁移时，各个控制条件处理 都没有完全看懂，膜拜 Doug Lea 大佬的设计。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://zcy-fover.github.io/tags/HashMap/"}]},{"title":"数据存储/MySQL/05.高性能索引","date":"2020-03-27T02:13:08.000Z","path":"2020/03/27/数据存储/MySQL/05.高性能索引/","text":"索引方便存储引擎快速查找，索引可以包含一列或多列。 索引的类型B-Tree 索引即是 BTree，在不同的存储引擎底层可会有不同的实现，NDB 存储引擎内部使用 T-Tree 结构存储；InnoDB 使用的是 B+Tree。 BTree对索引列是顺序存储的， BTree可以加快访问数据的速度，使存储引擎不在需要全表扫描，从索引的根节点开始搜索。 可以使用 BTree 索引的查询类型123456789create table index_test( aa varchar(10) not null, bb varchar(10) not null, cc varchar(10) not null, dd varchar(10) not null, key(aa, bb, cc));insert into index_test(aa, bb, cc, dd) values(&quot;a1&quot;, &quot;b1&quot;, &quot;c1&quot;, &quot;d1&quot;),(&quot;a2&quot;, &quot;b2&quot;, &quot;c2&quot;, &quot;d2&quot;),(&quot;a3&quot;, &quot;b3&quot;, &quot;c3&quot;, &quot;d3&quot;); 全值匹配：和索引中的所有列进行匹配；上述索引可以用于查找 aa=a1,bb=b1,cc=c1 的行 匹配最左前缀：即组合索引中使用索引的第一列；可以查找 aa=a1 的行 匹配列前缀：匹配某一列值的开头部分；可以查找 aa 列以 a 开头的行 匹配范围值：查找 aa 在 a1 和 a3 之间的行 精确匹配某一列并范围匹配另外一列：可以查找 aa=a1 AND bb=&#39;%b&#39; 的行 只访问索引的查询： BTree索引限制 如果不是按照索引的最左列开始查找则无法使用索引；无法使用索引查找 cc=c3 的行 不能跳过索引的列；例如 aa=a1 AND cc=c1 则只使用了第一列索引，第三列索引未使用 查询中有某个列的范围查询则其右边的列都无法使用索引查询，例如 WHERE aa=&quot;a1&quot; AND BB = &quot;%1&quot; AND cc=&quot;c1&quot; 中 CC 这里只能使用索引的前两列 在实际的业务项目中给那些列加索引需要重点分析，在编码过程中 WHERE 列的匹配顺序也很重要。 哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效，存储引擎会给每一行的索引列计算一个哈希码，不同键值的行计算出的哈希码不一样，哈希索引将所有的哈希吗存储在索引中并在哈希表中保存了索引指向每一行数据的指针。如果哈希码计算产生了哈希冲突，哈希索引会以链表的方式存储在一个哈希条目中。 在具体的查询中，先计算查询条件的哈希值，然后在哈希索引中查找对应索引然后根据数据指针找到对应的数据行比对数据是否是要查询的数据 哈希索引的限制 哈希索引中只存索引值和行数据指针，所以不能根据索引直接比对数据，需要定位到对应的行 哈希索引并不是按照索引值排序存储的，也就无法用于排序 哈希索引不支持部分索引列匹配查找，哈希索引是根据索引列的全部内容来计算索引值的，在hash(aa, bb)上建立哈希索引，如果只是用 aa列查找则无法使用索引 由于哈希索引的计算和存储格式，只能支持等值(= IN &lt;=&gt;)查找不支持范围查找 哈希冲突较少时，哈希索引的访问速度非常快；哈希冲突多的时候会造成索引维护成本变高，也会造成查询效率变低 InnoDB 的自适应性哈希索引会在某个索引被频繁使用时，在 B-Tree 索引之上在建立一个哈希索引。 空间数据索引(R-Tree)MyISAM 支持空间索引，可以做地理数据存储。可以从所有维度来索引数据，可以从任意维度组合索引查询。但是必须使用 MySQL 的 GIS 相关函数 MBRCONTAINS() 来维护数据，在这个方面 PostgreSQL 支持的较好。 全文索引适合查找文本中的关键字，而不是比较索引中的值。全文索引更适合做搜索引擎。 聚簇索引将数据与索引放在一起存储，避免数据冗余存储所以一个表只有一个聚簇索引。聚簇索引默认使用主键作为 key，没有主键使用唯一键，还没有的话使用 6 字节的 rowId。 索引的优点 大大减少服务需要扫描的数据量 索引可以帮助服务器避免排序和建立临时表 将随机 IO 变为顺序 IO 索引为查询提供了很好的性能，但是当表的数据量特别大时，维护索引的代价也会增加。 索引策略独立的列查询条件中的列需要是独立的，列不能是表达式的一部分，也不能是函数的参数 前缀索引和索引选择性索引的选择性是指不重复的索引值和数据表的记录总数(T)的比值，范围是从 1/T ~ 1 唯一索引的选择性是最好的性能也是最好的。 对于一些数据类型必须要使用前缀索引(BLOB、TEXT、过长的VARCHAR)，索引这些列的完整长度，资源耗费太大。前缀索引的长度也是需要根据具体的数据分析。前缀索引是的索引更小更快但是 MySQL 无法使用前缀索引做 GROUP BY、ORDER BY 和覆盖扫描。 组合索引创建索引的时候并不是给每个列创建索引，可以结合具体的业务查询，可以创建多列索引。尽可能是的索引的选择性更高。 当服务器对多个索引做相交操作(多个 AND 条件)时，这时建立包含相关列的组合索引效果会更好 当服务器对多个索引做相交操作(多个 OR 条件)时，通常会耗费大量 CPU、内存资源在缓存、排序和合并操作上 索引顺序在一个多列索引中，索引列顺序按照最左匹配开始，所以索引列的顺序很重要。一般情况下将选择性最高的索引列放在最左边，这样可以降低后面索引列的查找范围。这个在 B-Tree 索引中有介绍。 聚簇索引聚簇索引并不是一种索引类型，而是一种数据存储方式。索引依赖与具体的存储引擎，并不是所有的存储引擎都实现了聚簇索引，InnoDB 的聚簇索引叶子节点保存了 key 和数据行，非叶子只保存 key。因为保存了数据行，所以一个表只能有一个聚簇索引。InnoDB 将主键作为聚簇索引的 key，如果没有主键使用唯一键，还没有的话会定义一个隐式的主键来作为聚簇索引。 优点： 索引和数据保存在一起，找到索引即找到数据，数据访问更快 使用覆盖索引扫描的查询可以直接使用叶节点的主键值 缺点： 对于 I/O 密集的应用聚簇索引可以提高查询的性能，但是如果数据都放在内存中时这种优势就下降了 聚簇索引的叶子节点是有序的，当插入新的数据时，插入速度依赖于主键顺序。 当要更新聚簇索引的索引列，这样可能引起底层叶子节点的数据迁移，这样会影响插入性能 当插入数据和更新索引列，有可能会引起“页分裂”(新插入的行和索引变化列需要放到某个已满的页)，这个时候需要将已满页的数据调整，叶子节点要调整上层非叶子节点也可能要调整。 聚簇索引可能会导致全表扫描变慢。尤其是行比较稀疏的情况，这是因为数据行分布在不同的页上，需要将数据加载到内存，此时 I/O 的损耗较大。 建立了聚簇索引，会导致二级索引(非聚簇索引)访问需要两次查找，先在二级索引查到对应的主键列然后在聚簇索引中查找数据。前面说的 InnoDB 引擎自适应性哈希可以减少这样的工作。二级索引存储主键列不是行指针，这样可以减少页分裂和行移动时的二级索引维护工作 可以看到建立聚簇索引主键的性质对于聚簇索引很重要，如果主键是有序自增长的则在插入数据时会更方便一点。如果是随机的例如 UUID，则会存在几个缺点： 插入的数据不一定是在最后可能是已有数据的中间，这样可能导致 InnoDB 不得不频繁的做页分裂，以便为新的行数据分配空间 数据航要写入的页可能已经刷到磁盘上并从缓存中移除，或者还没有被加载到缓存中，此时要插入数据时需要先从磁盘读取页数据，增大了 I/O 开销 频繁的页分裂，页会变的稀疏并被不规则的填充最终有数据碎片产生 当然顺序的主键因为要控制自增，在并发情况下可能会导致间隙锁竞争和 AUTO_INCREMENT锁竞争 覆盖索引索引的叶子节点已经包含(覆盖)了要查找的字段，不需要在回表查询。所以索引在设计上要尽可能多考虑到后续的查询场景。覆盖索引对于性能的提升很有帮助。 覆盖索引必须要存储索引列的值，MySQL 只能使用 B-Tree 做覆盖索引 索引条目远小于数据行，所以如果只读取索引，可以减少缓存的负载、I/O 的消耗 索引按照列值顺序存储，对于 I/O 密集型的范围查询比随机读取每一行数据的 I/O 要少 MyISAM 在内存中缓存索引，访问数据时需要访问磁盘进行一次系统调用。如果在内存中可以直接获取性能会更好 二级索引存在查询聚簇索引的情况，如果二级索引能够覆盖查询则可以避免对主键索引的二次查询 使用索引做排序扫描索引本身是很快的，但是索引要是没有完全包含要查询的列，则需要在查询的时候回表查询对应的数据行，这样的话反而比顺序全表扫描慢了。 当索引的列顺序和 ORDER BY 的列顺序完全一致，并且所有列的排序方向 都一样时才能使用索引排序；如果查询关联多张表只有当 ORDER BY 子句引用的字段全部是第一个表的才能使用索引排序，ORDER BY 也要求满足索引的最左前缀匹配原则。当前导列为常量时， ORDER BY 不满足最左前缀要求也可以用索引排序。 压缩(前缀压缩)索引MyISAM 使用前缀压缩来减少索引的大小，让内存可以存放更多的索引。MyISAM 压缩每个索引块的方法是：保存索引块中的第一个值，然后把后面的索引对比得到相同的前缀部分和不同的后缀部分，把这部分存储起来即可。例如：第一个索引是 abcd，第二个是 abcdefg，第二个所以压缩存储后是 4,efg。MyISAM 对行指针也采取类似存储做法。 压缩块减少了存储空间但是在查询时每个索引值计算依赖前面的值，使得查找时无法使用二分查找只能从头开始扫描。 冗余和重复索引重复索引是指在相同的列上按照相同的顺序创建相同类型的索引，例如给主键再加索引 冗余索引是指要创建的索引已经可以被包含在其他的索引中，例如已经有 KEY(a, b)，再创建 KEY(a)，此时 (a) 是 (a, b) 的前缀索引。所以创建索引的时候应该尽量在之前的基础上进行扩展而不是一味新建索引。但是扩展时也得考虑扩展后会不会导致索引的维护成本变得更高。 删除未使用的索引在前期架构设计时可能存在缺陷，存在一些无用的索引，可以利用 INFORMATION_SCHEMA.INDEX_STATISTICS 查看使用频率低的索引，将其删除。 索引和锁索引可以在查询的时候锁定更少的行，减少 InnoDB 访问的行数，InnoDB 在二级索引上使用共享(读)锁，但访问主键索引需要排他(写)锁。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://zcy-fover.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"查询","slug":"查询","permalink":"https://zcy-fover.github.io/tags/%E6%9F%A5%E8%AF%A2/"}]},{"title":"数据存储/MySQL/mysql执行计划","date":"2020-03-24T12:49:05.954Z","path":"2020/03/24/数据存储/MySQL/mysql执行计划/","text":"mysql执行计划​ 在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。 ​ 可以使用explain+SQL语句来模拟优化器执行SQL查询语句，从而知道mysql是如何处理sql语句的。 ​ 官网地址： https://dev.mysql.com/doc/refman/5.5/en/explain-output.html 1、执行计划中包含的信息 Column Meaning id The SELECT identifier select_type The SELECT type table The table for the output row partitions The matching partitions type The join type possible_keys The possible indexes to choose key The index actually chosen key_len The length of the chosen key ref The columns compared to the index rows Estimate of rows to be examined filtered Percentage of rows filtered by table condition extra Additional information id select查询的序列号，包含一组数字，表示查询中执行select子句或者操作表的顺序 id号分为三种情况： ​ 1、如果id相同，那么执行顺序从上到下 1explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal; ​ 2、如果id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 1explain select * from emp e where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); ​ 3、id相同和不同的，同时存在：相同的可以认为是一组，从上往下顺序执行，在所有组中，id值越大，优先级越高，越先执行 1explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); select_type 主要用来分辨查询的类型，是普通查询还是联合查询还是子查询 select_type Value Meaning SIMPLE Simple SELECT (not using UNION or subqueries) PRIMARY Outermost SELECT UNION Second or later SELECT statement in a UNION DEPENDENT UNION Second or later SELECT statement in a UNION, dependent on outer query UNION RESULT Result of a UNION. SUBQUERY First SELECT in subquery DEPENDENT SUBQUERY First SELECT in subquery, dependent on outer query DERIVED Derived table UNCACHEABLE SUBQUERY A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query UNCACHEABLE UNION The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY) 12345678910111213141516171819202122232425262728--sample:简单的查询，不包含子查询和unionexplain select * from emp;--primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primaryexplain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;--union:若第二个select出现在union之后，则被标记为unionexplain select * from emp where deptno = 10 union select * from emp where sal &gt;2000;--dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响explain select * from emp e where e.empno in ( select empno from emp where deptno = 10 union select empno from emp where sal &gt;2000)--union result:从union表获取结果的selectexplain select * from emp where deptno = 10 union select * from emp where sal &gt;2000;--subquery:在select或者where列表中包含子查询explain select * from emp where sal &gt; (select avg(sal) from emp) ;--dependent subquery:subquery的子查询要受到外部表查询的影响explain select * from emp e where e.deptno in (select distinct deptno from dept);--DERIVED: from子句中出现的子查询，也叫做派生类，explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;--UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存 explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size); --uncacheable union:表示union的查询结果不能被缓存：sql语句未验证 table 对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集 1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名 ​ 2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表 ​ 3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id type type显示的是访问类型，访问类型表示我是以何种方式去访问我们的数据，最容易想的是全表扫描，直接暴力的遍历一张表去寻找需要的数据，效率非常低下，访问的类型有很多，效率从最好到最坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 一般情况下，得保证查询至少达到range级别，最好能达到ref 12345678910111213141516171819202122232425262728293031--all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。explain select * from emp;--index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序explain select empno from emp;--range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, BETWEEN, LIKE, or IN() explain select * from emp where empno between 7000 and 7500;--index_subquery：利用索引来关联子查询，不再扫描全表explain select * from emp where emp.job in (select job from t_job);--unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引 explain select * from emp e where e.deptno in (select distinct deptno from dept); --index_merge：在查询过程中需要多个索引组合使用，没有模拟出来--ref_or_null：对于某个字段即需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式explain select * from emp e where e.mgr is null or e.mgr=7369;--ref：使用了非唯一性索引进行数据的查找 create index idx_3 on emp(deptno); explain select * from emp e,dept d where e.deptno =d.deptno;--eq_ref ：使用唯一性索引进行数据查找explain select * from emp,emp2 where emp.empno = emp2.empno;--const：这个表至多有一个匹配行，explain select * from emp where empno = 7369; --system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现 possible_keys ​ 显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key ​ 实际使用的索引，如果为null，则没有使用索引，查询中若使用了覆盖索引，则该索引和查询的select字段重叠。 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key_len 表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下长度越短越好。 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; ref 显示索引的哪一列被使用了，如果可能的话，是一个常数 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; rows 根据表的统计信息及索引使用情况，大致估算出找出所需记录需要读取的行数，此参数很重要，直接反应的sql找了多少数据，在完成目的的情况下越少越好 1explain select * from emp; extra 包含额外的信息。 12345678910111213141516--using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置explain select * from emp order by sal;--using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除explain select ename,count(*) from emp where deptno = 10 group by ename;--using index:这个表示当前的查询时覆盖索引的，直接从索引中读取数据，而不用访问数据表。如果同时出现using where 表名索引被用来执行索引键值的查找，如果没有，表面索引被用来读取数据，而不是真的查找explain select deptno,count(*) from emp group by deptno limit 10;--using where:使用where进行条件过滤explain select * from t_user where id = 1;--using join buffer:使用连接缓存，情况没有模拟出来--impossible where：where语句的结果总是falseexplain select * from emp where empno = 7469;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"执行计划","slug":"执行计划","permalink":"https://zcy-fover.github.io/tags/%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/"}]},{"title":"数据存储/MySQL/MySQL 内置函数","date":"2020-03-20T09:27:08.000Z","path":"2020/03/20/数据存储/MySQL/MySQL 内置函数/","text":"TIPSON DUPLICATE KEY UPDATE使用：作用：向数据库以相同unique或者primary key插入一条记录，若已经存在该key则更新这条记录，否则则新增一条记录； 示例： 1INSERT INTO TABLE_NAME(&#39;id&#39;, &#39;column2&#39;) VALUES(&#39;&#39;, &#39;&#39;) ON DUPLICATE KEY UPDATE id &#x3D; &#39;111&#39; MySQL字符串函数：ASCII(str)：作用：返回第一个字符串的ASCII码值；如果字符串为空则返回0； 示例： 12SELECT ASCII(&#39;2&#39;)&#96;&#96; ORD(str)：作用：如果字符串str句首是单字节返回与ASCII()函数返回的相同值。如果是一个多字节字符,以格式返回((first byte ASCII code)256+(second byte ASCII code))[256+third byte ASCII code…] 示例： 1SELECT ORD(&#39;2&#39;)","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"MySQL内置函数","slug":"MySQL内置函数","permalink":"https://zcy-fover.github.io/tags/MySQL%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"}]},{"title":"数据存储/MySQL/04.范式与反范式","date":"2020-03-20T07:31:08.000Z","path":"2020/03/20/数据存储/MySQL/04.范式与反范式/","text":"范式与反范式Schema 设计太多的列MySQL 存储 API 引擎在工作的时候需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码为各个列。但是这个过程代价是比较昂贵的，列越多代价就越大。MyISAM 的定长行结构实际上与服务器层的行结构刚好匹配，所以不需要转换；但是 MyISAM 的边长行结构与 InnoDB 的行结构总是需要转换。 太多的关联关联太多会导致查询性能和并发性降低 枚举使用数据库枚举导致设计凌乱，而且枚举变化时需要执行 ALTER TABLE 这对于业务应用影响较大，尽量在上层应用中实现枚举。 合理使用 NULL 值使用 NULL 值会使列的索引和索引统计难度增加，但是也不要完全摒弃。在特殊场景中合理使用避免自定特殊值导致应用出现其他问题。 范式化优点 更新操作比反范式化要更快 当数据很好的范式化时，就是有很少或者没有重复数据 范式化的表会更小 减少数据检索的难度，可以不使用 DISTINCT 或者 GROUP BY 缺点 设计上需要关联 反范式化会造成数据冗余但是没有关联是的查询会更高效。 混用范式化与反范式化可以具体分析业务数据，将两者结合起来使用。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"范式","slug":"范式","permalink":"https://zcy-fover.github.io/tags/%E8%8C%83%E5%BC%8F/"}]},{"title":"数据存储/MySQL/03.MySQL数据类型","date":"2020-03-20T03:27:46.000Z","path":"2020/03/20/数据存储/MySQL/03.MySQL数据类型/","text":"MySQL 数据类型选择最优的数据类型更小的通常更好：选择满足数据范围的最小数据类型，因为他们可以占用更少的磁盘、内存和 CPU 缓存，处理时需要的 CPU 周期也更少； 简单就好：简单的数据类型处理时需要更少的 CPU 周期；例如整型比字符操作代价更低； 尽量避免 NULL 值：可为 NULL 的列使得索引、索引统计和值比较都更复杂； 整数类型整数和实数可以用来存储整数，MySQL 有 TINTINT(8)、SMALLINT(16)、MEDIUMINT(24)、INT(32)、BIGINT(64)几种类型(数字表示 N 位存储空间)，值范围是 $-2^(N-1)~2^(N-1)-1$。 整数类型也可以选用 UNSIGNED 无符号数，上述所有类型正数部分扩大为原来的 2 倍。 MySQL 可以为整数类型指定宽度，这不会影响实际的数据存储。 实数类型带有小数的数，FLOAT(32)和DOUBLE(64)类型使用标准的浮点数进行近似计算，DECIMAL用于存储精确的小数。DECIMAL只是一种存储格式，在实际计算中转换为 DOUBLE类型。MySQL 使用 DOUBLE作为内部的浮点数计算类型。 字符串类型VARCHAR、CHAR是两种主要的字符串类型。 VARCHAR可存储变长字符串，必定长的类型更节省空间。如果 MySQL 表使用了 ROW_FORMAT=FIXED 创建的话，每一行会使用定长存储，这样比较浪费空间。 VARCHAR 需要使用额外 1 或 2 个字节记录字符串长度，最大长度小于等于 255 时，使用一个字节记录，否则使用 2 字节。VARCHAR 节省了存储空间能提高性能，但是这样也导致在 UPDATE 需要更多的额外工作。例如一个行占用的空间边长，但是当前页内空间不足，MyISAM 会将行拆成不同片段存储，InnoDB 需要分裂页来存储。 适合使用 VARCHAR 的情况：字符串列最大长度比平均长度大很多；列的更新较少，碎片较少；使用了像 UTF-8 这样复杂的字符集，每个字符使用不同的字节数存储。 CHAR定长存储，CHAR 比 VARCHAR 产生更少的碎片。对于单字节的字符串更适合用 CHAR 用 VARCHAR 会占用两个字节；CHAR 在存储字符串时会将字符串末尾的空格去掉。 BINARY 和 VARBINARY 与上面的类似，他们存储的是二进制字符串，二进制字符串与常规字符串类似，但是存储的是字节码而不是字符，填充的时候是 \\0 (0字节)，而不是空格，检索时也不会去掉填充。 BLOB 和 TEXT 类型更大的字符串数据类型，分别采用二进制和字符方式存储；两者分别对应有 TINYTEXT、SMALLTEXT、TEXT、MEDIUMTEXT、LOGTEXT；TINYBLOB、SMALLBLOB、BLOB、MEDIUMBLOB、LOGBLOB。BLOB 存储二进制数据，没有字符集和排序规则， TEXT 存储字符数据有字符集和排序规则。MySQL 在对这两个数据类型排序的时候不是针对整个字符串排序，而是没个列的最前 max_sort_length 字节做排序，或者使用 ORDER BY SUSTRING(column, length)。 ENUM 类型MySQL 会将每个值在列表中的位置保存为整数，并且在 .frm 文件中保存 数字-字符串 的映射关系表。 1234create table enum_test(ee ENUM(&#39;fish&#39;, &#39;apple&#39;, &#39;dog&#39;) not null);insert into enum_test(ee) values(&#39;fish&#39;, &#39;dog&#39;, &#39;apple&#39;);select ee+0 from enum_test; # 结果： 1 3 2select ee from enum_test order by ee; # 结果：fish apple dog 可以看到在列的存储中，enum 存储的是对应位置的整数而不是具体枚举值；在排序中也是按照整数输出不是具体的字符串插入顺序。枚举的字符串列表是建表的时候初始化的，所以要修改的时候需要 ALTER TABLE。 日期和时间类型DATETIME从 1001 ~ 9999 年，精度为秒。与时区无关，占用 8 个字节存储空间。 TIMESTAMP保存了从 1970-01-01 00:00:00 以来的秒数，只使用 4 个字节存储空间。MySQL 提供 FROM_UNIXTIME 将时间戳转换为日期， UNIX_TIMESTAMP 将日期转换为时间戳。 TIMESTAMP 比 DATETIME 的空间效率更高。如果需要存储微秒级别的时间戳，可以使用 BIGINT 或者 DOUBLE 存储秒之后的小数部分，也可以使用 MariaDB。 位数据类型BITBIT 列最大长度是 64 位，MySQL 把 BIT 当作字符串类型，存储的是包含二进制 0 1 的字符串，而不是 ASCII 码值。检索 BIT 列时，例如存储的是 b&quot;00110011&quot;，在字符串环境中得到的是 ASCII 码值为 51 的字符 “9”，如果是在数字环境中则得到的是数字 51。 123create table bit_test(bb bit(8));insert into bit_test(bb) values(b&#39;00110011&#39;);select bb, bb+0 from bit_test; # 输出： 3 51 SETSET 数据类型可以利用 FIND_IN_SET、FIELD 方便查询，但是 SET 集合的修改需要使用 ALTER TABLE 进行修改；一般情况 SET 列上也无法使用索引检索。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"}]},{"title":"数据存储/MySQL/02.MySQL性能剖析","date":"2020-03-17T12:06:20.000Z","path":"2020/03/17/数据存储/MySQL/02.MySQL性能剖析/","text":"MySQL 性能剖析通常指完成某件任务所需要的时间度量，也会考虑吞吐量、CPU利用率和可扩展性等等 性能优化原则： 性能即响应时间：性能优化就是在一定的工作负载下尽可能的降低响应时间；性能优化不是降低 CPU 使用率，降低资源消耗，CPU 和资源就是被用来消耗的，如果机器不超负载的情况下，尽量利用资源提高性能。 无法测量就无法优化：要能分析出执行的时间消耗在什么地方，这样才能谈优化 性能剖析 测量任务所花费的时间 对结果进行排序，将重要的任务排在前面 理解性能剖析 值的优化的查询：性能剖析并不会自动给出哪些需要优化，具体的情况需要自己根据实际业务、耗费精力情况来分析。 异常情况：有些任务出现的情况少，但是每次出现可能会造成异常或者导致了其他情况，可能虽然不是致命的。但是要认真分析解决，因为它可能是个不定时炸弹。 未知：性能剖析的工具会显示可能的“丢失时间”，即任务的实际处理时间和测量时间不一致。需要分析是什么情况造成，应用是不是还存在未知的处理。 被掩藏的细节：性能分析的结果不能只看平均值，突刺、标准差百分比等都需要关注 查询剖析剖析服务器负载 日志文件中捕获 MySQL 查询日志，是否存在慢查询日志。慢查询日志是重要的分析依据。 利用工具将查询日志解析为报告进行分析 剖析单条查询使用 SHOW PROFILE、使用SHOW STATUS、使用慢查询日志 、使用 Performance Schema 工具针对单条查询语句做分析","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"}]},{"title":"数据存储/MySQL/01.Mysql基准测试","date":"2020-03-16T03:47:26.000Z","path":"2020/03/16/数据存储/MySQL/01.Mysql基准测试/","text":"MySQL基准测试基准测试是观察系统在不同压力下的行为，评估系统的容量，掌握哪些变化是重要的，或者观察系统是如何处理不同的数据。他的主要问题就是他不是真实的压力测试，在正式的生产环境或者压力测试中，影响条件是多变的。 基准测试的策略 集成式：针对整个系统的整体测试 单组件式：单独测试 MySQL 测试指标吞吐量：单位时间内的事务处理量。TPS、TPM指标等 响应时间或延迟：测试任务所用的整体时间，计算出平均响应时间、最小响应时间、最大响应时间和所占百分比。 并发性：Web 服务器的并发性标识会话存储机制可以处理多少数据的能力，度量指标是任意时间有多少同时发生的并发请求。当并发性增加时需要关注的是吞吐量是否下降、响应时间是否延长，如果出现下降和延长的情况，那应用就有可能无法处理峰值流量。 可扩展性：系统的压力增加时，对应性能响应时间和吞吐量也应该线性增加。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"}]},{"title":"设计/设计模式/Head First设计模式","date":"2020-02-22T08:10:13.636Z","path":"2020/02/22/设计/设计模式/Head First设计模式/","text":"Head First设计模式OO基础 抽象、封装、多态、继承 设计原则 找出应用中可能需要变化之处，把他们独立出来，不要和那些不需要变化的代码混合在一起； 针对接口编程而不是针对实现编程 多用组合少用继承 开放关闭原则 最少知识原则：对象之间的交互要尽可能的少 策略模式 定义了算法族，分别封装起来，让他们之间可以互相替换，在这种模式下可以让算法的变化独立于他们的使用者 观察者模式 定义了对象之间的一对多依赖，这样当一个对象状态改变状态时，他的所有继承者都会收到通知并自动更新观察者模式让主题和观察者之间松耦合 装饰者模式 装饰者和被装饰者拥有共同的超类型 可以用一个或者多个装饰者对象包装对象 装饰者和被装饰对象拥有相同的超类，所以在任何需要使用超类型的地方都可以使用装饰过的对象代替 装饰者可以在被装饰者对象的行为之前或之后加上自己的行为 对象可以在任何时候被装饰 装饰者模式的装饰者的行为来自自己和组件组合，继承超类型知识为了保证 装饰者和被装饰这达到类型匹配 装饰者模式动态得将责任附加到对象上， 工厂模式 工厂模式通过让子类决定该创建什么对象来达到将创建对象的过程封装 依赖倒置 变量不可以持有具体类的引用 不要让类派生自具体类 不要覆盖基类中已经实现的方法 单例模式 确保一个类只有一个实例，并且可以提供全局访问点（类访问） 命令模式 命令模式将请求封装成一个对象，以便不同的请求、队列或日志来参数化其他对象。命令模式也支持撤销操作。 适配器模式 将一个类的接口转换成客户期望的另一个接口，适配器让原本不兼容的接口可以合作 对象适配器：通过组合实现 类适配器：通过多继承实现 外观模式 外观模式提供了一个统一的接口，用来访问系统中的一群接口。外观模式定义了一个高层接口，让子系统的功能调用更简单； 外观不只是简化了接口，也将客户从子系统的接口中解耦 外观和适配器可以包装很多类，但是外观模式知识简化了接口的使用，适配器模式是将接口转换成不同的接口； 模板方法模式 模板方法定义了一个算法的步骤，并允许子类为一个或多个步骤提供实现 模板方法可以使得子类在不改变算法结构的情况下，重新定义算法中的某些步骤 迭代器模式 提供一种方法顺序访问一个聚合对象的内部元素，而不暴露其内部的实现 组合模式 允许你将对象组合成树形结构来表现“ 整体 / 部分”层次结构，组合能让用户以一致的方式处理个别对象以及对象组合。 状态模式 状态模式允许对象在内部状态改变时改变他的行为，对象看起来好想改变了他的类。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zcy-fover.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"职业精神/代码整洁之道/代码整洁之道","date":"2020-02-22T08:07:46.828Z","path":"2020/02/22/职业精神/代码整洁之道/代码整洁之道/","text":"##《代码整洁之道》 勒布朗法则：稍后等于永不。 第一章 整洁代码 1、糟糕代码的原因 在我自己来看，写出糟糕代码可能是以下几个原因： 编程经验不够，没有意识到代码整洁的重要性，处于功能实现即可完成任务的阶段； 有“整洁代码、优化代码”的意识，在具体编程时，由于项目进度和时间的原因，没有时间去思考如何优化，如何使代码整洁。最后只能草草了事，完成任务即可。想着可以后续继续优化，但只是停留在这想法上了。 力不从心，有优化代码的想法，但是不知道该如何进行优化、整洁。或者是不知道如何深层次的进行优化。 2、整洁代码 在Bjarne Stroustrup认为，整洁代码： 在Grady Booch看来，整洁代码为： 整洁代码2 Dave Thomas认为： 整洁代码3 Michael Feathers认为： 整洁代码4 Ron Jeffries认为： 整洁代码5 第二章 有意义的命名1、文件命名 文件一般包括类、配置文件和资源文件。文件的命名一般是名次或者名次短语。 2、方法命名 这种类型的命名一般是动词或者动词短语。方法一般是为解决某个问题或者处理某种逻辑而存在的，在命名上最好是体现出这个方法的作用 3、属性命名 普通属性可以使用驼峰式；静态变量属性最好使用A_B_C式的。命名使用英语单词，避免中英混杂，名字最好可以体现这个属性所表达的意义。 第三章 函数 函数应当尽量的短； 函数的缩进层级最多应当为2级，注意在if、else、while、for等语句块里面应当只是一个函数调用，不应再嵌套； 函数应当只做好一件事。（看一个函数是否还可以拆分） 函数名称上面也叙述过了，不要担心函数名称长度。长而具有描述性的名称是可以被接受的，命名的风格要保持一致； 函数的参数应当尽可能的少，最多为三个； 函数的书写功底也并非一日之功，想写出高效简洁就可以写出来的，是需要有一定的代码积累，有一定的编程架构思想，懂得功能分解才能达到的境界，不然也只是部分优化或者不完全优化，达不到一个高标准。 第四章 注释 以前在自己看来，多写点注视应该总是没错的，对自己看代码或者后面的开发者看总是有益无害的。但是看了本书之后，纠结于以后到底要不要写注释，且现在来看自己以前写的都是烂注释，书中对于注释要求甚是严格： 1、好注释： 提供法律信息 提供代码的有效信息 说明意图，解释代码的意图，或者是输出什么结果 可以阐释代码的结果，以进行比对，但是务必要保证注释的正确性，避免风险 有警示作用的代码，提醒读者或者此处需要注意什么问题 利用TODO或者FIX注释，标识将来需要完成或者完善的功能 2、坏注释 坏注释 第五章 代码格式第六章 对象和数据结构1、影藏对象，暴露操作 过程式代码难以添加数据结构，因为必须修改所有的函数；面向对象代码难以添加新函数，因为需要修改所有的类。 第七章 错误处理 1、避免使用返回错误码，利用异常处理错误 2、使用catch finally去捕获异常，使用不可控异常，在方法上抛出异常，会违背接口设计的开放必和原则，在它的继承和使用方法上都得抛出该异常，在底层如果修改了代码，可能会影响到其他的方法调用 3、最好在代码中给出异常可能发生的环境 第八章 边界 没看太懂 第九章 单元测试1、重视测试 在项目团队中，如果不是有要求，我想应该是没有几分人会去主动写测试类的。所以首先有这个意识很重要。项目中也有测试团队这也许导致了开发有所依赖，所以不去编写测试代码或者是随意编写测试代码。但实际上编写简洁、整洁的测试代码是对自己的代码的检验，也是一种责任的体现，团队中每个环节、每个人都能超标保证自己的任务的质量，不去依赖下一个环节，项目的质量就会提高。 2、测试的F.I.R.S.T规则 快速(Fast): 测试代码的逻辑不应太过复杂，能够快速运行，如果测试代码运行过慢，可能就不会频繁进行测试了； *独立(Independent): *每个测试方法测试类应当独立，彼此之间不能有依赖，某个测试不能成为下一个测试的依赖条件，这会导致测试很复杂； 可重复(Repeatable): 测试不应该依赖环境，在任何环境中都应当测试通过，当测试不能在任意环境中重复测试时，说明代码中存在导致其失败的接口； 自足验证(Self-Validating): 么个测试方法运行都应当有true或false输出，测试者不应当通过查询日志或主观判断进行验证。 及时(Timely): 测试应及时编写，单元测试应当在使其通过的生产代码之前编写。否则生产代码编写好之后可能会由于生产代码的逻辑复杂就不会去编写测试代码了。 第十章 类第十一章 系统 “一开始就做对系统”是不可能的，我们应当只去实现用户当前的需求，然后对系统重构，实现新的用户需求。但是在我认为，在我们有了大数据之后，我们应该去探索、预测用户的需求，一味被动等待用户有了需求在去实现就有点落后了。 第十七章 味道与启发1、注释 不恰当的信息：注释只应当描述有关代码和设计的技术性信息 废弃的注释：应当即使删除掉或者更新 冗余的注释 糟糕的注释：写注释应当和写代码一样，要思考一下 注释掉的代码：应当及时删除 2、环境 需要多少步才能实现构建：应当使用单个命令签出系统，并用单个指令构建，系统的构建不应当是分小步或者是繁琐的。 需要多少步才能做到的测试：单元测试应当可以在一个指令下全部运行。 3、函数 过多的参数：一个函数的参数应当少于3个，多余三个时应当被封装成为一个对象； 输出参数：输出单数违反直觉，可以直接改变对象的状态 表示参数：函数中的标识参数过多说明函数做了不止一件事 死函数：没有被调用的函数应当删除掉 4、一般性问题 一个源文件存在多种语言：一个源文件的语言种类应当尽可能的少，降低文件的复杂性 明显的行为未被实现：函数的实现应当按照其描述或名字定义所形容的实现 不正确的边界行为：边界行为要靠编辑测试去发现不应当靠直觉 忽视安全：警告也有可能造成程序运行的错误，对于安全机制和警告应当去处理而不是视而不见 重复：代码中又重复说明代码还有可以优化和抽象的地方 在错误的抽象层级上的代码：抽象类和派生类的界限需要根据设计划分清楚 基类依赖于派生类： 信息过多： 死代码：删除系统中存在的死代码 垂直分割：变量函数的定义和位置，应当遵循前面章节所描述的 前后不一致：同类型的变量或方法取名定义时在系统中应当是一致的 混淆视听：没有实现的构造器、没有用到的变量、没有调用的函数、没有信息量的注释；这些都应当被疑除掉。 人为耦合：声明函数、变量和常量应当有统一的地方，而不是信手拈来的位置 选择算子参数： 晦涩的意图：代码要尽可能有表达力 位置错误的权责： 不恰当的静态方法：一般情况下尽量使用非静态函数，除非该函数没必要使用多态 使用解释性变量： 函数名称应该表达其行为： 理解算法; 用多态代替if\\else和switch\\case 遵循标准约定： 用命名变量代替魔术数： 准确：消除代码的不确定性 结构基于约定： 封装条件：通常if和while语句内的判断条件如果过多都是可以封装成为一个函数的 避免否定性条件：肯定是条件要比否定式条件好理解 函数只该做一件事： 掩蔽时序耦合：当调用函数的执行是有顺序的时候，可以通过调用显示执行 别随意 封装边界条件：编辑处理的代码应当集中在一处，不应散落在代码中 函数应该只在一个抽象层级上 在较高层级放置可配置数据 避免传递浏览 6、Java 通过使用通配符避免过长的导入清单 不要继承变量 常量和枚举 7、名称 采用描述性名称 名称应与抽象层级相符 尽可能使用标准命名法 无歧义的名称 为较大作用范围选用较长的名字 避免编码 函数名称应当与函数功能相符，不应当有副作用 8、测试 测试不足：测试的覆盖率没有达到100%，就是不足 使用测试覆盖率的工具 别略过小测试 被忽略的测试就是对不确定事物的疑问 边界条件的测试 全面测试相近的缺陷 测试失败的模式有启发性 测试覆盖率的模式有启发性 测试应该快速","tags":[{"name":"代码规范","slug":"代码规范","permalink":"https://zcy-fover.github.io/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"}]},{"title":"middle-service/apm/Skywalking/Skywalking介绍","date":"2020-02-22T08:01:24.987Z","path":"2020/02/22/middle-service/apm/Skywalking/Skywalking介绍/","text":"Skywalking 简介Skywalking背景 Apache 孵化器项目 加入 OneAPM 公司 Skywalking 介绍（分布式 APM 系统 / 分布式追踪系统） 全自动探针检测，不需要修改应用程序代码（可支持的中间件和组件：） 支持手动探针监控，用埋点的方式手动上传业务数据； SkyWalking提供了支持 OpenTracing 标准的 SDK。也支持 OpenTracing-Java 支持的组件 自动监控和手动监控可以同时使用，使用手动监控弥补自动监控不支持的组件，或者私有化组件； 纯 Java 后端分析程序，提供 RESTful 服务，可为其他语言探针提供分析能力； 高性能纯流式分析； 可将 traceId。集成到主流的日志框架中输出，如 log4j，logback 等 对应的 WEB 页面由单独的工程进行发布（sky-walking-ui） Skywalking 架构图 架构图 Skywalking-web：web 可视化平台，用来展示数据 skywalking-collector：链路数据归集器，数据可以落地 ElasticSearch，单机也可以落地 H2，不推荐，H2 仅作为临时演示用 skywalking-agent：探针，用来收集和发送数据到归集器 Skywalking 目前暴露的三个问题 现象： Agent 和 Collector 正常工作，没有异常日志 已经对系统进行过访问，Trace 查询有数据 UI 除 Trace 查询页面外，其他页面无数据 原因： Collector 和被监控应用的系统主机时间，没有同步 解决方法： 同步各主机操作系统时间 现象 ： Kafka 消息消费端链路断裂 原因： Kafka 探针只是追踪了对 Kafka 的拉取动作，而整个后续处理过程不是由 kafka consumer 发起。故需要在消费处理的发起点，进行手动埋点 解决方法: 可以通过 Application Toolkit 中的@Trace标注，或者 OpenTracing API 进行手动埋点 现象： 加载探针并启动应用 Console 中被 GRPC 日志刷屏 原因：Skywalking 采用了 GRPC 框架发送数据，GRPC 框架读取 log 的配置文件进行日志输出。 解决方法: 在log的配置文件中添加对org.apache.skywalking.apm.dependencies包的过滤 Dapper 的缺点 合并的影响：我们的模型隐含的前提是不同的子系统在处理的都是来自同一个被跟踪的请求。在某些情况下，缓冲一部分请求，然后一次性操作一个请求集会更加有效。（比如，磁盘上的一次合并写入操作）。在这种情况下，一个被跟踪的请求可以看似是一个大型工作单元。此外，当有多个追踪请求被收集在一起，他们当中只有一个会用来生成那个唯一的跟踪 ID，用来给其他 span 使用，所以就无法跟踪下去了。我们正在考虑的解决方案，希望在可以识别这种情况的前提下，用尽可能少的记录来解决这个问题。 跟踪批处理负载：Dapper 的设计，主要是针对在线服务系统，最初的目标是了解一个用户请求产生的系统行为。然而，离线的密集型负载，例如符合MapReduce[10]模型的情况，也可以受益于性能挖潜。在这种情况下，我们需要把跟踪ID与一些其他的有意义的工作单元做关联，诸如输入数据中的键值（或键值的范围），或是一个 MapReduce shard。 寻找根源：Dapper 可以有效地确定系统中的哪一部分致使系统整个速度变慢，但并不一定能够找出问题的根源。例如，一个请求很慢有可能不是因为它自己的行为，而是由于队列中其他排在它前面的(queued ahead of)请求还没处理完。程序可以使用应用级的 annotation 把队列的大小或过载情况写入跟踪系统。可以采用成对的采样技术可以解决这个问题。它由两个时间重叠的采样率组成，并观察它们在整个系统中的相对延迟。 记录内核级的信息：一些内核可见的事件的详细信息有时对确定问题根源是很有用的。我们有一些工具，能够跟踪或以其他方式描述内核的执行，但是，想用通用的或是不那么突兀的方式，是很难把这些信息到捆绑到用户级别的跟踪上下文中。我们正在研究一种妥协的解决方案，我们在用户层面上把一些内核级的活动参数做快照，然后绑定他们到一个活动的 span 上。 Skywalking竞品 同类型企业级收费产品 OneAPM：http://www.oneapm.com/ 透视宝：http://www.toushibao.com/product_server.html 华为：http://www.huaweicloud.com/product/apm.html?utm_source=Baidu&amp;utm_medium=cpc&amp;utm_campaign=CP-APM&amp;utm_content=CJ&amp;utm_term=APM Testin听云：https://www.testin.cn/ 开源工具 Twitter Zipkin：http://zipkin.io/ （finagle 分布式微服务框架） 美团点评 CAT：https://link.jianshu.com/?t=https://github.com/dianping/cat 应用性能管理工具 PinPoint：https://link.jianshu.com/?t=https://github.com/naver/pinpoint Apache HTrace：https://link.jianshu.com/?t=http://htrace.incubator.apache.org/","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Skywalking","slug":"Skywalking","permalink":"https://zcy-fover.github.io/tags/Skywalking/"}]},{"title":"middle-service/apm/Skywalking/Skywalking环境搭建","date":"2020-02-22T08:01:23.266Z","path":"2020/02/22/middle-service/apm/Skywalking/Skywalking环境搭建/","text":"Skywalking 环境搭建环境： Windows 7 x64 IDEA 2017.01 JDK 1.8 x64 Maven 3.5.0 源码获取： Skywalking Git可以利用 Git Clone 或者 ZIP 下载到本地； 利用 IDEA 选择 Maven 导入项目 项目结构 启动 Skywalking-collecor 在项目根目录下或者 IntelliJ IDEA Terminal 运行mvn clean compile install -Dmaven.test.skip=true； 编译完后设置 gRPC 自动生成代码的目录： apm-network/target/generated-sources/protobuf 下的grpc-java和java; GRPC设置 apm-collector/apm-collector-remote/collector-remote-grpc-provider/target/generated-sources/protobuf 下的grpc-java和java; gRPC设置 设置方法：在 grpc-java 上右键-&gt; Mark Directory as -&gt; Generated Souces Root 代码生成 运行org.skywalking.apm.collector.boot.CollectorBootStartUp的main(args)方法，启动 Collector； 在浏览器中输入http://127.0.0.1:10800/agent/jetty地址，返回 [&quot;localhost:12800/&quot;] ，说明启动成功。 启动 Skywalking-Agent 在 Skywalking 项目的同级新建一个 Web 项目 我这里新建了一个 SpringBoot 的项目（注意 SpringBootDemo 必须和 skywalking 项目平级，这样才可以调试 Agent） 项目结构 在org.skywalking.apm.agent.SkyWalkingAgent的premain()方法里打上断点； 在自己新建的Web项目，配置启动参数-javaagent:skywalking-agent.jar的路径（这里的路径可以绝对路径也可以是相对路径） agentJarPath web项目启动配置 启动Web项目，这里可能会出现agent.application_code is missing或者collector.servers is missing.的错误，我改了org.skywalking.apm.agent.core.conf.Config中的： 12public static String APPLICATION_CODE = \"SpringBootDemo\";public static String SERVERS = \"127.0.0.1:8080\"; 此时停掉之前启动的 skywalking-collector，重新运行mvn clean compile install -Dmaven.test.skip=true进行编译； 编译完成后再启动 skywalking-collector，然后启动自己的Web项目，如果程序进入了之前的org.skywalking.apm.agent.SkyWalkingAgent的premain()方法中的断点，并且 Web 项目启动成功则说明 Agent 模块启动成功。","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Skywalking","slug":"Skywalking","permalink":"https://zcy-fover.github.io/tags/Skywalking/"}]},{"title":"Spring/SpringCloud/SpringCloud介绍","date":"2020-02-22T07:58:59.550Z","path":"2020/02/22/Spring/SpringCloud/SpringCloud介绍/","text":"SpringCloud 学习示例项目微服务特点 按业务划分为一个独立运行的程序，即服务单元 服务之间通过 http 协议通信 自动化部署 可用不同的编程语言 可用不同的存储技术 服务集中化管理 微服务是一个分布式系统 微服务“微” 代码量 开发时间长短 业务大小 CAP C（Consistency 一致性）：数据写入成功，之后读取读到的都是写入后的数据 A（Availability 可用性）：服务的可用性 P（Partition-tolerance 分区容错性）：单台或多台服务出现问题后，其他正常的服务仍可以正常提供服务 微服务具有的功能 服务的注册和发现 服务的负载均衡 服务的容错 服务的网关 服务配置的统一管理 链路追踪 实时日志 Zookeeper和Eureka Zookeeper Eureka CAP 满足CP 满足AP 服务注册 当 master 节点 down 掉，剩余节点会重新选举 leader ，耗时30~120s，选取期间整个集群不可用，服务瘫痪 各个节点平等，当请求一个节点失败时会自动切换至另一个节点，但是不保证各个节点的强一致性 Eureka 还有一种自我保护机制，如果在 15 分钟内超过 85% 的节点都没有正常的心跳，那么 Eureka 就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： 1.Eureka 不再从注册列表中移除因为长时间没收到心跳而应该过期的服务 2. Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用) 3.当网络稳定时，当前实例新的注册信息会被同步到其它节点中 负载均衡 将负载分摊到多个执行单元上，常见的两种方式 独立进程单元，通过负载均衡策略，将请求发送到不同的执行单元上，例如 Nginx 将负载均衡以代码逻辑的形式封装到服务消费者的客户端上，服务消费者维护了一份服务提供者的信息列表，通过负载均衡策略将请求分摊给多个服务提供者 Feign 简化 Java Http 客户端远程调用 Feign 采用的是http网络交互，可以采用feign-httpclient或者okhttp做网络请求框架，只需要在pom中添加相关依赖即可。 Feign中负载均衡也是通过Ribbon来实现的。 Feign请求过程 通过 @EnableFeignClients 注解开启FeignClient功能； 根据Feign的规则实现接口，并在接口上面加上 @FeignClient 注解； 程序启动自动扫描 @FeignClient 注解的类，并注入到IoC容器； 当接口的方法被调用时，通过JDK代理生成具体的 requestTemplate 对象，生成 http 请求的 request 对象； 将 request 对象交给 Client 去处理，可以使用 HttpUrlConnection 、HttpClient 或 OkHttp； 最后 Client 被封装到 LoadBalanceClient 类，这个类结合 Ribbon 实现负载均衡。 Feign 可以直接配置 Hystrix 熔断器 Hystrix 通过隔离服务的访问点组织联动故障，提供故障的解决方案，提高整个分布式系统的弹性 设计原则 防止单个服务的故障耗尽整个那个服务的 Servlet 容器的线程资源 快速失败机制，当某个服务出现故障，则调用该服务的线程快速失败而不是线程等待 提供回退方案，请求发生故障时，按照提供的方案回退 使用熔断机制，防止故障扩大影响到其他服务 利用监控组件实时监控熔断器的状态 Hystrix工作机制 当某个API服务在一定时间内失败的次数大于设定阀值，触发熔断器打开，这时请求该API服务的接口会执行快速失败逻辑（即回退方案）。 处于打开状态的熔断器，一段时间后，会处于半打开半关闭状态，将一定数量的请求执行正常逻辑，剩余的请求执行快速失败逻辑，如果执行正常逻辑的请求失败了，则熔断器继续打开，如果成功了，则熔断器关闭。 测试 执行请求中，断开两个服务提供方的其中一个，在短时间内的请求上仍然可以负载到 done 掉的服务上。在停止两个服务提供方后则会执行 fallback 配置的方法。 Zuul 作用 Zuul、Ribbon 以及 Eureka 结合，可以实现智能路由和负载均衡，Zuul能够将请求流量按照某种策略分发到集群状态的多个服务实例； 网关将所有的服务 API 接口统一聚合，并统一对外暴露。外界系统无需关注内部服务，也保护了内部的微服务单元避免敏感信息对外暴露； 服务网关做用户身份认证和权限控制，防止非法请求操作API接口； 网关实现监控功能，实时日志输出，对请求做记录； 网关可以实现流量监控，在高流量的情况下，实现降级； API 接口从内部服务分离处理，方便做测试 微服务链路追踪 Sleuth Dapper 中的专业术语： Span：基本工作单元，发送一个远程调用服务就会产生一个 Span，Span 是一个64位的 ID， Span 包含了摘要、时间戳事件、Span 的 ID 以及进程的 ID 。 Trace：有一系列 Span 组成，呈树状结构。请求一个微服务系统的 API 接口，这个 API 接口需要调用多个微服务单元，每调用一个新的微服务单元都会产生一个 Span ，所有由这个请求产生的 Span 组成了这个 Trace。 Annotation：用于记录一个事件，一些核心注解用户定义一个请求的开始和结束： cs-Client Sent：客户端发送一个请求，描述 Span 的开始 sr-Server Received：服务端获得请求并准备开始处理它，用 sr 减去 cs 时间戳，就是网络传输的时间 ss-Server Sent：服务端发送响应，该注解表明请求处理的完成，用 ss 减去 sr 的时间戳就是服务端处理的时间长度 cr-Client Received：客户端接受响应，此时 Span 结束，用 cr 减去 cs 的时间戳，就得到整个请求的耗时。 Zipkin 使用 RabbitMQ 传输链路数据，默认使用 Http 上传数据到 zipkin-server 的。 可以使用 MySql、Elasticsearch 存储链路数据，如果在Elasticsearch中存储数据，可以利用 Kibana 展示数据。 微服务监控Spring Boot Security 安全 认证：认证主体，可以在应用程序中执行操作的用户、设备或其他系统 授权：拥有什么权限，允许已认证的主体执行某一项操作","tags":[{"name":"Spring","slug":"Spring","permalink":"https://zcy-fover.github.io/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zcy-fover.github.io/tags/SpringCloud/"}]},{"title":"middle-service/mycat/Mycat基础","date":"2020-02-22T07:58:24.550Z","path":"2020/02/22/middle-service/mycat/Mycat基础/","text":"Mycat分布式数据库 透明性：不用关心逻辑分区和物理位置分布细节； 数据冗余性：通过冗余实现系统的可靠性、可用性。多节点存储数据副本，在某一节点损坏时，通过心跳机制，节点自动切换，保证系统可用。热点数据就近分布，减少网络损耗加快访问速度、提升性能； 易于扩展性：分布式数据库可以进行水平或者垂直进行扩展提高性能； 自治性：本节点上的数据由本地的DBMS管理； 分布式数据库实现原理分布式数据库的目录管理存放系统元数据以数据库元数据的全部信息，保证数据被有效、正确地访问 全局目录 分布式目录 全局与本地混合目录 数据分片将一台数据库的压力分散到多台主机上，多台设备存取，提高性能、提高系统整体的可用性 水平切分：按照某个字段的某种规则将数据分散到多个节点库中 垂直切分：数据库由多表构成，每个表对应不同的业务，按照业务讲标分散不同的节点上。但是当表的数据量达到一定程度后，扩展较难 混合切分：将上述两者综合使用 分布式查询处理将查询解析到各个数据节点，然后将结果汇总 分布式并发控制并发控制保证分布式数据中的多个事务并发高效、正确的执行。并发控制保证事务的可串行性 加锁并发控制：容易死锁 时间戳控制：需要有全局的统一时钟，消除死锁，一旦发生冲突变回重启而不是等待 乐观并发控制：对于冲突较少的系统比较适合 Mycat架构、核心功能Mycat架构 mycat架构图 Mycat核心功能 mycat核心功能 Mycat核心概念逻辑库中间件被当做一个或多个数据库集群构成的逻辑库 逻辑表 分片表：将数据量很大的表切分到多个数据库实例中，例如将 mytable 配置到 dn1 和dn2 两个节点上1&lt;table name&#x3D;&quot;mytable&quot; primaryKey&#x3D;&quot;id&quot; autoIncrement&#x3D;&quot;true&quot; dataNode&#x3D;&quot;dn1,dn2&quot; rule&#x3D;&quot;myRule&quot; &#x2F;&gt; 非分片表：根据业务量，对于不需要分片的表可以只配置到一个节点上1&lt;table name&#x3D;&quot;mytable&quot; primaryKey&#x3D;&quot;id&quot; autoIncrement&#x3D;&quot;true&quot; dataNode&#x3D;&quot;dn1&quot; &#x2F;&gt; ER表：基于实体关系模型，子表的记录与其所关联的父表记录放在同一个数据分片上，保证关联查询不会跨分片 全局表：业务表规模较大分片后，业务表和附属字典表之间的关联查询比较麻烦，通过冗余数据解决这类关联查询，即所有分片都复制一份数据，这个冗余数据构成的表定义为全局表 分片节点分片表被分到不同的分片数据库上，每个表所在的分片数据库就是分片节点 节点主机将数据分片后，同一台机器上有可能有多个分片节点，所在的主机就是节点主机。为了规避单节点主机并发数量限制，尽量将读写压力高的节点合理分放，避免单节点压力过高 配置方式本地文件 schema.xml：mycat 的逻辑库、分片表、分片节点、分片节点主机信息配置 server.xml：系统参数配置文件，mycat 优化相关属性 rule.xml：分片规则配置文件 log4j2.xml：mycat 输出日志配置文件 sequence.properties：全局序列配置文件 Zookeeper 配置 zk-create.yaml：本地文件中的配置项都配置在此文件中","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"mycat","slug":"mycat","permalink":"https://zcy-fover.github.io/tags/mycat/"}]},{"title":"middle-service/mycat/Mycat 分片配置","date":"2020-02-22T07:58:23.325Z","path":"2020/02/22/middle-service/mycat/Mycat 分片配置/","text":"Mycat 分片配置mycat 将表分为两种概念：对于数据量小且不需要做数据切分的表成为非分片表；数据量大到单库性能、容量不足以支撑，数据需要通过水平切分均匀分布到不同的数据库表称之为分片表 rule.xmlrule.xml 为分片规则配置文件， schema.xml 中 table 标签中的 rule 属性的值需要在 rule.xml 中配置 function 标签123&lt;function name&#x3D;&quot;mod-long&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;property name&#x3D;&quot;count&quot;&gt;3&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; name 指定算法的名称，在该文件中唯一 class 属性对应具体的分片算法，指定具体的算法类 property 根据算法要求指定 tableRule 标签123456&lt;tableRule name&#x3D;&quot;my-mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;&#x2F;columns&gt; &lt;algorithm&gt;mod-long&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt; name 指定分片唯一算法名称 rule 分片算法具体内容 columns 对应表中用于分片的列名 algorithm function 中定义的算法名称 取模分片123456789&lt;tableRule name&#x3D;&quot;my-mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;&#x2F;columns&gt; &lt;algorithm&gt;mod-long&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;mod-long&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;property name&#x3D;&quot;count&quot;&gt;3&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; 概算法根据 ID 进行十进制求模计算，相比固定的分片 hash，这种分片算法在批量插入会增加事务一致性的难度 枚举分片通过在配置文件中配置可能的枚举ID，指定数据分布到不同的物理节点上，本规则适合按照省份或县区来拆分数据类业务 1234567891011&lt;tableRule name&#x3D;&quot;sharding-byintfile&quot;&gt; &lt;rule&gt; &lt;columns&gt;sharding_id&lt;&#x2F;columns&gt; &lt;algorithm&gt;hash-init&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;hash-init&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByFileMap&quot;&gt; &lt;property name&#x3D;&quot;mapFile&quot;&gt;partion-hash-init.txt&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;type&quot;&gt;0&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultNode&quot;&gt;0&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; 其中 partition-hash-init.txt 内容： 12310000&#x3D;010010&#x3D;1DEFAULT_NODE&#x3D;1 type 默认值为 0，0 表示 Integer，非 0 表示 String defaultNode 小于 0 表示不设置默认节点，大于等于 0 表示设置默认节点。默认节点的作用：枚举分片时，如果有不认识的枚举值就路由到默认节点。如果不配置默认节点，遇到无法识别的枚举值，就会报错。 范围分片12345678910&lt;tableRule name&#x3D;&quot;auto-sharding-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;&#x2F;columns&gt; &lt;algorithm&gt;range-long&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;range-long&quot; class&#x3D;&quot;io.mycat.route.function.AutoPartitionByLong&quot;&gt; &lt;property name&#x3D;&quot;mapFile&quot;&gt;auto-partition-long.txt&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultNode&quot;&gt;0&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; auto-partition-long.txt 配置如下： 1234# range start-end，data node index0-10000&#x3D;010001-20000&#x3D;120000-60000&#x3D;2 范围求模算法先范围分片，然后组内求模。范围求模可以保证组内数据分布比较均匀，避免热点数据问题；范围分片在水平扩展时，原有数据不需要迁移。 12345678910&lt;tableRule name&#x3D;&quot;auto-sharding-rang-mod&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;&#x2F;columns&gt; &lt;algorithm&gt;range-mod&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;range-mod&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByRangeMod&quot;&gt; &lt;property name&#x3D;&quot;mapFile&quot;&gt;partition-range-mod.txt&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultNode&quot;&gt;0&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; partiton-range-mod.txt 配置如下，等号前面的范围代表一个分片组，等号后面的数字代表该分片组所拥有的分片数量 1230-200M&#x3D;5 &#x2F;&#x2F;5个分片节点200M1-400M&#x3D;1400M1-600M&#x3D;3 固定分片 hash 算法12345678910&lt;tableRule name&#x3D;&quot;sharding-hash&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-hash&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-hash&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByLong&quot;&gt; &lt;property name&#x3D;&quot;partitionCount&quot;&gt;2,1&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;partitionLength&quot;&gt;256,512&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; partitionCount 分片个数列表 partitionLength 分片范围列表，分区长度默认最大为 2^n = 1024，最大支持 1024 个分区 count 和 length 两个数组的长度必须一致。1024 = SUM((count[i]*length[i]))，count 和 length两个向量的点击恒等于 1024。 取模范围算法先取模，然后范围分片 1234567891011&lt;tableRule name&#x3D;&quot;sharding-by-pattern&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-pattern&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-pattern&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByPattern&quot;&gt; &lt;property name&#x3D;&quot;patternValue&quot;&gt;256&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultNode&quot;&gt;2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;mapFile&quot;&gt;partition-pattern.txt&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; partition-pattern.txt 配置，dataNode 是默认节点，如果采用默认配置则不进行求模运算，如果 id 不是数据则会分配在默认节点上 12341-32&#x3D;033-64&#x3D;165-96&#x3D;297-128&#x3D;3 patternValue 求模基数 字符串 hash 求模范围算法与上相同，该算法支持述职、符号、字母取模 123456789101112&lt;tableRule name&#x3D;&quot;sharding-by-prefixpattern&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-prefixpattern&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-prefixpattern&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByPrefixPattern&quot;&gt; &lt;property name&#x3D;&quot;patternValue&quot;&gt;256&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;prefixLength&quot;&gt;5&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultNode&quot;&gt;2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;mapFile&quot;&gt;partition-prefixpattern.txt&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; partition-prefixpattern.txt，截取长度为 prefixLength 的子串，再对字符串中每个字符的 ASCII 码进行求和得出 sum 值，最后对 sum 进行求模运算 (sum % patternValue)，可以算出分片数 12341-4&#x3D;05-8&#x3D;19-12&#x3D;213-16&#x3D;3 应用指定的算法1234567891011&lt;tableRule name&#x3D;&quot;sharding-by-substring&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-substring&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-substring&quot; class&#x3D;&quot;io.mycat.route.function.PartitionDirectBySubString&quot;&gt; &lt;property name&#x3D;&quot;patternCount&quot;&gt;8&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;size&quot;&gt;2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;defaultPattern&quot;&gt;0&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; 根据字符串子串(必须是数字)计算分区号，例如 id = 05-0001，其中 id 是从 startIndex = 0 开始，截取长度为 2 位，即分区号为 05，分配到默认分区。 字符串 hash 解析算法1234567891011&lt;tableRule name&#x3D;&quot;sharding-by-stringhash&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-stringhash&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-stringhash&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByString&quot;&gt; &lt;property name&#x3D;&quot;length&quot;&gt;512&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;count&quot;&gt;2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;hashSlice&quot;&gt;0:2&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; length 字符串 hash 的求模基数 count 分区数 hashSlice 预算位，根据子字符串中的 int 值进行 hash 运算 一致性 hash 算法12345678910111213&lt;tableRule name&#x3D;&quot;sharding-by-murmur&quot;&gt; &lt;rule&gt; &lt;columns&gt;userId&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-murmur&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-murmur&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByMurMueHash&quot;&gt; &lt;property name&#x3D;&quot;seed&quot;&gt;0&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;count&quot;&gt;2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;virtualBucketTimes&quot;&gt;160&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;weightMapFile&quot;&gt;weightMapFile&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;bucketMapPath&quot;&gt;&#x2F;etc&#x2F;mycat&#x2F;bucketMapPath&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; count 要分片的数据库节点数量 virtualBucketTimes 一个实际的数据库节点被映射后的虚拟节点，默认是 160 倍，即虚拟节点是物理节点的 160 倍 weightMapFile 节点的权重，没有指定权重的节点默认是 1，以 properties 文件的格式编辑，以从 0 开始到 count - 1 的整数值也就是节点索引 key，以节点权重值为值。所有权重必须是正整数，否则以 1 代替 bucketMapPath 测试时观察各物理节点与虚拟节点的分布情况。如果指定该属性，则会把虚拟节点的 murmur hash 值与物理节点的映射输出到这个文件，没有默认值，不配置则不输出。 按日期(天)分片算法123456789101112&lt;tableRule name&#x3D;&quot;sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-date&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-date&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByDate&quot;&gt; &lt;property name&#x3D;&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sBeginDate&quot;&gt;2019-08-08&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sEndDate&quot;&gt;2019-08-09&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sPartionDay&quot;&gt;10&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; sPartitionDay 分区天数，默认从开始日期算起，每隔 10 天一个分区 sEndDate 如果配置该属性，则数据达到这个日期的分片后会重复从开始分片插入 单月小时算法123456789&lt;tableRule name&#x3D;&quot;sharding-by-hour&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-hour&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-hour&quot; class&#x3D;&quot;io.mycat.route.function.LatestMonthPartition&quot;&gt; &lt;property name&#x3D;&quot;sliptOneDay&quot;&gt;24&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; columns 为拆分字段，字符串类型(yyyyMMddHH) sliptOneDay 为一天切分的分片数 自然月分片算法12345678910&lt;tableRule name&#x3D;&quot;sharding-by-month&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;&#x2F;columns&gt; &lt;algorithm&gt;sharding-by-month&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;sharding-by-month&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name&#x3D;&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sBeginDate&quot;&gt;2019-08-08&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; 日期范围 hash 算法现根据日期分组，再根据时间 hash 使得短期内数据分布更加均匀，可在一定程度上避免范围分片的数据热点问题 123456789101112&lt;tableRule name&#x3D;&quot;range-date-hash&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;&#x2F;columns&gt; &lt;algorithm&gt;range-date-hash&lt;&#x2F;algorithm&gt; &lt;&#x2F;rule&gt;&lt;&#x2F;tableRule&gt;&lt;function name&#x3D;&quot;range-date-hash&quot; class&#x3D;&quot;io.mycat.route.function.PartitionByRangeDateHash&quot;&gt; &lt;property name&#x3D;&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sBeginDate&quot;&gt;2019-08-08&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sPartionDay&quot;&gt;12&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;groupPartionSize&quot;&gt;6&lt;&#x2F;property&gt;&lt;&#x2F;function&gt; sPartionDay 代表多少天一组 groupPartionSize 每组的分片数量","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"mycat","slug":"mycat","permalink":"https://zcy-fover.github.io/tags/mycat/"}]},{"title":"middle-service/mycat/Tips","date":"2020-02-22T07:58:21.802Z","path":"2020/02/22/middle-service/mycat/Tips/","text":"高可用 VIP高可用性HA (High Availability) 尽量缩短系统日常的维护操作和突发的系统奔溃导致的停机时间，提高系统和应用的可用性。数据库通常通过主从关系来实现。 数据库实现高可用，数据库服务搭建主从关系，主库 IP、从库 IP、读写 VIP、只读 VIP，使用这几个 IP 地址都可以连接对应的数据库服务。VIP 如何寻址到对应的服务器，使用的是 TCP/IP 协议的 ARP 协议。当 物理数据库无法使用时，动态将 VIP 对应的 MAC 地址替换成从库","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"mycat","slug":"mycat","permalink":"https://zcy-fover.github.io/tags/mycat/"}]},{"title":"middle-service/mycat/配置文件","date":"2020-02-22T07:58:20.328Z","path":"2020/02/22/middle-service/mycat/配置文件/","text":"配置文件server.xmluser 标签1234567&lt;user name&#x3D;&quot;zcy-fover&quot;&gt; &lt;property name&#x3D;&quot;schemas&quot;&gt;mycattest1,mycatttest2&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;password&quot;&gt;123456&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;readOnly&quot;&gt;true&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;benchmark&quot;&gt;100&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;usingDecrypt&quot;&gt;1&lt;&#x2F;property&gt;&lt;&#x2F;user&gt; user 标签用于定义登录 mycat 的用户和权限，配置的用户只可以访问对应的 schema schemas 可以配置多个 schema 用英文逗号分隔 readOnly 属性用来限制用户的读写权限 benchmark 属性限制前端的整体链接数量，置为 0 或者不设值则表示不限 usingDecrypt 属性表示开启密码加密功能，0：不开启，1：开启 system 标签 charset 字符集属性，配置时保证与 mysql 的一致 defaultSqlParser 指定默认的 sql 解析器 processors 指定系统可用的线程数量，默认值为机器 CPU 核心 x 每个核心运行线程的数量，processors 的值会影响 processorsBufferPool、processorsBufferLocalPersent、ProcessorsExecutor 和 NIOProcessor 属性 processorsBufferChunk 指定每次分配 Socket Direct Buffer 的默认字节是 4096，也会影响 bufferPool 的长度，如果一次性获取的字节过多导致 buffer 不够用，会出现告警，可以适当提高 processorsBufferChunk 的值 processorsBufferPool 指定 bufferPool 的计算比例，由于每次执行 NIO 读写都要使用到 buffer，所以 mycat 在初始化是会创建一定长度的 buffer 池来加快 NIO 读写效率，减少 buffer 的时间。 processorsBufferPool 的默认值：bufferChunkSize(4096) * processers * 1000 BufferPool 和 ThreadLocalPool 池，BufferPool 使用 ThreadLocalPool 作为二级缓存，每次从 BufferPool 获取时都会优先从 ThreadLocalPool 中获取 Buffer 的值，如果未命中，则会从 BufferPool 中获取，ThreadLocalPool 在每个线程内部使用，而 BufferPool 是每个 NIO 共享的。 BufferPool 的总长度为 BufferPool / BufferChunk，如果比值不是整数倍，则取整加一 processorBufferLocalPercent 控制 ThreadLocalPool 分配 Pool 的比例大小，该属性的默认值为 100 线程缓存百分比 = BufferLocalPercent / processors ThreadLocalPool 长度 = 线程缓存百分比 * BufferPool 长度 / 100 processorExecutor 指定 NIOProcessor 上共享 businessExecutor 固定线程池的大小，Mycat 把异步处理任务提交到这个 businessExecutor 线程池中 sequenceHandlerType 指定 Mycat 全局序列的类型，0：本地文件方式，1：数据库方式，2：时间戳序列方式。默认使用本地文件方式 TCP连接的相关属性 StandardSocketOptions.SO_RCVBUF、StandardSocketOptions.SO_SNDBUF、StandardSocketOptions.TCP_NODELAY对应到 mycat 的 TCP 连接配置如下： frontSocketSoRcvbuf：默认值为 1024 * 1024 frontSocketSoSndbuf：默认值为 4 * 1024 *1024 frontSocketSoNoDelay：默认值为 1 backSocketSoRcvbuf：默认值为 4 * 1024 * 1024 backSocketSoSndbuf：默认值为 1024 *1024 backSocketSoNoDelay：默认值为 1 MySQL连接的相关属性 packetHeaderSize：指定 MySQL 协议中的报文长度，默认值为 4 个字节 maxPacketSize：指定 MySQL 协议可以携带的数据的最大值，默认值为 16MB idleTimeout：指定连接的空闲时间的超时长度。如果某个连接的空闲时间超过 idleTimeout 的值，则该连接资源将被关闭并回收，单位毫秒，默认 30 分钟 charset：初始化连接字符集，默认 utf8 txIsolation：初始化前端连接事务的隔离级别，后续的 txIsolation 值为客户端的配置值。默认为 REPEATED_READ；READ_UNCOMMITTED: 1、READ_COMMITTED: 2、REPEATED_READ: 3、SERIALIZABLE: 4 sqlExecuteTimeout：执行 SQL 语句的超时时间，若 SQL 执行超过这个时间，则会关闭连接，单位为秒，默认 300 秒 心跳属性 processorCheckPeriod：清理 NIOProcessor 前后端连接空闲、超时、关闭连接的时间间隔，单位为毫秒，默认为 1 秒 dataNodeIdleCheckPeriod：对后端连接进行空闲、超时检查的时间间隔，单位为毫秒默认为 300 秒 dataNodeHeartbeatPeriod：对后端的所有读、写库发起心跳的时间间隔，单位为毫秒，默认为 10 秒 服务相关属性 bindIp：服务监听的 IP 地址，默认值为 0.0.0.0 serverPort：定义 mycat 的使用端口，默认值为 8066 managerPort：定义 mycat 的管理端口，默认值为 9066 fakeMySQLVersion属性 mycat 使用 MySQL 的通信协议模拟了一个 MySQL 服务器，默认版本是 5.6 handleDistributedTransactions 分布式事务开关属性, 值为0：不过滤分布式事务 值为1：过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤） 值为2：不过滤分布式无，但是记录分布式事务日志 useOffHeapForMerge 该属性指定是否启用非堆内存处理跨分片结果集，1：开启，0：关闭 useGlobleTableCheck 全局表一致性检查，1：开启，0：关闭 useSQLStat 开启实时统计，1：开启，0：关闭 useCompression 是否开启 MySQL 压缩协议，1：开启，0：关闭 usingAIO 0：NIO，1：AIO firewall标签全局防火墙的设置，针对IP地址进行限制 12345678&lt;firewall&gt; &lt;whitehost&gt; &lt;host host=\"127.0.0.1\" user=\"mycat\"/&gt; &lt;host host=\"127.0.0.2\" user=\"mycat\"/&gt; &lt;/whitehost&gt; &lt;blacklist check=\"false\"&gt; &lt;/blacklist&gt;&lt;/firewall&gt; schema.xmlmycat 的逻辑库、表、分片规则、分片节点及数据源相关配置项 schema 标签定义逻辑库 123456&lt;schema name&#x3D;&quot;test1&quot; checkSQLschema&#x3D;&quot;false&quot; sqlMaxLimit&#x3D;&quot;100&quot;&gt; &lt;table name&#x3D;&quot;goods_order&quot; subTables&#x3D;&quot;goods_order$0-2&quot; primaryKey&#x3D;&quot;ID&quot; autoIncrement&#x3D;&quot;true&quot; dataNode&#x3D;&quot;dn1&quot; rule&#x3D;&quot;my-mod-long&quot;&#x2F;&gt;&lt;&#x2F;schema&gt;&lt;schema name&#x3D;&quot;test2&quot; checkSQLschema&#x3D;&quot;false&quot; sqlMaxLimit&#x3D;&quot;100&quot;&gt; &lt;table name&#x3D;&quot;goods_order&quot; subTables&#x3D;&quot;goods_order$0-2&quot; primaryKey&#x3D;&quot;ID&quot; autoIncrement&#x3D;&quot;true&quot; dataNode&#x3D;&quot;dn1&quot; rule&#x3D;&quot;my-mod-long&quot;&#x2F;&gt;&lt;&#x2F;schema&gt; name schema名称，需要在 server.xml 中定义后才可以 dataNode 配置逻辑库的默认分片，没有配置 table 标签则会分到默认的 dataNode；通过 mycat 建表，没有提前配置 table 标签，也没有配置默认 dataNode，则会报错 checkSQLSchema 当值为 true 时，sql 语句发送到数据库执行时，会去掉 schema，例如SELECT * FROM test1.user会变成SELECT * FROM user，如果语句所带的 schema 没有在schema标签中指定，则 mycat 不会去掉，在执行时如果没有定义该库则执行会出错。 sqlMaxLimit 拆分库情况下，限制返回数据的大小。例如设置为 100，当实际 sql 中没有使用 limit，在执行时，mycat 会自动加上 limit 100。如果在实际 sql 中写了 limit 语句，则该属性即时设置也无效。 table 标签定义逻辑表 1&lt;table name=\"goods_order\" subTables=\"goods_order$0-2\" primaryKey=\"ID\" autoIncrement=\"true\" dataNode=\"dn1\" rule=\"my-mod-long\"/&gt; name 定义逻辑表的名称，和数据库中执行 create table 语句一样，同一个 schema 标签中，定义的表名必须唯一 dataNode 定义逻辑表所属的 dataNode，该值需要和 dataNode 标签中定义的一样，如果该表分布在多个 dataNode 上，可以如上类似使用 $ 符减少配置 rule 定义逻辑表使用的分表规则，该值需要在 rule.xml 文件中定义且需对应 ruleRequired 指定表是否绑定分片规则，如果设为true，但是没有指定 rule，则会报错 primaryKey 逻辑表对应真实表的主键。如果该属性配置的是真实表的主键，mycat 会缓存主键与 dataNode 的信息，再次使用主键查询时就不会广播式查询，直接路由到对应的 dataNode。但是如果缓存没有命中，还是会进行广播式查询。 type 定义逻辑表的类型，全局表：type 值是global；普通表：不指定该值为 global 的表 autoIncrement MySQL 对于非自增主键使用 last_insert_id() 不会返回结果，只会返回0，所以在 mycat 中使用该属性需要 MySQL 的表主键定义 auto_increment。使用该属性时配合数据库模式的全局序列使用 subTables 定义子表名称，目前在 mycat 1.6 版本后才支持分表，并且 dataNode 在分表条件下只能配置一个 needAddLimit 指定表是否需要在每个语句的后面加上 limit 限制，添加该属性后 mycat 会默认为查询语句后面添加 limit 100，如果 sql 语句中添加了 limit 限制，则该属性失效。该属性默认值为 true。 childTable 标签定义 E-R 分片的子表，通过标签上的属性与父表关联，将有关联关系的父、子表放在同一个节点上，方便查询提高效率 name 子表名称 joinKey 插入子表时使用该属性查找父表存储的数据节点；该属性为子表的属性 parentKey 与父表建立关联关系的列名。首先获取 joinKey 再通过 parentKey 指定的列名产生查询语句，通过执行该查询语句知道父表在哪个分片上，从而确定子表的的存储位置；该属性是父表的属性 primaryKey 同 table 标签 needAddLimit 同 table 标签 dataNode 标签定义 mycat 中的数据节点，一个 dataNode 标签就是一个独立的数据分片节点 1&lt;dataNode name=\"dn1\" dataHost=\"mysql1\" database=\"mycattest1\"/&gt; name 定义 dataNode 的唯一名字，应用在 table 标签上的 dataNode 属性，建立表和数据节点的对应关系 dataHost 定义该数据分片所属的数据库实例，需要在 dataHost 标签中定义 dataBase 定义该分片所属数据库实例上的具体库，利用 实例+具体的库 两个维度定义分片，每个库上的表结构是一样的，这样可以方便对表进行水平拆分 dataHost 标签定义数据库实例、读写分离和心跳 123456&lt;dataHost name=\"mysql1\" maxCon=\"1000\" minCon=\"20\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM0\" url=\"127.0.0.1:3306\" user=\"test\" password=\"123456\"&gt; &lt;readHost host=\"hostS0\" url=\"127.0.0.1:3306\" user=\"test\" password=\"123456\"/&gt; &lt;/writeHost&gt;&lt;/dataHost&gt; name 定义 dataHost 标签的名称，在 dataNode 中使用 maxCon 每个读写实例连接池的最大连接数，内嵌标签 writeHost 和 readHost 都会使用这个值来初始化连接池的最大长度 minCon 每个读写实例连接池的最小连接数，初始化连接池大小 balance 负载均衡类型 balance=”0”：不开启读写分离机制，所有读操作发送到当前可用的 writeHost 上 balance=”1”：全部的 readHost 与 stand by writeHost 都参与当前 select 语句的负载均衡。即当为双主双从模式(M1-&gt;S1，M2-&gt;S2，并且M1，M2互为主备)，正常情况下 M2、S1、S2都参与 select 语句的负载均衡 balance=”2”：所有的读操作都随机地分在 writeHost 和 readHost 上 balance=”3”：所有的读请求都随机分发到 writeHost 对应的 readHost 上，writeHost 不负载读压力。该配置在 mycat 1.3 后才有 dbType 指定后端连接的数据库类型，支持二进制的 MySQL 协议，还可以用 JDBC 连接 MongoDB、Oracle 等 dbDriver 指定连接后端使用的 Driver，可选 native 和 jdbc，因为 native 执行的是二进制的 MySQL 协议，所以可以使用 MySQL 和 MariaDB。其他类型的数据库需要使用 jdbc 驱动来支持，如果使用 jdbc，需要把支持 jdbc4 标准的驱动 jar 包放到 mycat 的 lib 文件夹下 switchType -1：不自动切换 1：默认值，表示自动切换 2：基于 MySQL 主从同步的状态决定是否切换，心跳语句 show slave status 3：基于 MySQL Galary Cluster 的切换机制(适合集群，用于 mycat 1.4.1及上)，心跳语句show status like &#39;wsrep%&#39; tempReadHostAvailable 如果配置了 writeHost，下面的 readHost 依旧可用，默认值为 0 heartBeat 标签指明用于后端数据库心跳检查的语句，例如 MySQL 可以使用select user()，Oracle 可以使用select 1 from dual，这个标签还有 connectionInitSql 属性，当使用 Oracle 需要执行初始化 SQL 的语句放到这里。 writeHost、readHost 标签实例化后端连接池 host 标识不同的实例，writeHost 通常用 *M1；readHost 通常用 *S1 url 实例数据库连接地址，如果使用的是 native，一般为 address:port；使用 JDBC 或其他 dbDriver，需要自己指定；例如 JDBC示例：jdbc:MySQL://localhost:3306 user 后端存储实例的用户名 password 后端存储实例的密码 weight 在 readHost 中作为读节点的权重 usingDecrypt 开启密码加密功能，0：不开启，1：开启 rule.xml分片规则配置文件， schema.xml 中 table 标签中的 rule 属性的值需要在 rule.xml 中配置 function 标签123&lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;/function&gt; name 指定算法的名称，在该文件中唯一 class 属性对应具体的分片算法，指定具体的算法类 property 根据算法要求指定 tableRule 标签123456&lt;tableRule name=\"my-mod-long\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; name 指定分片唯一算法名称 rule 分片算法具体内容 columns 对应表中用于分片的列名 algorithm function 中定义的算法名称 sequence 配置文件分库分表情况下，数据库自增主键无法保证主键在集群中全局唯一，mycat 提供本地配置和数据库配置 本地文件方式要启用这种方式，需要在 server.xml 配置文件中配置如下参数： name1234567891011121314151617181920212223配置后，在 mycat 的conf目录下，在 sequence_conf.properties 配置如下参数：&#96;&#96;&#96;propertiesCOMPANY.MAXID&#x3D;2000GLOBAL.MAXID&#x3D;20000COMPANY.HISIDS&#x3D;CUSTOMER.MAXID&#x3D;2000HOTNEWS.CURID&#x3D;1000ORDER.MINID&#x3D;1001CUSTOMER.HISIDS&#x3D;HOTNEWS.MINID&#x3D;1001GLOBAL.CURID&#x3D;10054ORDER.MAXID&#x3D;2000COMPANY.CURID&#x3D;1000CUSTOMER.CURID&#x3D;1000COMPANY.MINID&#x3D;1001GLOBAL.MINID&#x3D;10001HOTNEWS.MAXID&#x3D;2000CUSTOMER.MINID&#x3D;1001GLOBAL.HISIDS&#x3D;HOTNEWS.HISIDS&#x3D;ORDER.HISIDS&#x3D;ORDER.CURID&#x3D;1000 mycat 重新发布后配置文件中的 sequence 会恢复到初始值；优点是本地文件加载且读取速度快 数据库方式在数据库中创建一张名为 sequence 的表，在 sequence_db_conf.properties 进行相关配置 sequence 获取步骤 初次使用 sequence，根据传入的 sequence 民称从数据表中读取 current_value、increment 到 mycat 中，并做 current_value = current_value + increment mycat 将读取到的 current_value + increment 作为本次使用的 sequence 值，下次使用时 sequence 自动加一，当使用 increment 次后，执行与步骤一相同的操作 mycat 负责维护这张表，用到那些 sequence 时，只需要在这张表中插入一条记录即可。若某次读取的 sequence 没有用完，系统宕机了，则本次已经读取未使用的 sequence 值会被丢弃 数据库配置 创建表 123456789#创建 sequence 表CREATE TABLE IF NOT EXISTS sequence ( name VARCHAR(50) NOT NULL, current_value INT NOT NULL, increment INT NOT NULL DEFAULT 100, PRIMARY KEY (name)) ENGINE = InnoDB;#初始化记录INSERT INTO sequence (name, current_value, increment) VALUES ('GLOBAL', 10000, 100); 创建存储过程 12345678910111213141516171819202122232425262728293031323334# 获取当前sequence值DROP FUNCTION IF EXISTS mycat_seq_currval;DELIMITER $CREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8DETERMINISTICBEGINDECLARE retval VARCHAR(64);SET retval = \"-999999999,NULL\";SELECT concat(CAST(current_value AS CHAR), \",\", CAST(increment AS CHAR)) INTO retval FROM sequence WHERE name = seq_name;RETURN retval;END $DELIMITER ;# 设置sequence值DROP FUNCTION IF EXISTS mycat_seq_setval;DELIMITER $CREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),value INTEGER) RETURNS VARCHAR(64) CHARSET utf8DETERMINISTICBEGINUPDATE sequence SET current_value = value WHERE name = seq_name;RETURN mycat_seq_currval(seq_name);END $DELIMITER ;# 获取下一个sequence值DROP FUNCTION IF EXISTS mycat_seq_nextval;DELIMITER $CREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8DETERMINISTICBEGINUPDATE sequence SET current_value = current_value + increment WHERE name = seq_name;RETURN mycat_seq_currval(seq_name);END $DELIMITER ; sequence_db_conf.properties 配置 指定 sequence 表所在的节点信息 12345#sequence stored in datanodeGLOBAL=dn1COMPANY=dn1CUSTOMER=dn1ORDERS=dn1 本地时间戳方式ID = 64 位二进制[42位(毫秒)+5位(机器ID)+5位(业务编码)+12位(重复累加)]，换算成十进制 18 位数的 long 类型，每毫秒可以并发 12 位二进制的累加 配置 server.xml1&lt;property name=\"sequenceHandlerType\"&gt;2&lt;/&gt; 配置 sequence_time_conf.properties WORKID=0~31：可取 0 ~ 31 的任意整数 DATAACENTERID=0~31：可取 0 ~ 31 的任意整数 其他方式 使用 catlet 注解 使用 zookeeper 实现 自增长主键利用 MySQL 数据库的自增主键功能，创建一个只有自增 ID 的表，在 table 标签中将 autoIncrement 置为 true，在 sequence_db_conf.properties 配置改数据表所在节点，在数据库的 sequence 表中增加该表的 sequence 记录 其他配置缓存配置文件1234567#used for mycat cache service conffactory.encache=io.mycat.cache.impl.EnchachePooFactory#key is pool name ,value is type,max size, expire secondspool.SQLRouteCache=encache,10000,1800pool.ER_SQL2PARENTID=encache,1000,1800layedpool.TableID2DataNodeCache=encache,10000,18000layedpool.TableID2DataNodeCache.TESTDB_ORDERS=50000,18000 factory.encache 指定缓存的实现类，不同的缓存实现类对应不同的缓存框架，后面的指定缓存的框架、缓存大小、过期时间 日志文件配置日志的输出路径以及日志级别","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"mycat","slug":"mycat","permalink":"https://zcy-fover.github.io/tags/mycat/"}]},{"title":"设计/架构/亿级流量高可用高并发/负载均衡与反向代理","date":"2020-02-22T07:55:38.734Z","path":"2020/02/22/设计/架构/亿级流量高可用高并发/负载均衡与反向代理/","text":"负载均衡与反向代理 上游服务器配置：使用 upstream server 配置上游服务器配置 负载均衡算法：配置多个上游服务器时的负载均衡机制 失败重试机制：配置当超时或者上游服务器不存活时，是否需要重试其他上游服务器 服务器心跳检查：上游服务器的健康检查 / 心跳检查 upstream配置1234upstream backend &#123; server 192.168.61.1:9080 weight&#x3D;1; server 192.168.61.2:8080 weight&#x3D;1;&#125; IP 地址和端口：配置上游服务器的 IP 地址和端口 权重：weight配置权重，默认是1，权重越高分配到的请求量就越多，按照权重比例分配","tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://zcy-fover.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"}]},{"title":"设计/架构/亿级流量高可用高并发/交易系统设计原则","date":"2020-02-22T07:55:35.873Z","path":"2020/02/22/设计/架构/亿级流量高可用高并发/交易系统设计原则/","text":"交易系统设计原则高并发原则 无状态：应用无状态，配置文件有状态。应用要支持水平扩展 拆分：大型系统设计时，要按照功能模块进行拆分，有以下几个维度 系统维度：按照系统功能/业务拆分 功能维度：对一个系统进行功能再拆分 读写维度：根据读写比例特征进行拆分（读服务考虑使用缓存，写入量大考虑使用分库分表） AOP维度：根据访问特征，进行AOP拆分 模块维度：按照基础或者代码模块拆分，基础模块分库分表、数据库连接池；代码结构按照三层（Web、Service、DAO） 服务化：服务独立部署，避免相互影响；进程内服务 -&gt; 单机远程服务 -&gt; 集群手动注册服务 -&gt; 自动注册和发现服务 -&gt; 服务的分组/隔离/路由 -&gt; 服务治理 消息队列：使用消息队列进行服务解耦，可做大流量缓冲，但是要考虑数据校对问题 数据异构： 数据聚合：数据异构把数据从多个数据源拿过来，在做聚合给前端 前段展示：可通过一个或少量几个请求获取数据 缓存： 浏览器缓存：可用于对实时性要求较低的数据，例如静态文件、广告等等 APP客户端缓存：防止大促瞬间流量冲刷，可以提前把一些静态文件下发缓存 CDN缓存：利用CDN节点为用户推送数据； 推送机制：内容节点变更后，推送到CDN边缘节点； 拉取机制：先访问边缘节点，当没有内容时，回源到源服务节点拿取内容并缓存到CDN边缘节点。在设计URL时要注意不要有随机数，这样每次都会穿透CDN回源到源服务器，相当于CDN没有作用。 接入层缓存： URL重写：按照规定的设计格式、顺序重写，避免随机数 一致性哈希：按照指定的参数做一致性哈希，保证相同的数据落到同一台服务器上 proxy_cache：使用内存 / SSD 级代理缓存来缓存内容 proxy_cache_lock：使用 lock 机制，将多个回源合并为一个，减少回源量 shared_dict：如果架构使用 Nginx+Lua 实现，可以考虑使用 Lua shard_dict 进行缓存，最大的好处就是reload缓存不会丢失。Nginx + Lua参考 应用层缓存：堆内缓存、堆外缓存 分布式缓存：部署分布式缓存集群 并发化：非依赖服务并发请求 高可用原则 降级 开关集中化管理：通过推送机制把开关推送到各个应用 可降级的多级读服务：服务降级为只读本地缓存、只读分布式缓存、只读默认降级数据 开关前置化：在 Nginx 层做开关，请求流量不回源到后端服务器 业务降级：当高并发流量来袭，为保证主服务，将部分同步服务改为异步，优先处理高优先级数据或特殊特征数据，合理分配进入系统的流量，最终要保持数据一致性。 限流：做好防火墙 恶意请求只访问到 cache 恶意 IP 拦截 使用 Nginx 的 limit 模块处理，避免流量超出系统峰值 切流量：某机房瘫痪切换流量到其他机房 DNS：切换机房入口 HttpDNS：客户端分配好流量入口，绕过运营商LocalDNS并实现高精准的流量调度 LVS / HsProxy：切换故障的Nginx接入层 Nginx：切换故障的应用接入层 可回滚 业务设计原则 防重设计 幂等设计 流程可定义 状态与状态机 后台系统操作可反馈 后台系统审批化 文档和注释 备份","tags":[{"name":"高可用","slug":"高可用","permalink":"https://zcy-fover.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"高并发","slug":"高并发","permalink":"https://zcy-fover.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"}]},{"title":"数据结构和算法/数据结构与算法之美/数据结构与算法","date":"2020-02-22T07:46:54.571Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/数据结构与算法/","text":"数据结构是为算法服务的，算法要作用在特定的数据结构上 数据结构和算法图谱","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/1.复杂度分析","date":"2020-02-22T07:46:51.484Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/1.复杂度分析/","text":"复杂度分析对于算法执行的时间和空间的分析，通过分析可以衡量算法的执行效率。 事后统计法通过统计、监控得到算法执行的时间和占用的内存大小 局限性 测试结果依赖于测试环境 测试结果受数据规模的影响比较大 大 O 复杂度表示法代码的执行时间 T(n) 与每行代码的执行次数 n 成正比 1T(n) &#x3D; O(f(n)) 大 O 时间复杂度表示法 表示代码执行时间随数据规模增长的变化趋势，也叫渐进时间复杂度，简称时间复杂度。 例如：假设每行代码的执行时间是 unitTime 且每行代码的执行时间相同，则下面代码的执行总时间是 $(2n + 2) * unitTime$ 即 $T(n) = O(2n + 2)$，当 n 趋近于无穷大时，则用量级表示即可：$T(n) = O(n)$，如果是双层循环则是：$T(n) = O(n^2)$ 12345678int cal(int n) &#123; int sum = 0; int i = 1; for (; i &lt;= n; ++i) &#123; sum = sum + i; &#125; return sum;&#125; 时间复杂度分析分析方法 关注循环执行次数最多的一段代码 加法法则：总复杂的等于量级最大的那段代码的复杂度 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘机 常见复杂度量级 常量阶 $O(1)$ 对数阶 $O(logn)$ 线性阶 $O(n)$ 线性对数阶 $O(nlogn)$ k 次方阶 $O(n^2)$ $O(n^3)$…$O(n^k)$ 指数阶 $O(2^n)$ 阶乘阶 $O(n!)$ 非多项式量级：$O(2^n)$ 和 $O(n!)$，其他的是多项式量级，非多项式量级的算法问题叫做 NP (Non-Deterministic Polynomial)非确定多项式问题 空间复杂度分析空间复杂度是算法的存储空间与数据规模之间的增长关系，也叫做渐进空间复杂度 复杂度分析补充最好情况时间复杂度在理想的情况下执行代码的时间复杂度；例如下面代码的最好情况时间复杂度是：$O(1)$ 123456789101112// n 表示数组 array 的长度int find(int[] array, int n, int x) &#123; int i = 0; int pos = -1; for (; i &lt; n; ++i) &#123; if (array[i] == x) &#123; pos = i; break; &#125; &#125; return pos;&#125; 最坏情况时间复杂度在最糟糕的情况下执行代码的时间复杂度；例如上面代码的最坏情况时间复杂度是：$O(n)$ 平均情况时间复杂度将每种情况出现的概率考虑进去，例如上面的代码：要查找的数据出现在数组中和不出现在数组中的概率是$1/2$，出现在 0～n-1 这 n 个位置的概率是 $1/n$，则要查找的数据可能出现在数组中的概率是：$1/2n$，将每种情况发生的情况考虑进去就是，去掉系数常量就是 $O(n)$$$1\\frac{1}{2n} + 2\\frac{1}{2n}+…+n\\frac{1}{2n}+n\\frac{1}{2}=\\frac{n(n+1)}{4n}+\\frac{n}{2}=\\frac{3n+1}{4}$$ 均摊时间复杂度对一个数据结构的一组操作中，大部分情况下耗时都很低，个别情况比较高，并且这些操作存在前后连贯的时序关系，可以将这一组操作放在一块儿分析，将高耗时的分摊到其他情况中。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/2.数组","date":"2020-02-22T07:46:49.616Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/2.数组/","text":"数组数组：一种线性表数据结构，用一组连续的内存空间，来存储一组具有相同类型的数据 如何实现数组随机访问线性表特性数据像排成一条线，每个线性表上的数据最多只有两个方向；数组、链表、队列、栈都是线性表。相对立就是非线性表，比如二叉树、堆、图等 连续的存储空间和相同的数据类型数组的连续存储使得地址空间可以根据第几个元素和每个元素的空间大小算出地址，从而可以实现随机访问，但是随即访问也使得删除和插入变得低效，需要迁移很多数据。寻址公式： 1a[i] = base_address + i * data_type_size 对于一个 m*n 的二维数组，寻址公式： 1a[i][j] = base_address + (i * n + j) * data_type_size 数组的插入删除插入在一个长度为 n 的数组中在 k 位置插入一个元素，则需要把后面 n - k 个元素向后移一位，如果刚好是最后一个元素，则时间复杂度是 $O(1)$，如果是第一个元素则是 $O(n)$，平均时间复杂度是 $(1+2+3+…+n) / n = O(n)$。 当插入的数列本身是无序的时候，可以把插入的位置的元素直接放到数组的最后，避免大规模移动数据 删除删除的场景类似于出入，如果数组无序，可以把最后一个元素放到要删除的位置，也可以避免大规模移动数据。 也可以利用 JVM 标记清除的思想，将元素标记为删除，当空间不足或者达到一定量时，统一做删除操作 容器和数组数组需要提前划分好连续的地址空间大小，无法动态扩容；容器可以支持动态扩容 数组越界问题访问超过划分的地址空间就会出现异常。但对于一些语言和编译器有可能会出现无限循环的情况。例如这段 C 语言，在有的编译器下可能出现循环访问的情况。 123456789int main(int argc, char* argv[])&#123; int i = 0; int arr[3] = &#123;0&#125;; for(; i&lt;=3; i++)&#123; arr[i] = 0; printf(\"hello world\\n\"); &#125; return 0;&#125; C 语言中除受限内存空间所有内存可以自由访问。数组大小为 3，a[0]、a[1]、a[2]，当数组大于3时才结束循环，此时会造成访问越界，但这个地址刚好是变量 i 的地址，就会导致无限循环。这里的循环问题也是特例，这个还和编译器分配内存和字节对齐相关。 数组下标从 0 开始数组下标为 0 时寻址公式： 1a[i] = base_address + i * data_type_size 下标为 1 时寻址公式： 1a[i] = base_address + (i - 1) * data_type_size 对 CPU 来说需要多做一次减法操作，在以前机器性能不高时可能有一定作用。现在来看应该作用不大。保留下来应该也有历史原因，现在有些语言数组不一定从 0 开始，甚至可以有负数，例如 python。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/3.链表","date":"2020-02-22T07:46:46.498Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/3.链表/","text":"链表链表介绍 线性表数据结构 内存空间不连续，将分散的内存块串联起来，进行数据存储 链表的每个数据节点，不仅存储数据还要存储下一个节点的地址 链表特点 由于链表的数据结构，插入、删除效率高(改变指针指向即可)，时间复杂度 $O(1)$，但是随机访问的速度较慢，需要从头遍历链表。这个和数组相反 由于链表的节点不仅存储数据还要存储下一节点的指针，所以存储空间相较于数组消耗较大 单链表、循环链表、双向链表、双向循环链表单链表 每个节点存储数据和下一个节点的指针，即后继指针 第一个节点是头结点，记录链表的基地址；最后一个是尾节点，指向 NULL 单链表的的插入和删除的时间复杂度是 $O(1)$，查询的时间复杂度是 $O(n)$。 循环链表 尾节点的后继节点是头结点 比较适合于处理环形数据结构的问题，例如约瑟夫环问题 双向链表 每个节点有后继指针和前驱指针；头结点的前驱指针是 NULL，尾节点的后继指针是 NULL 插入、删除操作比单链表效率更高 $O(1)$ 级别。以删除操作为例，删除操作分为 2 种情况：给定数据值删除对应节点和给定节点地址删除节点。对于前一种情况，单链表和双向链表都需要从头到尾进行遍历从而找到对应节点进行删除，时间复杂度为 $O(n)$ 。对于第二种情况，要进行删除操作必须找到前驱节点，单链表需要从头到尾进行遍历直到 p-&gt;next = q，时间复杂度为 $O(n)$，而双向链表可以直接找到前驱节点，时间复杂度为 $O(1)$。 双向循环链表 首节点的前驱指针指向尾节点，尾节点的后继指针指向首节点 指针和引用 指针和引用是同一个概念，都是存储所指对象的内存地址 将某个变量赋值给指针就是将变量的内存地址赋值给指针；对应的就是指针存储的就是变量的内存地址，通过这个指针就可以找到这个变量 指针丢失、内存泄漏 链表操作时，要注意指针的交换顺序，避免出现指针丢失的情况。例如，要在当前节点 p 插入节点 x，示例1的操作会导致 x-&gt;next = x，造成整个链表断裂；只需将两个语句顺序交换即可。123456// 示例 1p-&gt;next = x;x-&gt;next = p-&gt;next;// 示例 2x-&gt;next = p-&gt;next;p-&gt;next = x; 在没有自动管理内存的编程语言，再删除节点后要手动释放内存空间，避免造成内存泄漏 利用哨兵实现插入、删除 针对链表的插入、删除，插入时需要对链表的第一个节点和最后一个节点进行特殊判断； 引入哨兵，“哨兵”节点不存储数据，无论链表是否为空，head指针都会指向它，作为链表的头结点始终存在。这样，插入第一个节点和插入其他节点，删除最后一个节点和删除其他节点都可以统一为相同的代码实现逻辑了。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/4.栈","date":"2020-02-22T07:46:45.089Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/4.栈/","text":"栈先进后出，后进先出。栈是一种操作受限的线性表，只允许在一端插入和删除。用数组实现的栈叫做顺序栈，用链表实现的栈叫做链式栈。 复杂度分析 空间复杂度：栈在操作过程中，存储空间是提前申请好的，空间复杂度是 $O(1)$ 时间复杂度：栈的操作只涉及个别元素的操作，所以时间复杂度是 $O(1)$ 顺序栈、链式栈扩容 顺序栈：顺序栈在栈满之后如果需要扩容需要重新申请一个更大的数组，将数据迁移过去 链式栈：栈支持动态扩容，但是需要存储后继节点的地址指针，内存消耗较多 栈的应用函数调用、表达式求值、括号匹配 利用栈实现浏览器的前进后退需要使用两个栈：前进栈 X，后退栈 Y，将一次浏览的页面（a、b、c）按顺序压入前进栈 X，在 c 页面点后退则将 c 从 X 出栈，然后放入后退栈 Y 中；再点后退的话同理，将 b 放入 Y 中，此时点前进 则把 b 从Y中出栈，放入 X 中，需要注意的是前进栈 X 入栈时将入栈的元素和 Y 栈的栈顶元素比较，如果相同则 Y 栈顶出栈，不相同则将 Y 栈清空。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/5.队列","date":"2020-02-22T07:46:43.368Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/5.队列/","text":"队列什么是队列 先进先出，也是一种操作受限的线性表数据结构。用数组实现的队列叫做顺序队列，用链表实现的队列叫做链式队列 队列支持队头入队，队尾出队 队列需要有两个指针 head 指向头指针，tail 指向队尾指针 队列实现顺序队列顺序队列当入队、出队时 head 指针和 tail都向后移。顺序队列当 tail 指针到达数组尾部，数组 索引 [0 - head] 之间的空间就会浪费掉，可以利用数据迁移的想法将在入队时将数据整体往前迁移。这样出队时间复杂度是 ${O(1)}$ ，入队时需要数据搬移，最好的情况就是 head 指针在数组索引 0 的位置，不需要迁移，否则假如队列有 n 个元素，则需要迁移 n 次。则平均时间复杂度$(1+2+3+…+n) / n = O(n)$。 链式队列链式队列也需要两个指针，head 指针和 tail 指针。链式队列的出队、入队时间复杂度都是${O(1)}$。 12345// 入队操作tail.next = newNode;tail = tail.next;// 出队操作head = head.next; 循环队列用数组实现的队列当出队时会造成空间浪费，所以需要数据搬移，利用循环队列来解决这个问题。 关键的地方是如何判断堆满和队空的条件： 12head = (head + 1) % n;tail = (tail + 1) % n; 阻塞队列队列为空时出队操作会被阻塞，此时还无数据可取；队列满时入队被阻塞直到队列中有空闲位置。类似于 生产者-消费者 模型。当多个线程同时操作队列时就会出现线程安全问题。 并发队列线程安全的队列叫做并发队列，需要在出队、入队操作上加锁。基于数组的循环队列利用 CAS 原子操作可以实现高效的并发队列。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/6.递归","date":"2020-02-22T07:46:41.146Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/6.递归/","text":"递归递归简介把规模大的问题转化为规模小的相似子问题来处理，子问题要有明显的结束条件。所有的所有的递归问题都可以用递归公示来表示。 递归需要满足的条件1、一个问题的解可以拆分为几个子问题的解2、这个问题与分解之后的子问题，除了数据规模不同，求解思路完全相同3、存在递归终止条件 递归优缺点优点：代码表达能力强，简介缺点：1、空间复杂度高2、堆栈溢出风险，可记录堆栈深度，达到一定时抛出异常3、存在重复计算，利用散列表揭露某个字问题的解4、过多的函数计算会耗时较多 如何写递归代码写出递推公式，找出终止条件。","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构和算法/数据结构与算法之美/7.排序","date":"2020-02-22T07:46:16.878Z","path":"2020/02/22/数据结构和算法/数据结构与算法之美/7.排序/","text":"排序算法排序算法分析 算法 时间复杂度 是否基于比较 冒泡、插入、选择 O(n^2) 是 快排、归并 O(nlogn) 是 桶、计数、基数 O(n) 否 算法的执行效率 最好、最坏、平均情况时间复杂度比较：根据数据的特点(无序、基本有序等)选择合适的算法。 时间复杂度的系数、常数、低阶：数据规模很大时一般忽略了这几个量，但是当同一阶的算法比较时也需要把这几个量考虑进来 比较次数和交换次数：基于比较的算法有两个操作：比较和移动，在分析效率时也需要考虑。 算法的内存消耗 数据量较大时，执行时也需要考虑内存的消耗，原地排序特指空间复杂度是 $O(1)$ 的排序算法。 排序算法的稳定性 稳定性：排序队列中存在值相同的元素，经过排序之后想等元素之间原有的先后顺序不变。（这个特点主要实际项目中一组对象的排序时比较重要） 冒泡排序比较相邻的两个元素，并且移动元素让其满足大小关系要求。经过一次冒泡至少有一个元素移动到他应该在的位置。 复杂度分析稳定性：冒泡排序中相等的两个元素不做交换时是稳定的排序算法空间复杂度：只需要常量级的临时空间，空间复杂度为 $O(1)$，是一个原地排序算法时间复杂度： 最好的情况下只需要一次冒泡：时间复杂度为：$O(1)$ 最坏的情况下是需要 n 次，时间复杂度为：$O(n^2)$ 平均时间复杂度：$O(n^2)$ 有序度数组中具有有序关系的元素对的个数，比如 [2,4,3,1,5,6] 这组数据的有序度就是 11，分别是 [2,4][2,3][2,5][2,6][4,5][4,6][3,5][3,6][1,5][1,6][5,6]。对于一个倒序数组，比如 [6,5,4,3,2,1]，有序度是 0；对于一个完全有序的数组，比如 [1,2,3,4,5,6]，有序度为 $n(n-1)/2$，完全有序的情况称为满有序度。即有 *逆序度=满有序度-有序度**。排序过程，就是有序度增加，逆序度减少的过程，最后达到满有序度。 插入排序通过比较将无序队列中的元素不断的插入到有序队列中。插入时要保证有序队列是一直有序的。 复杂度分析稳定性：出现相等的元素可以保持插入到前面元素的后面，即是稳定的。 空间复杂度：插入排序不需要额外的空间，复杂度为 $O(1)$，是原地排序。 时间复杂度： 最好的情况下只需要一次冒泡：时间复杂度为：$O(1)$ 最坏的情况下是需要 n 次，时间复杂度为 $O(n^2)$。 平均时间复杂度为 $O(n^2)$ 选择排序区分有序和无序队列，每次从无序队列中找出最小元素发到有序队列的末尾。 复杂度分析稳定性：不能保证稳定性。例如：5，8，5，2，9第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了。空间复杂度：插入排序不需要额外的空间，复杂度为 $O(1)$，是原地排序。时间复杂度： 最好的情况下只需要一次冒泡：时间复杂度为：$O(1)$ 最坏的情况下是需要 n 次，时间复杂度为 $O(n^2)$。 平均时间复杂度为 $O(n^2)$ 归并排序归并排序采用分治思想，将整体划分为小部分，最后归并在一起达到整体有序。 实现分治和递归比较相像，分治是一种解决问题的思想，递归是一种编程技巧。归并排序的递归公式： 1234&#x2F;&#x2F; 递推公式merge_sort(p...r) &#x3D; merge(merge_sort(p...q), merge_sort(q + 1, r))&#x2F;&#x2F; 终止条件，当子数组不可再分解p &gt;&#x3D; r 伪代码实现： 12345678910111213141516// A 数组，n 数组大小 merge_sort(A, n) &#123; merge_sort_c(A, 0, n-1);&#125;//递归函数merge_sort_c(A, p, r) &#123; //终止条件 if p &gt;= r then return //取p-r中间位置q q = (p + r) / 2 merge_sort_c(A, p, q) merge_sort_c(A, q + 1, r) //将有序数组A[p, q], A[q + 1, r]合并到A[p, r]中 merge(A[p, r], A[p, q], A[q + 1, r])&#125; merge 函数将有序子数组合并，伪代码： 123456789101112131415161718192021merge(A[p, r], A[p, q], A[q + 1, r]) &#123; var i = p, j = q + 1, k = 0 //申请一个和 A[p, r]一样大的数组 var temp = new Array[0, r - p] while(i &lt;= q AND j &lt;= r) do &#123; if A[i] &lt; A[j] &#123; temp[k++] = A[i++] &#125; else &#123; temp[k++] = A[j++] &#125; &#125; //判断哪个子数组中只有剩余元素将其拷贝到temp var start = i, end = q if j &lt;= r then start = j, end = r //将剩余数组拷贝到临时数组中 while start &lt;= end do &#123; temp[k++] = A[start++] &#125; //将临时数组拷贝到 A 数组中 A = temp&#125; 复杂度分析稳定性归并排序是否稳定主要是最后的 merge 函数，合并的时候如果遇到值相等的元素，保持 A[p, q] 的元素在前即可保证稳定性。 时间复杂度归并排序采用了分治的思想，时间复杂度是求解各个子问题的和加上最后归并的时间。 12&#x2F;&#x2F;将问题 a 分解为 b 和 c，K是最后合并b和c的时间 T(a) &#x3D; T(b) + T(c) + K 归并排序的复杂度公示： 1234567891011T(1) &#x3D; C;T(n) &#x3D; 2*T(n&#x2F;2) + n;T(n) &#x3D; 2*T(n&#x2F;2) + n &#x3D; 2*(2*T(n&#x2F;4) + n&#x2F;2) + n &#x3D; 4*T(n&#x2F;4) + 2*n &#x3D; 4*(2*T(n&#x2F;8) + n&#x2F;4) + 2*n &#x3D; 8*T(n&#x2F;8) + 3*n &#x3D; 8*(2*T(n&#x2F;16) + n&#x2F;8) + 3*n &#x3D; 16*T(n&#x2F;16) + 4*n ...... &#x3D; 2^k * T(n&#x2F;2^k) + k * n ...... 达到终止条件即 $T(n/2^k) = T(1)$ 时，有 12345n&#x2F;2^k &#x3D; 1k &#x3D; nlog_2nT(n) &#x3D; 2^kT(n&#x2F;2^k) + kn &#x3D; 2^kC + kn &#x3D; nC + nlog_2n 归并排序和原数组的有序程度无关，时间复杂度都是 $nlog_2n$ 空间复杂度归并排序需要开辟和原数组一样大的空间辅助排序，空间复杂度时 $O(n)$ 快速排序快速排序也利用分治思想，对 A[p, r] 进行排序，选择 p-r 之间任意一个数据 pivot 作为分区点，遍历 p-r 的数据，将小于 pivot 的数据移到左边，大于 pivot 的数据放到右边，pivot 的位置为 q，原数组分为 A[p, q-1]、A[q] 和 A[q+1, r]，如此区分直到区间缩小为1，则所有数据都有序。 实现1234&#x2F;&#x2F; 递推公式：quick_sort(p, r) &#x3D; quick_sort(p, q-1) + quick_sort(q+1, r)&#x2F;&#x2F;终止条件：p &gt;&#x3D; r 123456789101112131415161718192021222324&#x2F;&#x2F; 快速排序，A是数组，n表示数组的大小quick_sort(A, n) &#123; quick_sort_c(A, 0, n-1)&#125;&#x2F;&#x2F; 快速排序递归函数，p,r为下标quick_sort_c(A, p, r) &#123; if p &gt;&#x3D; r then return q &#x3D; partition(A, p, r) &#x2F;&#x2F; 获取分区点 quick_sort_c(A, p, q-1) quick_sort_c(A, q+1, r)&#125;partition(A, p, r) &#123; pivot :&#x3D; A[r] i :&#x3D; p for j :&#x3D; p to r-1 do &#123; if A[j] &lt; pivot &#123; swap A[i] with A[j] i :&#x3D; i+1 &#125; &#125; swap A[i] with A[r] return i 这里分区函数的处理类似于插入排序，将 A[p, r-1] 分为两部分，A[p, i-1] 的元素都小于 pivot，暂叫做已处理区间，每次从未处理区间 A[i, r-1] 取出一个元素和 pivot 比较，如果小于则交换到未处理区间 复杂度分析稳定性由于分区函数存在元素交换，所以快速排序是不稳定的算法 时间复杂度正常情况下，如果分区合理则快速排序的时间复杂度与归并排序一样是 $O(nlog_2n)$ 12T(1) &#x3D; C； n&#x3D;1时，只需要常量级的执行时间，所以表示为C。T(n) &#x3D; 2*T(n&#x2F;2) + n； n&gt;1 如果选择的最后一个分区元素是最大的，则分区就不均衡，会退化成 $O(n^2)$ 空间复杂度在排序过程中，分区函数的实现在原数组中，原地处理。空间复杂度是 $O(1)$ 归并排序与快速排序区别 归并排序：先递归调用然后合并处理。从下往上先处理子问题。 快速排序：先分区在递归调用，从上往下处理，到最后已经有序。 选择分区点 三位取中法：从区间的首、中、尾分别选取三个元素，选取三个元素的中位元素位置作为分区点 随机法：随机选取元素作为分区点，降低最大元素成为分区点的概率 桶排序先对原有的值域进行划分，将元素区分到每个桶中，然后每个桶各自排序，最后将桶合并。桶排序是针对一些有特征的数据集效果较好。 实现 值域划分，通过规则将每个元素映射到对应的桶，确定桶的个数。需要根据数据集的特征来确定映射规则。例如：123&#x2F;&#x2F; f(x) 是元素 x 所在桶的编号；length 是原数据集的大小f(x) &#x3D; (x - min) &#x2F; lengthbucketNum &#x3D; (max - min) &#x2F; length + 1 排序算法，每个桶的排序算法可以自定。 复杂度分析时间复杂度数据集有 n 个元素，桶的个数为 m，如果是均匀的划分，每个桶内的元素个数为 $k = n/m$。桶内使用快速排序来实现，每个桶的时间复杂度是 $O(klogk)$，m 个桶的时间为 $O(mklogk)$，$k = n/m$ 则有 $O(nlog(n/m))$，当桶的个数接近 n 时，则时间复杂度接近为 $O(n)$。 空间复杂度需要申请 m 个桶空间，整体的空间复杂度是 $O(m + n)$ 稳定性桶排序的稳定性与每个桶内所采用的排序算法相关 计数排序通过辅助数组，遍历原集合将每个元素标记在对应的位置，遇到相同的元素则对应的位置计数器自增。 实现 计算辅助数组的大小1size &#x3D; max + 1 遍历待排序集合，将每个元素出现的次数记录到辅助数组中 计算每个元素的最终位置，从后往前遍历保证稳定性 例如，数组 A[2, 4, 5, 3, 4, 1]： 辅助数组大小为 6，遍历后得到 C[0, 1, 1, 1, 2, 1] 计算小于等于每个元素的个数，可以通过 C 数组得到，即为 C[i - 1] + C[i]，得到 C[0, 1, 2, 3, 5, 6] 临时数组 R 存放排序后的元素，从后往前遍历数组 A，A[5] = 1，对应的小于等于 1 的元素 C[1] 是 1，则元素 1 应该排在 R 的第一个位置即 R[0] = 1，同时 C[1] 的值自减 1；A[4] = 4，小于等于 4 的元素 C[4] = 5，则 A[4] 元素放在 R[4] 的位置。同时 C[4] 自减 1；……循环到数组 A 被遍历完。 最后得到的 R 数组就是数组 A 排序后的结果。 复杂度分析时间复杂度原数组大小是 N，辅助数组大小是 M，原数组存在多次遍历，但是去掉系数后时间复杂度是 $O(N + M)$ 空间复杂度申请了一个辅助排序的数组，空间复杂度是 $O(N + M)$ 稳定性如果在确定了元素位置后直接输出，是不稳定的，通过上述事例中的处理则是稳定的 适用范围计数排序适用在范围不大的数据集中，而且要求数据是正整数，对于负数或者小数需要将其处理为整数。 基数排序将元素先按照低位排序，在按照高位排序。元素位数不够的，按照最大元素的位数在不够的元素前面补 0。 实现 确定最大元素及其位数 申请一个基数数组 C[] 用于统计每一位元素出现的次数 计算元素排序后的位置，这与计数排序中类似，计算小于等于 C[i] 的个数 申请一个临时数组 R[] 存储排序后的元素 复杂度分析时间复杂度如果最大的元素只有一位，则时间复杂度是 $O(n)$，最大元素的位数为 k，则基数排序的时间复杂度是 $O(k*n)$ 空间复杂度空间复杂度是 $O(n + k)$ 稳定性与计数排序类似，实现过程中的处理可以保证稳定性","tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zcy-fover.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"排序","slug":"排序","permalink":"https://zcy-fover.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"数据存储/缓存/CsCache设计","date":"2020-02-22T07:40:41.945Z","path":"2020/02/22/数据存储/缓存/CsCache设计/","text":"CsCache缓存实现缓存架构介绍 CsCache缓存分层图 客户端层：使用者直接通过该层与数据进行交互 缓存提供层：对缓存管理层的生命周期进行维护，负责缓存管理层的创建、保存、获取和销毁 缓存管理层：对缓存客户端的生命周期进行维护，负责客户端的创建、保存、获取以及销毁 缓存存储层：负责以什么样的形式存储数据 基本存储层：以普通的ConcurrentHashMap为存储核心，不淘汰数据 LRU存储层：以最近最少使用原则进行数据存储和缓存淘汰 Weak存储层：以弱引用为原则的数据存储和缓存淘汰机制","tags":[{"name":"缓存","slug":"缓存","permalink":"https://zcy-fover.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"数据存储/MySQL/07.MySQL并发与事务","date":"2020-01-20T08:59:40.000Z","path":"2020/01/20/数据存储/MySQL/07.MySQL并发与事务/","text":"MySQL并发与事务并发控制MySQL 通过锁解决并发问题，一般有两种类型共享锁、排他锁，也叫读锁、写锁。 锁粒度加锁后就会影响系统的性能，需要在锁的性能损耗和数据安全性之间寻求平衡。 表锁用户写数据时需要先获得写锁，这会阻碍该表的所有的读写操作，读锁之间互不影响。写锁可以插到锁队列的读锁前面，反之则不行。 行级锁行级锁可以最大程度的支持并发处理，但这同时增大了锁的开销，MySQL 行级锁是在存储引擎层实现，服务层没有相关设计。 事务事务的特征：原子性、一致性、隔离性、持久性，即ACID 原子性：一个事务被视为一个不可分割的最小工作单元，整个事务必须全部提交或者全部回滚 一致性：数据库从一个一致性的状态转换到另一个一致性的状态 隔离性：通常情况下，一个事务所做的修改在最终提交前对于其他事务是不可见的 持久性：一旦事务提交，其所做的修改就会永久保存到数据库中 隔离级别未提交读(READ UNCOMMITTED)：事务中的修改即使没有提交对于其他事务也是可见的，事务可以读取未提交的数据，称之为脏读。 提交读(READ COMMITTED)：一个事务开始时，只能看见已经提交的事务所做的修改。即一个事务从开始到提交所做的修改对于其他事务是不可见的。也叫不可重复读。 可重复读(REPEATABLE READ)：解决了脏读问题，保证了一个事务中多次读取同一个数据结果是一致的，但是无法解决幻读。幻读是指当一个事务在读取某个范围的记录时，另一个事务在这个范围中插入了新的记录，再次读取会产生不同的结果。可重复读是 MySQL 的默认隔离级别。 可串行化(SERIALIZABLE)：强制事务串行化，会在读取的每行数据上加锁，避免了幻读。可能会造成大量的锁超时。 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ UNCOMMITTED YES YES YES NO READ COMMITTED NO YES YES NO REPEATABLE READ NO NO YES NO SERIALIZABLE NO NO NO YES 死锁死锁指两个或者多个事务在同一资源上相互占用，并请求对方占用的资源，导致恶性循环。多个事务同时锁定同一资源时，也会产生死锁。 InnoDB 存储引擎可以检测死锁的循环依赖并立即返回错误，InnoDB 目前处理死锁的方式是将持有最少行级锁(写锁)的事务进行回滚。 MySQL 中的事务自动提交(AUTOCOMMIT)：MySQL 默认采用自动提交模式，SHOW VARIABLES LIKE &#39;AUTOCOMMIT&#39;使用命令查看，1 或者 ON 表示启用，0 或者 OFF 表示禁用。在执行 DDL 相关命令时会强制执行 COMMIT 提交当前活动的事务。可以通过 SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED 设置事务的隔离级别。 在事务中混合使用存储引擎：事务是由下层存储引擎实现的，所以在同一个事务中使用多个存储引擎是不可靠的。如果混合使用了事务性和非事务性的表，在提交事务时不会有什么问题，但是回滚时非事务性表上的变更无法回退。 隐式锁定和显示锁定：InnoDB 执行的是两阶段锁定协议，在事务执行过程中随时可以锁定，只有当事务提交或者回滚之后锁才回释放，所有的锁在同一时刻释放，是隐式锁定；InnoDB 支持通过特定语句 LOCK TABLES 进行显示锁定。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zcy-fover.github.io/tags/MySQL/"},{"name":"MySQL事务","slug":"MySQL事务","permalink":"https://zcy-fover.github.io/tags/MySQL%E4%BA%8B%E5%8A%A1/"}]},{"title":"middle-service/search/elasticsearch/elasticsearch安装","date":"2019-02-17T07:27:41.888Z","path":"2019/02/17/middle-service/search/elasticsearch/elasticsearch安装/","text":"elasticsearch 安装环境 系统：MACOS Java 1.8+ 版本 版本历史：1.x -&gt; 2.x -&gt; 5.x -&gt; 6.x 下载的是 6.5.4 安装​ 首先在官网上下载压缩包，下载地址官网，或者在命令行使用wget命令获取，下载后解压即可。 目录介绍​ bin存放相关脚本命令 ​ config启动相关配置文件 ​ lib依赖的第三方库 ​ modules模块目录 ​ plugins第三方插件 ​ logs运行后会默认产生的日志文件夹 ​ data运行后产生的数据文件夹 单实例安装​ 打开terminal，目录切换至解压后的 elasticsearch 文件夹的 bin 目录下，输入java -version检查 java 版本是否符合，要求在1.8以上。 ​ 键入sh elasticsearch后回车，启动服务，默认端口 9200，在浏览器输入localhost:9200出现以下信息，启动成功。 1234567891011121314151617&#123; \"name\" : \"Bc8O_aI\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"xYAoAJt1QFihcu9U-TRQXg\", \"version\" : &#123; \"number\" : \"6.5.4\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"d2ef93d\", \"build_date\" : \"2018-12-17T21:17:40.758843Z\", \"build_snapshot\" : false, \"lucene_version\" : \"7.5.0\", \"minimum_wire_compatibility_version\" : \"5.6.0\", \"minimum_index_compatibility_version\" : \"5.0.0\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; 插件安装 Head插件","tags":[{"name":"中间件","slug":"中间件","permalink":"https://zcy-fover.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://zcy-fover.github.io/tags/elasticsearch/"}]},{"title":"java/Thread/Thread-wait-sleep","date":"2019-01-20T06:38:22.702Z","path":"2019/01/20/java/Thread/Thread-wait-sleep/","text":"Thread wait &amp; sleepThread wait线程等待（Waiting） 是线程的状态之一。通过 Thread.wait() 进入等待状态的线程会自动放弃 对象锁（Monitor），然后进入线程等待状态。当其他线程调用 notify() 或 notifyAll() ，等待线程进入可运行状态（Runnable），等待 CPU 调度。线程的一生介绍了线程状态间切换的过程。 调用 Object.wait() 前，必须已经获取了对象锁，否则将抛出 IllegalMonitorStateException。 1234567891011121314public class Demo &#123; private final Object lock = new Object(); public void badUsage() &#123; // will throw IllegalMonitorStateException lock.wait(); &#125; public void goodUsage() &#123; synchronized (lock) &#123; lock.wait(); &#125; &#125;&#125; Thread sleep处于 sleep 的线程也进入 等待 状态。与 Thread.wait() 不同是：线程不会因为 sleep 而放弃对象锁。当然，在任何情况下都可以调用 Thread.sleep() 方法，即使是未获得任何对象锁的前提下。 处于 sleep 下的线程，可能被其他线程中断（Interrupt），中断响应后将抛出 InterruptedException。何时需要线程中断中介绍了更多中断的内容。 Thread awaitwait() 方法属于 Object 类，await() 方法属于 Condition 类。 两者都是需要在获取锁的前提下调用，调用成功后放弃锁。前者获取对象锁，后者获取显式锁（Java 中 Lock 的实现类）。 Object.notify() 随机唤醒一个等待线程，Condition.signal() 唤醒指定的等待线程。这是使用上最大的不同。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"线程","slug":"线程","permalink":"https://zcy-fover.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"java/Thread/线程的一生","date":"2019-01-20T06:38:22.701Z","path":"2019/01/20/java/Thread/线程的一生/","text":"线程的一生线程是 CPU 调度的基本单位。Java 中线程状态分为 6 种： New：创建状态 Runnable：可运行状态 Waiting：等待状态 Timed Waiting：限时等待状态 Blocking：阻塞状态 Terminated：结束状态 Thread.State 中介绍了各个状态的含义。 Runable创建（new） 后的线程对象，调用 Thread.start() 方法进入 可运行（Runnable） 状态。 可运行 线程并没有立即执行，而是分为了两步：ready to run 和 running。因为线程进入可运行状态后仍然需要等待某些资源，最常见的是等待 CPU 调度资源或 IO 资源。 线程执行结束后，进入了 结束（Terminated） 状态。 Waiting线程会以 3 种不同方式进入 等待（Waiting） 状态，然后以各自的方式被唤醒。唤醒后的线程并没有直接进入 可运行 状态，而是参与了锁竞争。下面详细的介绍了这个过程。 任何处于等待状态下的线程，均允许响应中断。但是，仍然需要参与锁竞争，获得锁权限后才会抛出 InterruptedException。 Object.wait()Object.wait() 调用后，线程需要先放弃对象锁（若事先未获得锁，则抛出 IllegalMonitorStateException），然后被推进 线程等待队列（Thread Waiting Set），等待其他线程的唤醒。 其他线程调用 Object.notify() 会 随机 唤醒等待队列中的一个线程。为了公平性，该线程并没有直接进入可运行状态，而是重新开始了锁竞争，成功获取锁权限后才进入可运行状态。否则，线程会因为竞争锁失败而进入 阻塞（Blocking），一直到获取锁权限。 Object.notifyAll() 会唤醒等待队列中的所有线程，后续过程与 Object.wait() 相同。 特别注意： 等待线程仍然可以响应中断，但是需要竞争到锁权限后才会抛出 InterruptedException 等待线程有可能（概率尽管很小）出现 意外唤醒（Surprise Wakeup），因此通常在循环中调用 wait() 方法 1234567private final Object object = new Object();....synchronized (object) &#123; while (condition) &#123; object.wait(); &#125;&#125; Thread.join()Thread.join() 方法是为了等待某一个线程进入 终止（Terminated） 状态，当线程执行完毕，等待结束。 1234Thread t = new Thread();t.start();// waiting for t finished.t.join(); Thread.join() 的底层原理是基于 Object.wait() 实现的，通过循环判断线程是否存活来决定是否继续等待。 1234567public final synchronized void join(long millis) &#123; ... while (isAlive()) &#123; wait(delay); &#125; ...&#125; LockSupport.park()LockSupport 是 Java 中用于支持 线程阻塞原语（Thread Blocking Primitives，又称 PV 原语） 的基础工具类，位于 java.util.concurrent.locks 包下。Lock 与 Condition 都是基于 LockSupport 实现的。 12Lock lock = new ReentrantLock();Condition cond = lock.newCondition(); PV 原语用于空闲资源申请和释放，P 操作用于申请一个空闲资源，V 操作用于释放空闲资源，操作系统的线程管理 中介绍了 PV 原语的作用和原理。 park 方法等同于 P 操作，unpark 等同于 V 操作。调用 park 方法无法获取空闲资源时，线程会进入等待状态，直到其他线程调用 unpark 方法释放资源。 特别注意的是，park 方法进入的等待的线程，有可能被意外唤醒（与 Object.wait() 中的意外唤醒相同），为了安全起见，通常都会在循环中调用。 123while (condition) &#123; LockSupport.park(this);&#125; Timed Waiting限时等待（Timed Waiting） 与 等待（Waiting） 状态相似，但是它可以在超时后在没有外界的影响下自我唤醒。 下面是关于各个限时等待方法的参数对于边界值的处理方式： 等于 0 小于 0 Thread.sleep(millis) 立即唤醒 IllegalArgumentException Thread.join(millis) 与 jion() 相同 IllegalArgumentException Object.wait(timeout) 与 wait() 相同 IllegalArgumentException LockSupport.parkNanos 无任何操作，直接返回 无任何操作，直接返回 LockSupport.parkUtil 无任何操作，直接返回 无任何操作，直接返回 注：使用 LockSupport.parkNanos 和 LockSupport.parkUtil 时 必须 保证等待参数大于 0，否则方法无效。 Terminated执行完任务的线程，会进入 结束（Terminated） 状态。 以下是 Java 线程状态变化流程图。 thread_lifecycle Tick, Tick线程状态是 Java 多线程“游戏”中的基本规则。本篇重点讲解的线程等待与唤醒，恰恰是这场游戏中最复杂、最关键的一环。Java 中诸多熟知的多线程工具，例如：可重入锁、Condition、Thread.join 等都是基于线程等待实现的。","tags":[{"name":"Java","slug":"Java","permalink":"https://zcy-fover.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://zcy-fover.github.io/tags/JVM/"}]},{"title":"net-work/okhttp/OkHttpClient3架构简介","date":"2019-01-20T06:38:22.700Z","path":"2019/01/20/net-work/okhttp/OkHttpClient3架构简介/","text":"OkHttpClient3 架构简介OkHttp 旨在提供简单、稳定、高效的 HTTP Client 服务，并且支持 HTTP 2.0 以及 WebSocket。 总体架构分 6 层Protocols Layer 涵盖了 OkHttp 支持的所有“功能”，实现了复杂的协议通讯和 TSL 握手与验证。 Connection Layer 为“稳定、高效”而努力。除了单纯的实现了链路通讯，还实现了连接池（ConnectionPool）、链路复用（StreamAllocation）、失败链路黑名单（RouteDatabase）。 Cache Layer 用于缓存 Response，提高请求效率。 IO Layer 是基于 okio 的 IO 层，属于基础模块。 Interface Layer 是面向用户的接口层，目标是为用户提供简单的 API。OkHttp 将所有的需要暴露给用户的接口全部集中在了 OkHttpClient，方便用户的使用。OkHttpClient 类是外观模式的一个优秀案例。 Interceptor Layer 是其他 5 层的纽带，贯穿了整体的请求与响应流程。将这一复杂流程巧妙的划分为 5 部分，然后用拦截器分别实现各个子流程。同时，暴露给用户，方便用户接入自己的拦截器。 下图简单展示了请求与响应在 Interceptor 中的过程。 OkHttp请求与响应流程图 拦截器简介（选读） RetryAndFllowupInterceptor：创建 Stream、失败重试和重定向 BridgeInterceptor：从网络模型来看，它是传输层和应用层的桥梁，负责将用户的 Request 转换成网络可以理解的 Request；将来自网络的 Response 转换成易于用户使用的 Response CacheInterceptor：缓存获取与插入 ConnectInterceptor：开启一个连接，即从 Stream 中获取一个 RealConnection CallServerInterceptor：最后一个拦截器，用于向服务器发起原始的请求，并接收原始的响应 系统架构图 OkHttp系统架构图 Tick, Tick学习的过程应当尽可能的从宏观到微观。把握整体的脉络，走进了迷宫里才能方寸不乱，有张有弛。本篇从俯视的角度去了解 OkHttp。从它到底想解决什么问题开始，到它的整体设计如何围绕这些核心命题而展开。 “宏观到微观，问题驱动”，笔者的心得。欢迎大家一起分享自己的学习技巧，互相学习。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://zcy-fover.github.io/tags/HTTP/"},{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://zcy-fover.github.io/tags/OKHTTP/"}]},{"title":"net-work/okhttp/OkHttpClient3连接池模型","date":"2019-01-05T07:47:47.136Z","path":"2019/01/05/net-work/okhttp/OkHttpClient3连接池模型/","text":"OkHttpClient3 连接池模型OkHttp 的连接池与 JDBC 连接池有所不同。JDBC 的连接池往往面向单一目标服务器，而 OkHttp 中，多数情况下 HTTP 请求需要面向多台不同的服务器，因此 OkHttp 的连接池需要面向多目标。 客户端与服务器关系图 获取连接StreamAllocation#findConnections()方法用于获取一个连接（RealConnection，本文简称 cnn），cnn 可能来自线程池，创建新连接。 HTTP 2 连接复用 OkHttp 的连接复用与连接的创建和回收过程关联紧密，并且还涉及到了一个大角色——StreamAllocation HTTP 2.0 中，一个连接可以同时发送多个请求。所以 OkHttp 需要解决：如何让一个连接被多个线程使用，同时要确保线程安全，以及准确及时的回收空闲连接。 cnn 的复用是通过 StreamAllocation 实现的。StreamAllocation 可以看作是 cnn 的一个“分身”，一个 cnn 拥有众多的 StreamAllocation。用户使用连接的时，会获取 StreamAllocation，从而获取它背后真正的 cnn与服务器通讯。 StreamAllocation和Connection关系图 下面从 Java 层面展示了两者的关系。 123456789101112/* RealConnection class */public final class RealConnection extends Http2Connection.Listener implements Connection &#123; /** Current streams carried by this connection. */ public final List&lt;Reference&lt;StreamAllocation&gt;&gt; allocations = new ArrayList&lt;&gt;(); ...&#125;/* StreamAllocation class */public final class StreamAllocation &#123; private RealConnection connection; ...&#125; 一个 cnn 拥有一组 StreamAllocation 软连接集合， StreamAllocation 持有唯一一个 cnn。当用户获取一个连接时，会向特定的一个 StreamAllocation 发出申请，然后返回一个真正当连接。多个线程间可能会从不同的 StreamAllocation 获取同一个 cnn。一个线程持有一个唯一 StreamAllocation。 这里的用户是广义的，泛指连接的需求方，通常是一个线程。而并非真实的一个用户。 连接销毁 我们采用“倒叙”的方式铺开连接池的管理，从销毁讲起，后面还包括：连接的获取、连接的创建和线程安全保障 cnn 维护在 ConnectionPool#connections 中，数据结构如下： 1234public final class ConnectionPool &#123; private final Deque&lt;RealConnection&gt; connections = new ArrayDeque&lt;&gt;(); ...&#125; 完成这个清理工作的，是一个线程，它的处理方式很简单： connection pool 中没有任何空闲连接时，线程关闭 connection pool 中没有待清理的连接时，线程等待（waiting，默认等待 5 min） connection pool 中存在需要清理的连接时，执行清理任务 当有新的 cnn 加入到 connection pool 时，清理线程开启。 12345678910111213public final class ConnectionPool &#123; ... void put(RealConnection connection) &#123; assert (Thread.holdsLock(this)); if (!cleanupRunning) &#123; cleanupRunning = true; // start the cleanup thread executor.execute(cleanupRunnable); &#125; connections.add(connection); &#125; ...&#125; 连接池清理工作包括：寻找无效连接和销毁无效连接，空闲连接的判断是第一步的核心。 cnn 维护了一个 StreamAllocation 软连接集合用于对连接的使用情况进行追踪与计数。当没有任何线程使用 cnn 时，无法从集合中获取未被回收的 StreamAllocation 对象 。通过这样当方式，我们可以轻松的判断：”当前连接是否是处于空闲状态？“。 OkHttp 是允许部分空闲连接的存在的，只有超过最大空闲连接数量（maxIdleConnections）或者空闲时间过长的连接（keepAliveDurationNs），才被定义为“无效连接“，然后被清理线程销毁。 如同我们猜想的一样，销毁的最后一步，一定是将 cnn 从 connections 移除，并关闭 socket。 123456789101112131415public final class ConnectionPool &#123; long cleanup(long now) &#123; ... if (longestIdleDurationNs &gt;= this.keepAliveDurationNs || idleConnectionCount &gt; this.maxIdleConnections) &#123; // 1. remove cnn from connections connections.remove(longestIdleConnection); &#125; ... // 2. close socket // Close, ignoring any uncheck exceptions. Does nothing if socket is null. closeQuietly(longestIdleConnection.socket()); ... &#125;&#125; 结束了上面过程，简单梳理一下。清理连接的整体思路是：通过 cleanupRunnable 线程来执行清理任务，通过线程等待的方式不断的执行。StreamAllocation 软连接集合的引入，追踪了连接的被使用情况，解决了“空闲连接”定义的问题。该思路与 gc 回收算法中的“引用计数”算法大致相同。清理线程将无效的连接销毁，完成清理任务。 获取连接 &amp; 创建连接获取连接的过程包含了连接的创建。获取连接最初是由 ConnectInterceptor 拦截器发起的。拦截器模式是 OkHttp 整体流程的主干，贯穿了整体请求与响应流程，OkHttpClient3 架构简介 包含了 OkHttp 拦截器在整体架构中的地位与应用。 12345678910111213141516171819202122/* ConnectInterceptor class */public final class ConnectInterceptor implements Interceptor &#123; @Override public Response intercept(Chain chain) throws IOException &#123; ... // get a new stream HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); ... &#125;&#125;/* StreamAllocation class */ public HttpCodec newStream(...) &#123; ... try &#123; // find a connection RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout, ... &#125; catch (IOException e) &#123; throw new RouteException(e); &#125; &#125; OkHttp 优先尝试从 ConnectionPool 中获取连接，获取成功后计数加 1；如果获取失败，会创建一个新的连接，并将新连接加入到 connections 中，计数加 1。 计数过程是把 StreamAllocation 对象加入到 cnn 的“影子”集合中，StreamAllocation#acquire() 完成了这项工作。 获取连接获取 cnn 就是遍历 connections ，找到一个“合适”的连接返回。OkHttp 要求 HTTP 1.x 中，一个 cnn 最多拥有 1 个 Stream，HTTP 2.0 中可以拥有多个（默认为 Integer.MAX_VALUE）。合适连接要求如下： steam 没有达到创建的上限 host 相同 计数加 1，并将合适的 cnn 成功返回给用户，完成 HTTP 请求。 这里合适连接的要求，仅停留在 HTTP 1.x，HTTP 2.0 获取连接做了一些协议上的处理，不是本篇重点，这里不详述。 创建连接当从 ConnectionPool 获取连接失败后，会选择创建新的连接。并将新的连接加入到 connections 中，计数加 1。 1234567891011121314public final class StreamAllocation &#123; private RealConnection findConnection(...) throws IOException &#123; RealConnection result = null; ... // create new RealConnection result = new RealConnection(connectionPool, selectedRoute); // add stream to connection allocations acquire(result, false); ... // Pool the connection. Internal.instance.put(connectionPool, result); ... &#125;&#125; 连接的获取与创建过程，通过创建对象，并将新创建的对象加入到连接池中，计数加 1。本质上来看是连接池的连接容器（Deque&lt;RealConnection&gt;）的 add() 和计数器计数。 线程安全 本节所介绍的线程安全仅仅是有关连接池的线程安全。更多线程模型介绍在 OkHttpClient3 线程模型。 线程安全的核心是解决 共享资源在竞争条件下的状态不确定 问题。解决过程中的关键一步在于：找出可能处于竞争条件的共享变量。 其中，被 final 修饰的基础变量、Unmofied 容器、无访问通路的私有变量和局部变量，任何情况下都处于非竞争条件。更多关于线程的介绍在 操作系统的线程管理。 竞争条件（Race Condition， 又称竞太条件）：多个进程读写共享资源，最终的结果取决于进程运行的一个精确的时序，这样的情形称之为竞争条件，例如：缓冲区的并发访问问题。 Connection Pool 的共享变量ConnectionPool 作为 OkHttpClient 的一个 final 成员，随着 OkHttpClient 的创建而创建。一个 OkHttpClient 持有唯一一个 ConnectionPool，即 ConnectionPool 相对于 OkHttpClient 是单例模式。 OkHttp 的连接池类中，成员信息如下： 12345678910111213public final class ConnectionPool &#123; private static final Executor executor = new ThreadPoolExecutor(...); private final int maxIdleConnections; private final long keepAliveDurationNs; private final Runnable cleanupRunnable = new Runnable() &#123; ... &#125;; private final Deque&lt;RealConnection&gt; connections = new ArrayDeque&lt;&gt;(); final RouteDatabase routeDatabase = new RouteDatabase(); boolean cleanupRunning; ...&#125; 其中，共享变量有三个： connections：缓存连接，在线程创建、获取、销毁时使用 routeDatabase：缓存失败的链路，监视器类 cleanupRunning：清理线程开启的标志 ConnctonsOkHttp 在任何地方都使用了对象锁来保证访问 connections 的正确性，由于 ConnetionPool 对于 OkHttpClient 而言是单例，对象锁可以解决并发冲突。 RouteDataBase一个 HTTP URL 根据 DNS 解析的结果往往会存在多条 HTTP 链路（Route），例如： 121.1.1.1 www.abc.com1.1.1.2 www.abc.com OkHttp 维护来一个失败链路的黑明单，用于记录和规避连接失败的场景，提升连接的成功率。为了保证并发安全，OkHttp 采用了监视器模式实现该类。 cleanupRunningcleanupRuning 变量只在 put() 和 cleanup() 方法中用到，这两方法均使用了对象锁来保证。 Tick, Tick本篇文档偏重于讲解 OkHttp 线程模型的“骨骼”，其中的细节没有过多的涉及。目的是了解连接池的核心——安全高效的获取连接和回收连接，这是最有“营养”的部分。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://zcy-fover.github.io/tags/HTTP/"},{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://zcy-fover.github.io/tags/OKHTTP/"}]},{"title":"net-work/netty/Linux网络IO模型简介","date":"2019-01-05T06:54:02.980Z","path":"2019/01/05/net-work/netty/Linux网络IO模型简介/","text":"Linux内核将所有外设看作文件，文件的读写操作会返回一个文件描述符fd（file descriptor） socket的响应描述符为socketfd 描述符就是一个数字指向内核中的一个结构体（文件区域、路径属性等） 阻塞IO模型 非阻塞IO模型 IO复用模型 信号驱动IO模型 异步IO 所有文件操作阻塞执行，执行完一个在执行下一个 多个文件操作可以一起处理，各自应用进程轮询对应的内核数据 通过Linux提供的select/poll处理，进程将多个fd传给select或者poll系统调用，阻塞在select，这样select/poll就可以检测是否有fd处于就绪状态。 当数据准备就绪时，为该进程生成一个SIGIO信号，通知进程来读取数据。 以socket接口为例：进程空间调用recvFrom，其系统调用知道数据包到达且被写到应用进程缓冲区或者发生错误时返回，在此期间一直在等待。进程从开始调用recvFrom开始一直被占用所以叫阻塞模型。 recvFrom从应用到内核，如果缓冲区没有数据的话，就会返回一个EWOULDBLOCK错误，一般都对非阻塞IO模型进行轮询检查内核是不是有数据到来。 顺序扫描，支持的fd有限；还提供epoll系统调用，基于事件驱动方式代替顺序扫描，性能更好","tags":[{"name":"Linux","slug":"Linux","permalink":"https://zcy-fover.github.io/tags/Linux/"},{"name":"IO模型","slug":"IO模型","permalink":"https://zcy-fover.github.io/tags/IO%E6%A8%A1%E5%9E%8B/"}]},{"title":"数据存储/缓存/Redis/redis数据结构整理","date":"2019-01-01T13:18:50.746Z","path":"2019/01/01/数据存储/缓存/Redis/redis数据结构整理/","text":"Redis 数据结构扁平化的特点，不存在数据库中列表查询一类的操作。Redis 可以做缓存或者内存数据库 数据结构Value对象的通用数据结构1234567typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:REDIS_LRU_BITS; int refcount; void *ptr;&#125;robj; type：指String、List等结构化类型 encoding：encoding指的是这些接口规划类型具体的实现（承载）方式，同一个类型可以有多个实现方式，例如String可以用int来承载，也可以用封装的cha[]来承载，List可以用ziplist或者链表来承载 lru：表示本对象的空转时长，用于有限内存下长久不访问的对象的清理 refcount：应用计数用于对象的垃圾回收 ptr：指向的是以encoding方式实现这个对象的实际承载者的地址，例如String对象对应的sds地址 Redis 是二进制安全的存储，存储的数据编码格式有客户端自己指定，Redis 存储对应的字节。类似的还有 zookeeper、Kafka、hbase。 StringRedis中的String可以表示字符串、整数、浮点数、二进制四种类型，由Redis完成相互间的自动转型 基本操作： 存储二进制时，当偏移量超出当前字节的位数，也不会报错会继续开辟一个字节来存储 应用场景： 对于数值的自增自减可以用来做秒杀或者限流 二进制(bigmap)：可以利用二进制偏移的特性记录用户是否每天登录 123SETBIT KEY1 2 1 # 第三天登录SETBIT KEY1 9 1 # 第十天登录BITCOUNT KEY1 0 -1 # 统计用户总共登录几次 List RPUSH/LPUSH：RPUSH将元素添加在列表尾，L则是将元素添加在列表头部 RPOP/LPOP：取出给定key的列表的尾部或头部的元素并删除元素 LINDEX：去除给定的key对应列表索引的某个元素 LRANGE：取出给定key的索引范围内的元素，例如LRANGE key1 0, 3即取出前四个元素 LTRIM：将给定key的列表索引范围外的元素去除 BLPOP/BRPOP：BRPOP key1 key2 60，60秒内，key1非空则从key1对应的列表中pop最右元素，否则从key2中pop最右元素；如果60秒内两个列表始终为空，则超时返回 BLPOPPUSH/BRPOPPUSH：BRPOPPUSH key1 key2 60即60秒内如果key1对应的列表非空，则把key1列表的最右元素pop，并且放到key2最后 Hash： HGET：返回给定key， field的值 HSET：设置给定key，field的值 HMGET：返回给定key，field1、field2…的值 HMSET：设置给定key，多个field的值 HGETALL：获取给定key的所有field和value HDEL：删除给定key， field元素 HKEYS：获取给定的key的所有field名字 HVALS：获取给定key的所有value HLEN：获取给定的key的字段数量 HINCRBY：HINCRBY key field increment，给定key的field元素value自增整数 HINCRBYFLOAT：HINCRBYFLOAT key field increment ，给定key的field元素value自增浮点数 HEXISTS：检查指定key field是否存在 HSETNX：HSETNX key field value只有当field字段不存在时，设置该元素 Set SADD / SREM / SISMEMBER：实现向SET中增加、删除元素，以及检查元素是否存在 SCARD / SMEMBERS：实现统计元素个数、列出所有元素 SRANDMEMBER：随机获取元素的操作 12SRANDMEMBER key1 3 #返回set集合中随机的三个元素，如果超过了set集合的大小，则全部返回SRANDMEMBER key1 -4 #随即返回4个元素，但是可能存在重复；如果超过了集合大小，则会返回要求的数值个数元素，存在重复 SDIFF / SINTER：返回给定所有集合的差集/交集 SDIFFSTORE / SINTERSTORE destination key1 [key2]：返回所有集合的差集/交集，并且存储在 destination 中 SUNION：返回给定所有集合的并集 SUNIONSTORE destination key1 [key2]：返回所有集合的并集，并且存储在 destination 中 SMOVE source destination member：将 member 元素从 source 集合移动到 destination 集合 SPOP：移除并返回集合中的一个随机元素 Sorted-Set： ZADD / ZREM：添加/删除元素 ZRANK：确定某个KEY值在本sorted-set内按照顺序排在第几位 ZRANGE：例如ZRANGE key start stop，获取sorted-set中排名为start和stop间的数据 ZRANGESCOPE：ZRANGEBYSCOPE key min max获取sorted-set中scope介于min和max之间的数据 ZSCOPE：确定某个key值在本sorted-set内对应的 score ZINCRBY：有序集合中对指定成员的分数加上增量 increment ZCARD：获取有序集合成员数 ZCOUNT：获取指定 score 区间的成员数 ZLEXCOUNT：在有序集合中计算指定字典区间内成员数量 ZRANGE / ZREVRANGE：通过索引区间返回有序集合的元素 / 反转 ZRANGEBYLEX / ZREVRANGEBYLEX：通过字典区间返回元素 / 反转 ZRANGEBYSCORE / ZREVRANGEBYSCORE：通过 score 区间返回元素 / 反转 ZRANK / ZREVRANK：返回指定成员的索引(排名) / 反向排名 ZINTERSTORE：交集 ZUNIONSTORE：并集","tags":[{"name":"Redis","slug":"Redis","permalink":"https://zcy-fover.github.io/tags/Redis/"},{"name":"Redis数据结构","slug":"Redis数据结构","permalink":"https://zcy-fover.github.io/tags/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"net-work/okhttp/OKHTTP学习","date":"2019-01-01T13:18:05.057Z","path":"2019/01/01/net-work/okhttp/OKHTTP学习/","text":"来自王老板的分享OKHTTP系统架构模型 OKHTTP系统架构模型（王召） 线程池 线程模型（王召） 连接池（ConnectionPool） 连接池模型（王召） 思考概述 如何创建 如何管理 如何回收 要解决的问题 连接池上限 什么时候释放哪些连接 有链接超时的情况 学习协议 HTTP 1.0 HTTP 1.1 HTTP 2 SPDY 3.1 QUIK (Quick UDP Internet Connection) 创建put新连接 先检查空闲连接，将其清理 放入新的连接12345678void put(RealConnection connection) &#123; assert (Thread.holdsLock(this)); if (!cleanupRunning) &#123; cleanupRunning = true; executor.execute(cleanupRunnable); &#125; connections.add(connection);&#125; 123456789101112131415161718192021private final Runnable cleanupRunnable = new Runnable() &#123; @Override public void run() &#123; //循环执行清理操作 while (true) &#123; //返回清理执行等待的纳秒数 long waitNanos = cleanup(System.nanoTime()); if (waitNanos == -1) return; if (waitNanos &gt; 0) &#123; long waitMillis = waitNanos / 1000000L; waitNanos -= (waitMillis * 1000000L); synchronized (ConnectionPool.this) &#123; try &#123; ConnectionPool.this.wait(waitMillis, (int) waitNanos); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125; &#125; &#125;&#125;; 清理如何找到闲置的连接 通过pruneAndGetAllocationCount(connection, now)判断当前连接是不是在用 当idleDurationNs纳秒数超过keepAliveDurationNs或者idleConnectionCount超过maxIdleConnections时，直接将当前连接移除 上面情况不满足时，当idleConnectionCount &gt; 0返回允许等待的时间差值 当inUseConnectionCount &gt; 0返回keepAlive的最大时间 当前无连接不需要清理 如何判断连接是否在用 主要检查Reference的StreamAllocation是否为空，为空则说明有连接泄漏，程序有异常，不为空则返回Reference的列表size","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://zcy-fover.github.io/tags/HTTP/"},{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://zcy-fover.github.io/tags/OKHTTP/"}]},{"title":"数据存储/缓存/网站架构中的缓存结构整理","date":"2019-01-01T13:16:21.593Z","path":"2019/01/01/数据存储/缓存/网站架构中的缓存结构整理/","text":"网站架构中的缓存 image 网站架构缓存如图可分为： 客户端缓存页面缓存将之前渲染的页面保存为文件，当用户再次访问时可以避开网络连接，从而减少负载，提升性能和用户体验。 浏览器缓存HTTP1.0：与服务器约定规则进行，在服务器侧设置Expires的HTTP头来告诉客户端在重新请求文件之前多久是安全的，可以使用if-midified-since的条件请求来清空缓存，比较文件最初的下载时间和最后的更新时间，如果文件没有改变可以用304-Not Modified应答客户端 HTTP1.1：缓存系统被形式化引入了e-Tag标签，e-Tag标签是文件或者对象的唯一标识，当询问服务器某一个资源的e-Tag标签是否有效，有效会生成304-Not Modified；否则返回200提供正确的文件 e-Tag流程图 Cache-Control/Expires和Last-Modified/ETag一期使用时，Cache-Control/Expires的优先级要高于后者。即当本地缓存根据Cache-Control/Expires判断还在有效期内时，就不会在去服务器询问修改时间和实体标识了。 在html页面可以添加（并不是所有浏览器都支持） 1&lt;META HTTP-EQUIV=\"Pragma\" CONTENT=\"no-cache\"&gt; APP上缓存数据库缓存：把文件的相关信息（URL、路径、下载时间、过期时间）等放到数据库中，下次查询先从数据库中查询做对比 文件缓存：使用文件操作的API获取文件的最后修改时间。图片和其他配置类文件的缓存时间不一样。图片的缓存时间可能可以持续到下次清空缓存，但是配置文件可能会被更新；在不同网络环境下缓存的更新时间也可以不一样 网络中缓存WEB代理缓存正向代理 反向代理：客户端向代理服务发送请求，反向代理自己判断向何处发送请求，然后将从源服务获取到的内容返回给客户端 透明代理：客户端根本不需要知道有代理服务器的存在，又代理服务器改变客户端的请求报文，并传送真实的IP地址 匿名代理：加密的透明代理 边缘缓存反向代理服务和用户来源于同一个网络，用户访问反向代理服务就会得到较高质量的响应，这种反向代理缓存叫做边缘缓存 边缘缓存的商业化服务-CDN CDN缓存也是通过HTTP响应头的Cache-Control:max-age字段来设置CDN边缘节点的数据缓存时间，当客户端向CDN节点请求数据时，CDN回先判断缓存时间是否过期，没有过期则将缓存返回给客户端，过期则像服务器请求数据并更新本地缓存。 服务端缓存数据库缓存query cache：作用于MySQL实例，主要针对于select语句，MySQL将接收到的select语句以字符串进行hash，然后在query cache中进行查找，如果有就返回query cache的内容。 query cache：需要query_cache_size和query_cache_type；前者设置缓存大小，后者表示在那种场景下使用（0-OFF，1-ON，2-DEMAND） Qcache inserts表示多少次未命中然后插入；Qcache lowmem prunes值大则说明缓存不够；Qcache hits值非常大，则说明使用缓存较频繁；Qcache free blocks表明缓存区的碎片，如果较多需要清理. InnoDB缓存：innodb_buffer_pool_size设置缓存InnoDB索引及数据块的内存区域大小；table_cache设置高速缓存的数量。 平台级缓存EhCache： 轻量快速：线程机制为大型高并发系统设计 良性伸缩：数据可以伸缩到数G字节，节点可以到数百个 简洁灵活：运行时缓存设置，存活时间、空闲时间、内存和缓存存放的最大数目可以在运行时修改 标准支持： 强扩展性：节点发现，冗余器和监听器可插件化 数据持久：缓存的数据在机器重启后可以在磁盘上获取 缓存监听：提供对缓存事件之后的处理机制 分布式缓存：支持高性能的分布式缓存，兼具灵活性和扩展性 应用级缓存Redis：应用缓存技术： 缓存命中：缓存中有这一对象，则使用缓存的数据 没有命中：cache miss ，缓存中还有空间的时候，没有命中的对象就会被放入缓存中 存储成本：没有命中缓存，需要从数据库中取出数据放入缓存，这个过程消耗的时间和空间叫做存储成本 缓存失效：存储在缓存中的数据要被更新时，则原数据就失效了 替代策略：当缓存已经满了，有新的数据来，需要从缓存中去除一条旧的数据放入新的数据，如何去除如何插入新的需要有替代策略 替代策略： Least-Recently-Used（LRU）：替换掉最近最少请求的对象 Least-Frequently-Used（LFU）：替换掉访问次数最少的对象 Least-Recently-Used 2（LRU2）：把最近访问两次的对象放入缓存，会把最近两次使用最少的缓存对象去除，需要跟踪对象两次，访问负载会增加 Two Queues（2Q）：把被访问的数据放到KRU的缓存中，如果这个对象在被访问一次，就把这个对象放到第二个、更大的LRU缓存中，使用多级缓存 SIZE：替换占用空间最大的对象，这样会导致某些小对象可能一直存在与缓存中 LRU-Threshold：不缓存超过某一大小的对象，其他与LRU相同 Log(size)+LRU：替换最大的对象，size相同时按照LRU处理 Hyper-G：LFU的改进，同时考虑上一次访问时间和大小 Pitkow/Recker：替换最近最少使用的对象，除非所有对象都是今天使用的；如果都是今天则替换掉最大的对象 Lowest-Latency-First：替换下载时间最少的文件 Hybrid Hybrid：减少平均延迟，对缓存中的每个文档计算一个保留效用，保留效用最小的对象会被替换掉 Lowest Relative Value（LRV）：计算保留效用，替换保留效用最低的对象 Adaptive Replacement Cache（APC）：介于LRU和LFU中间，由两个LRU组成，第一个LRU包含最近只被使用过一次的，第二个包含最近被使用过两次的，以此得到新的和常用的对象；APC可以自我调节，访问负载较小 Most Recently Used（MRU）：MRU与LRU是相对的，移除最近被最多使用的对象；（减少因为计算寻找最少最近的耗时） First in First out（FIFO）：通过队列跟踪缓存对象，最先进入的对象最先被踢走 Random Cache：随意替换，效果比FIFO好，有些情况比LRU好 云缓存服务动态扩容、数据多备、自动容灾、成本较低","tags":[{"name":"缓存","slug":"缓存","permalink":"https://zcy-fover.github.io/tags/%E7%BC%93%E5%AD%98/"}]}]